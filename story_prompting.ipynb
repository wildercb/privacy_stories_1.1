{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import text_processing\n",
    "import secrets \n",
    "\n",
    "from typing import List, Dict\n",
    "import openai  # Assuming OpenAI API, but adaptable to other models\n",
    "\n",
    "# Load text file and taxonomy JSON\n",
    "\n",
    "taxonomy_file_path = 'privacy_ontology_simple.json'  # Replace with actual path\n",
    "example_file_path = 'annotations/Actual_Budget/Accounts_&_Transactions.txt'\n",
    "target_file_path = 'input/lh-ehr/Direct_Messaging_README.txt'\n",
    "\n",
    "# Load previously processed example files\n",
    "example_data = text_processing.process_input(example_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a privacy expert annotator tasked with annotating text files with metadata about privacy behaviors and stories. For the given text, annotate the following:\n",
      "\n",
      "1. Actions: Actions performed or expected in the text.\n",
      "2. Data Types: Types of data referenced in the text. Data types may include specific subcategories.\n",
      "3. Purposes: Intentions or purposes related to the actions and data types.\n",
      "4. Stories: Concise stories that describe how actions, data types, and purposes interact in context.\n",
      "\n",
      "After providing your annotations, explain your rationale for these annotations. Place <R> tag between your annotations and your rationale.\n",
      "\n",
      "Use only the categories listed below when annotating:\n",
      "\n",
      "Actions:\n",
      "Collect, Use, Share\n",
      "\n",
      "Data Types:\n",
      "Contact Data:\n",
      "  Phone Number:\n",
      "  Email address:\n",
      "  User ID:\n",
      "  Job Title:\n",
      "  Company:\n",
      "  Address:\n",
      "  Name:\n",
      "  Date of Birth:\n",
      "  Image:\n",
      "  Government ID:\n",
      "  Biographical Data:\n",
      "    CV:\n",
      "    Education:\n",
      "    Employment:\n",
      "Health Data:\n",
      "  Physical activity:\n",
      "Social Media:\n",
      "Location:\n",
      "  Approximate location:\n",
      "  Precise location:\n",
      "Financial:\n",
      "  Orders:\n",
      "  Payment History:\n",
      "  Purchase History:\n",
      "  Order:\n",
      "  Card Data:\n",
      "  Bank Account:\n",
      "  Credit Score:\n",
      "  Income Information:\n",
      "  assets:\n",
      "    vehicle:\n",
      "    Insurance:\n",
      "Usage Data:\n",
      "  App Interactions:\n",
      "    Pages Visited:\n",
      "    Timestamps:\n",
      "    Interaction with Ads:\n",
      "    User Engagement:\n",
      "    Session ID:\n",
      "  Device Information:\n",
      "    IP Address:\n",
      "    Device ID:\n",
      "    Advertisement ID:\n",
      "    Browser:\n",
      "    Operating System:\n",
      "    Diagnostics:\n",
      "    Sensor Data:\n",
      "    Audio:\n",
      "    Browsing history:\n",
      "Tracking:\n",
      "  Cookies:\n",
      "  Web Beacons:\n",
      "  Tags:\n",
      "Account Information:\n",
      "  User id:\n",
      "  Username:\n",
      "  Password:\n",
      "  Account Balance:\n",
      "  Messages:\n",
      "  Friends:\n",
      "\n",
      "Purposes:\n",
      "Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts, Requirements\n",
      "\n",
      "Here is the text:\n",
      "\n",
      "Full Cleaned Text:\n",
      "Using Actual\n",
      "Accounts & Transactions\n",
      "\n",
      "overview\n",
      "\n",
      " You can add as many accounts as you like. Adding all of your accounts (including things like mortgages) is a nice way to get an overview of all your finances.\n",
      "\n",
      "Off-budget accounts\n",
      "â€‹\n",
      "Actual makes a distinction between accounts being\n",
      "for budget or off budget. \n",
      "Off budget accounts don't effect the budget and are meant to track stuff like investments and mortgages. Transactions in off budget accounts can't be categorized; they simply track balances over time.\n",
      "\n",
      "For budget\n",
      "accounts affect the budget, and transactions can be categorized. These are accounts where you want to track cash flow and use the budget, like checking accounts and credit cards.\n",
      "\n",
      "Depending on your usage, savings accounts can either be on or off the budget. If you're not sure, we recommend keeping it on budget at the start.\n",
      "\n",
      "Adding a new account\n",
      "â€‹\n",
      "\n",
      "You can add an account to your budget at any time, however when you first install Actual you can use the\n",
      "Add Account\n",
      "button in the middle of the screen.\n",
      "\n",
      "You can also add an account using the\n",
      "+ Add account\n",
      "button in the sidebar.\n",
      "\n",
      "Two successive screens will appear with boxes asking you to fill in a few options\n",
      "\n",
      "Create a Local Account or Link to GoCardless (See\n",
      "Connecting Your Bank\n",
      ")\n",
      "Give your account a name\n",
      "Is the account on or off budget\n",
      "The current account balance\n",
      "\n",
      "Off budget means that the balance is not reflected when you assign money to categories in your budget register\n",
      "\n",
      "Here you can see how that looks when the options are completed.\n",
      "\n",
      "If you select the Off Budget checkbox then change the account type the Off Budget checkbox will reset and will need to be re-selected each time the account type is changed\n",
      "\n",
      "You can now see the account in the sidebar of Actual\n",
      "\n",
      "\n",
      "Closing or deleting an account\n",
      "â€‹\n",
      "\n",
      "Navigate to the account by clicking on it in the sidebar\n",
      "Click on the 3 dots (top right of the transactions list) to show the actions menu\n",
      "Select\n",
      "Close Account\n",
      "You need to select another account to transfer the existing balance to. Choose the account that you have moved funds to.\n",
      "Press\n",
      "Close Account\n",
      "\n",
      "You can still access this account under\n",
      "Closed Accounts\n",
      "in the sidebar, and even reopen it from the same actions menu.\n",
      "\n",
      "If you want to delete an account\n",
      "even if it has existing balances, in the popup after selecting\n",
      "Close Account\n",
      ", click the\n",
      "force close\n",
      "at the bottom.\n",
      "\n",
      "\n",
      "Renaming an existing account\n",
      "â€‹\n",
      "\n",
      "Click the account name in the sidebar of Actual\n",
      "\n",
      "Hovering your cursor close to the account name at the top will reveal two icons.\n",
      "The page icon allows you to write a note about this account, and the pencil icon allows you to rename the account.\n",
      "\n",
      "After editing a note for the account or its name, hit 'Enter' to save your changes.\n",
      "\n",
      "Off-budget accounts\n",
      "Adding a new account\n",
      "Closing or deleting an account\n",
      "Renaming an existing account \n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "(S: \n",
      "We collect account data, account balance, bank account, and assets for personal analytics.We collect account data, account balance, bank account, and assets for account management. We collect account data, account balance, bank account, and assets for Functionality. We use account data, account balance, bank account, and assets for personal analytics. We use account data, account balance, bank account, and assets for account management. We use account data, account balance, bank account, and assets for Functionality.\n",
      ")\n",
      "\n",
      "Here are the behaviors and the privacy requirements in the form of privacy stories we build from them:\n",
      "Privacy stories are built explicitly from our labelled privacy behaviors in the format of we (action) (data type) for (purpose)Actions: Collect, Use\n",
      "Data Types: Account Data, Account Balance, Bank Account, Assets\n",
      "Purposes: Personal analytics, Provide Service, \n",
      "\n",
      " \n",
      "Direct Messaging with LibreEHR and EMR Direct phiMail(R)\n",
      "Version 1.3, 19 Jul 2014\n",
      "\n",
      "A. Purpose: To provide a secure method from within LibreEHR for sending/receiving \n",
      "protected health information to/from another Direct address using the Direct Project \n",
      "messaging standard, as a step toward the goal of satisfying the three MU2 criteria \n",
      "requiring the use of Direct messaging.  (For general information about Direct messaging, \n",
      "see http://www.emrdirect.com/about-directed-exchange-and-secure-direct-messaging.html)\n",
      "\n",
      "B. IMPORTANT:  Please be aware of the following limitations when using the LibreEHR \n",
      "Direct Messaging features with PHI in a production environment:\n",
      "\n",
      "1. the current code only supports a single shared \"group\" Direct Address for each LibreEHR \n",
      "installation. Note that this model is fully compliant with the Direct Project \n",
      "requirements for Direct messaging, but we may add additional models in the future \n",
      "should we determine that doing so would provide a higher degree of interoperability for \n",
      "LibreEHR users.\n",
      "\n",
      "2. the current code only sends the CCR or CCD XML data that is already available in LibreEHR; \n",
      "these files as currently generated by existing LibreEHR code do not meet the requirements \n",
      "of the MU2 criteria, and the current CCD files do not pass strict CDA validation tests.\n",
      "\n",
      "C. Problems Solved:\n",
      "\n",
      "1. Patient-initiated transmission of clinical data from the Report section of the Patient \n",
      "Portal interface.\n",
      "\n",
      "2. Provider-initiated transmission of clinical data from the Report section of the Patient \n",
      "pane in the main LibreEHR interface.\n",
      "\n",
      "3. Log all data transmissions including date/time, patient, and whether transmission \n",
      "was initiated by the patient through the Patient Portal or by an LibreEHR user through the \n",
      "main interface.\n",
      "\n",
      "4. Receive Direct messages from other sources.\n",
      "\n",
      "D. How it Works:\n",
      "Once configured, LibreEHR will interface with a phiMail Direct messaging server to complete the\n",
      "required message transactions. The phiMail platform is described on the EMR Direct website, \n",
      "http://www.emrdirect.com and http://www.emrdirect.com/phimail-faq.html.\n",
      "\n",
      "E. What you need before enabling Direct Messaging in LibreEHR:\n",
      "\n",
      "1. Test Mode: Developers may request a complimentary test address at \n",
      "https://www.emrdirect.com/subscribe-developer  \n",
      "Access to a sandbox server is available for testing and development purposes.\n",
      "\n",
      "2. Production Mode: Healthcare provider users should begin by signing up for a production \n",
      "Direct messaging account with EMR Direct by registering at https://www.emrdirect.com/subscribe\n",
      "\n",
      "Subscribers will receive the username, password, and server address information with which to \n",
      "configure LibreEHR.  \n",
      "\n",
      "F. How to enable the Direct Messaging Features in LibreEHR:\n",
      "Setup of phiMail Direct messaging Service is done in the Administration::Globals::Connectors \n",
      "tab\n",
      "\n",
      "1. Check the \"Enable phiMail Direct Messaging Service\" checkbox.\n",
      "\n",
      "2. Enter the Server Address, Username, and Password provided to you. The server address\n",
      "will be of the form \"ssl://servername.example.com:32541\" - replace the hostname and port\n",
      "with the values provided to you by EMR Direct. The Username is your Direct Address. Do not \n",
      "enter the server URL into your browser address bar, as this will not work.\n",
      "\n",
      "3. Specify the LibreEHR user who will receive notification of new incoming Direct messages. \n",
      "Enter their LibreEHR username in the notification user field.\n",
      "\n",
      "4. Specify the interval for automatic message checking; we suggest 5 or 10 minutes as a\n",
      "starting point, but installations processing a large number of Direct messages may want a \n",
      "shorter interval. To disable automatic message checking through LibreEHR's background service\n",
      "manager, set the interval to 0 (zero). Disabling automatic checking would be appropriate \n",
      "if message checking is managed through another mechanism, such as a system cron job.\n",
      "\n",
      "5. Optionally check \"phiMail Allow CCD Send\" and/or \"phiMail Allow CCR Send\" to enable\n",
      "the Transmit feature for these data types. If you do not select at least one of these,\n",
      "LibreEHR will operate in a receive-only mode.\n",
      "\n",
      "6. Click the \"Save\" button.\n",
      "\n",
      "7. Confirm that a valid Notification Email Address is set in the Administration::\n",
      "Globals::Notifications tab to receive error notifications from the Direct Messaging service.\n",
      "\n",
      "8. Install the EMR Direct trust anchor certificate.  \n",
      "\n",
      "Note: This is *not* your Direct certificate; it is the trust anchor for the SSL \n",
      "certificate issued to our servers, and is used only to validate the SSL certificate \n",
      "presented by the phiMail server on the other side of LibreEHR's connection.  Your Direct private\n",
      "key and certificate are managed by the phiMail Server and are not installed in LibreEHR.\n",
      "Your Direct certificate is made availabe for your review by EMR Direct, but you will not\n",
      "need to install it anywhere.\n",
      "\n",
      "For added security, the trust anchor for the phiMail Server should be installed in the LibreEHR \n",
      "installation tree at:\n",
      "\n",
      "[installation_root]/sites/[site_id]/documents/phimail_server_pem/phimail_server.pem\n",
      "\n",
      "This phimail_server_pem directory and its contents should be readable by the the \n",
      "webserver process, but only writable by trusted local users. The certificate file \n",
      "itself must be PEM encoded. You can identify a PEM encoded certificate file because \n",
      "it begins with the text \"-----BEGIN CERTIFICATE-----\". Although LibreEHR will connect \n",
      "to phiMail servers without installing this certificate, this is a required configuration \n",
      "step for all production  accounts to ensure that you are connecting to the correct \n",
      "server. You can obtain the correct certificate at the following URLs:\n",
      "\n",
      "  a. Test accounts: http://certs.emrdirect.com/EMRDirectTestCA.crt\n",
      "     Important: Don't forget to rename the file to phimail_server.pem and install it\n",
      "     in the correct directory.\n",
      "\n",
      "  b. Production accounts: https://www.phicert.com/certs/phiCertDirectRootCA.crt\n",
      "     Important: The production root must be converted to PEM format as follows:\n",
      "     $ openssl x509 -in phiCertDirectRootCA.crt -inform DER -out phimail_server.pem\n",
      "     Don't forget to install phimail_server.pem in the correct directory. As an added\n",
      "     security measure, please call us to confirm the thumbprint on this certificate.\n",
      "\n",
      "G. Debugging background connections to the server.\n",
      "\n",
      "You may review the connection activity to the server by Selecting Administration::Other::Logs,\n",
      "selecting \"direct-message\" in the \"Name of events:\" drop-down menu, and clicking \"[Refresh]\".\n",
      "If the background service is succesfully connecting, you will see \"message check completed\"\n",
      "events in the log as well as any message related entries (see below for instructions to\n",
      "view more detailed message related status information). If you see no entries, make sure that\n",
      "the background service is enabled (See F.4 above). If you see \"could not connect to server\"\n",
      "entries, each entry will also contain an error code:\n",
      "\n",
      "  C1: phiMail is disabled in the global configuration. Fix: enable.\n",
      "  C2: the phiMail server URL entered in the global configuration is invalid. Fix: Confirm\n",
      "      the URL has been entered correctly. It should be of the form \n",
      "      \"ssl://server.example.com:32541\".\n",
      "  C3: unable to create stream context. Fix: Usually this is because the server certificate \n",
      "      file installed in F.8 above is not the correct certificate or is in the wrong format.\n",
      "  C4: failed to open connection. Fix: Confirm you Internet service and local DNS servers are\n",
      "      online and your firewall is not blocking connections to the phiMail Server.\n",
      "\n",
      "H. Checking the status and history of the Direct Messaging Service in LibreEHR:\n",
      "Administrators may view the status of the service by Selecting Reports::Services::Background \n",
      "Services from the main LibreEHR left navigation bar. The \"View Log\" link on this page or \n",
      "Reports::Services::Direct Message Log will open the messaging history log showing each message \n",
      "sent or received and the current status of that message (Received, Sent, Delivery Confirmed, \n",
      "or Failed).\n",
      "\n",
      "I. Note of message status messages: Receiving message status updates requires that Direct message\n",
      "checking be enabled. When receiving messages, the phiMail back-end is fully compliant with the \n",
      "Direct messaging protocols to notify the sender and provide final delivery confirmation, but \n",
      "please note that  many other Direct providers do not yet support these features. If a message \n",
      "is sent to a recipient using one of these other systems, LibreEHR probably won't ever receive a \n",
      "final delivery confirmation for that message.\n",
      "\n",
      "J. How to use the Direct Messaging Features in LibreEHR:\n",
      "\n",
      "1. Sending:\n",
      "When the phiMail Direct Messaging service is enabled, an additional \"Transmit\" button will\n",
      "appear in the Continuity of Care Record (CCR) and/or Continuity of Care Document (CCD) block \n",
      "of the Reports section in both the Patient Portal and the Patient pane of the main provider \n",
      "interface. \n",
      "\n",
      "To transmit a CCR or CCD, first click the \"Transmit\" button. This will open a small dialog \n",
      "immediately below the button with a form field to enter the intended recipient's Direct Address. \n",
      "Clicking \"Transmit\" again will hide the dialog.\n",
      "\n",
      "A Direct Address should have the same form as a regular email address, e.g. \n",
      "jonesclinic@direct.example.com. Enter the address in the field and click the \"Send\" button \n",
      "immediately to the right of the field. Only a single recipient may be specified in the field.\n",
      "The Send button will be temporarily disabled while LibreEHR is communicating with the phiMail \n",
      "server. This will only work for properly-configured Direct addresses. Attempts to send to a \n",
      "regular email address or Direct address outside of our test mode \"trust sandbox\" will fail\n",
      "during testing. Production accounts have wide interoperability with other Direct service\n",
      "providers. Should you encounter a trust community with which LibreEHR does not interoperate,\n",
      "please let us know at support@emrdirect.com.\n",
      "\n",
      "LibreEHR will then display a status message immediately below the Address field, the \n",
      "success or failure of the message transmission, or an error message. If the message is\n",
      "successfully submitted to the server, the Address field will be cleared to prevent accidental\n",
      "re-transmission. If multiple recipients are required, the next recipient can now be entered.\n",
      "\n",
      "If you receive an error message, it will be followed by an error code. For a discussion\n",
      "of error codes beginning with the letter \"C\" please see section G above. Error codes\n",
      "beginning with \"EC\" are listed here:\n",
      "\n",
      "  EC 1: phiMail disabled in global configuration. Fix: enable.\n",
      "  EC 4: authentication failure. Fix: The Username and Password entered in the\n",
      "        global configuration must be corrected.\n",
      "  EC 5: request to add text failed. Fix: Confirm total message length < 5MB.\n",
      "  EC 6: problem sending the text. Fix: Confirm your local network connectivity is stable.\n",
      "  EC 7: request to add clinical document failed. Fix: see EC 5.\n",
      "  EC 8: problem sending the clinical document. Fix: see EC 6.\n",
      "\n",
      "2. Receiving:\n",
      "When the phiMail Direct Messaging service is enabled, and message checking is enabled either \n",
      "through the background services manager of another mechanism, LibreEHR will automatically process \n",
      "message status updates and new messages. Status updates will be reflected immediately in the \n",
      "Direct Messaging log. Additionally, if a \"Failed\" notification is received for a previously sent \n",
      "message, a regular email message will be generated to the Notification Email Address specified \n",
      "in the Notifications tab of the Global Settings panel (accessed by selecting Administration::\n",
      "Globals from the main left navigation menu).\n",
      "\n",
      "New Direct messages will be processed as follows. A new \"Patient Note\" will be generated and \n",
      "sent to the phiMail notification user specified in the Connectors tab of the Global settings. \n",
      "The patient note will contain information about the message, including any text at the beginning \n",
      "of the message from the sender. Any attachments (and any non-text content) will be automatically \n",
      "converted to separate LibreEHR Documents, which will be referenced in the new Patient Note.  \n",
      "The Documents and the Patient Note are initially created without an assigned patient. \n",
      "\n",
      "At this time, the envisioned workflow is that the notification user will review the message text\n",
      "and any included Documents to determine which patient the content belongs to and will then set the \n",
      "patient using the existing Patient Note interface for choosing a patient. Once the patient is sent, \n",
      "the Patient Note can be forwarded to another provider or staff member as appropriate using the \n",
      "existing forwarding mechanism for Patient Notes. The unassigned Documents can be viewed by Selecting \n",
      "Miscellaneous::New Documents from the main left navigation menu, which opens a Documents list. Once \n",
      "the specified document is opened, the user can optionally categorize the document and, when \n",
      "appropriate, assign the document to a specific patient using the \"Move to Patient #\" feature in the \n",
      "Documents interface.\n",
      "\n",
      "\n",
      "Trademark Notice: phiMail is a registered trademark of EMR Direct.\n",
      "\n",
      "Copyright (c) 2013-2014 EMR Direct.\n",
      "\n",
      "\n",
      "Annotate the text with actions, data types, purposes, and stories as demonstrated, using only the categories from the list provided. For each annotation, provide your rationale and place <R> tag between your annotations and rationales.\n",
      "\n",
      "\n",
      "Token Count: 3961 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from typing import Dict, List, Union\n",
    "import tiktoken  # Library for token counting with OpenAI models\n",
    "import prompt_templates\n",
    "\n",
    "# Load the privacy ontology\n",
    "ontology_path = \"privacy_ontology_simple.json\"\n",
    "privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "# Load one processed example file for demonstration\n",
    "example_file = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "\n",
    "# Define target text to be annotated (for demonstration) & Load annotated version \n",
    "target_file_annotations = text_processing.process_input(target_file_path)\n",
    "new_text_to_annotate = open(target_file_path).read()\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_example = prompt_templates.create_annotation_prompt(example_file, new_text_to_annotate, privacy_ontology)\n",
    "\n",
    "# Print the prompt to review it\n",
    "print(prompt_example)\n",
    "print(f\"\\nToken Count: {prompt_templates.count_tokens(prompt_example)} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating with LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing input\\Actual_Budget\\Backup_&_Restore.txt: 'charmap' codec can't decode byte 0x9d in position 232: character maps to <undefined>\n",
      "Created prompt templates for 24 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import prompt_templates\n",
    "import text_processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "input_dir = 'input'\n",
    "\n",
    "def find_matching_file(input_file_path, annotations_dir):\n",
    "    \"\"\"\n",
    "    Find the matching annotation file for a given input file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Root directory of annotations\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the matching annotation file, or None if not found\n",
    "    \"\"\"\n",
    "    # Get the relative path from the input directory\n",
    "    relative_path = os.path.relpath(input_file_path, input_dir)\n",
    "    annotation_file_path = os.path.join(annotations_dir, relative_path)\n",
    "    \n",
    "    return annotation_file_path if os.path.exists(annotation_file_path) else None\n",
    "\n",
    "\n",
    "def find_most_similar_file(input_file_path, annotations_dir, exclude_file):\n",
    "    \"\"\"\n",
    "    Find the most similar annotation file to the input file, excluding a specified file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Directory containing the annotation files\n",
    "        exclude_file (str): File to exclude from similarity search\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the most similar annotation file\n",
    "    \"\"\"\n",
    "    # Read the input file's content\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        input_text = f.read()\n",
    "    \n",
    "    # List to store (similarity_score, annotation_file_path)\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Loop through the annotations directory to calculate similarity\n",
    "    for root, _, files in os.walk(annotations_dir):\n",
    "        for filename in files:\n",
    "            if filename == exclude_file or filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            annotation_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Read the annotation file's content\n",
    "            with open(annotation_file_path, 'r', encoding='utf-8') as f:\n",
    "                annotation_text = f.read()\n",
    "            \n",
    "            # Compute similarity using TF-IDF and cosine similarity\n",
    "            tfidf = TfidfVectorizer().fit_transform([input_text, annotation_text])\n",
    "            similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "            similarity_scores.append((similarity, annotation_file_path))\n",
    "    \n",
    "    # Sort by similarity score in descending order and return the most similar file\n",
    "    similarity_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    return similarity_scores[0][1] if similarity_scores else None\n",
    "\n",
    "\n",
    "def create_prompt_templates_dict(input_dir='input', annotations_dir='annotations', ontology_path='privacy_ontology_simple.json'):\n",
    "    \"\"\"\n",
    "    Create a dictionary of prompt templates matching input files with their corresponding annotation examples.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Root directory containing input files to be annotated\n",
    "        annotations_dir (str): Root directory containing annotated example files\n",
    "        ontology_path (str): Path to the privacy ontology JSON file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of prompt templates for each input file\n",
    "    \"\"\"\n",
    "    # Load privacy ontology\n",
    "    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "    \n",
    "    # Dictionary to store prompt templates\n",
    "    prompt_templates_dict = {}\n",
    "    \n",
    "    # Walk through all directories and files in the input directory\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            # Skip hidden files\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            # Full path to the input file\n",
    "            input_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Find corresponding annotation file (for exclusion from similarity search)\n",
    "            annotation_file_path = find_matching_file(input_file_path, annotations_dir)\n",
    "            \n",
    "            if not annotation_file_path:\n",
    "                print(f\"No matching annotation found for {input_file_path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Read the input text to annotate\n",
    "                with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                    new_text_to_annotate = f.read()\n",
    "                \n",
    "                # Find the most similar annotation file\n",
    "                most_similar_annotation = find_most_similar_file(input_file_path, annotations_dir, os.path.basename(annotation_file_path))\n",
    "                \n",
    "                if not most_similar_annotation:\n",
    "                    print(f\"No similar annotation found for {input_file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the example file from annotations\n",
    "                example_file = text_processing.process_input(most_similar_annotation)[0]\n",
    "                \n",
    "                # Create prompt template\n",
    "                prompt_template = prompt_templates.create_0_shot_annotation_prompt(\n",
    "                    example_file, \n",
    "                    new_text_to_annotate, \n",
    "                    privacy_ontology\n",
    "                )\n",
    "                \n",
    "                # Create a unique key based on relative path\n",
    "                relative_key = os.path.relpath(input_file_path, input_dir)\n",
    "                \n",
    "                # Store in dictionary\n",
    "                prompt_templates_dict[relative_key] = {\n",
    "                    'input_file_path': input_file_path,\n",
    "                    'annotation_file_path': most_similar_annotation,\n",
    "                    'prompt_template': prompt_template,\n",
    "                    'target_annotations': text_processing.process_file(annotation_file_path),\n",
    "                    'token_count': prompt_templates.count_tokens(prompt_template)\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_file_path}: {e}\")\n",
    "    \n",
    "    return prompt_templates_dict\n",
    "\n",
    "\n",
    "# Create the prompt templates dictionary\n",
    "prompt_templates_dict = create_prompt_templates_dict()\n",
    "\n",
    "# Save to JSON for inspection\n",
    "with open('prompt_templates_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({k: {**v, 'prompt_template': v['prompt_template']} \n",
    "              for k, v in prompt_templates_dict.items()}, \n",
    "              f, indent=2)\n",
    "\n",
    "print(f\"Created prompt templates for {len(prompt_templates_dict)} files\")\n",
    "\n",
    "# Optional: You can save the full dictionary using pickle if needed\n",
    "import pickle\n",
    "with open('prompt_templates.pkl', 'wb') as f:\n",
    "    pickle.dump(prompt_templates_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n",
      "Model: openai:gpt-4o-2024-11-20 - Completed a run\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from getpass import getpass\n",
    "import model_routing\n",
    "from typing import Dict, List\n",
    "\n",
    "# Ensure OPENAI_API_KEY is set\n",
    "os.environ['OPENAI_API_KEY'] = getpass('Enter your OPENAI API key: ')\n",
    "\n",
    "os.environ['GROQ_API_KEY'] =\"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\"\n",
    "\n",
    "def save_results_to_csv(models: List[str], \n",
    "                         prompt_templates_dict: Dict, \n",
    "                         model_responses: Dict, \n",
    "                         output_file: str):\n",
    "    \"\"\"\n",
    "    Save the model outputs, prompts, and file annotations to a CSV file.\n",
    "    \"\"\"\n",
    "    # Open the output CSV file\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Prepare the CSV header\n",
    "        fieldnames = ['File', 'Prompt', 'Model', 'Target File Path', 'Target Annotations', 'Model Response 1', 'Model Response 2']\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Iterate through the prompt templates and models to pair responses\n",
    "        for file_key in file_keys:\n",
    "            template_info = prompt_templates_dict[file_key]\n",
    "            \n",
    "            for model in models:\n",
    "                # Get responses for this model\n",
    "                model_specific_responses = model_responses.get(model, {})\n",
    "                \n",
    "                # Get responses for this specific file/prompt\n",
    "                prompt_responses = model_specific_responses.get(file_key, [])\n",
    "                \n",
    "                # Ensure we have at least two responses (or 'No Response')\n",
    "                response1 = prompt_responses[0] if prompt_responses and len(prompt_responses) > 0 else 'No Response'\n",
    "                response2 = prompt_responses[1] if prompt_responses and len(prompt_responses) > 1 else 'No Response'\n",
    "\n",
    "                # Create a row for each model and file\n",
    "                row = {\n",
    "                    'File': file_key,\n",
    "                    'Prompt': template_info['prompt_template'],\n",
    "                    'Model': model,\n",
    "                    'Target File Path': template_info['input_file_path'],\n",
    "                    'Target Annotations': json.dumps(template_info['target_annotations']),\n",
    "                    'Model Response 1': json.dumps(response1, ensure_ascii=False),\n",
    "                    'Model Response 2': json.dumps(response2, ensure_ascii=False)\n",
    "                }\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "def run_multi_file_annotations(prompt_templates_dict, output_csv, models=None):\n",
    "    \"\"\"\n",
    "    Run annotation process for multiple files and save results to a CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Prepare prompts that maintains the file key order\n",
    "        test_prompts = [\n",
    "            prompt_templates_dict[file_key]['prompt_template'] \n",
    "            for file_key in file_keys\n",
    "        ]\n",
    "\n",
    "        # Get model responses \n",
    "        raw_model_responses = model_routing.run_multi_model_prompts(\n",
    "            models=models, \n",
    "            prompts=test_prompts, \n",
    "            num_runs=2  # Number of runs per model\n",
    "        )\n",
    "\n",
    "        # Restructure responses to match file keys\n",
    "        model_responses = {}\n",
    "        for model in models:\n",
    "            model_responses[model] = {\n",
    "                file_key: model_runs \n",
    "                for file_key, model_runs in zip(file_keys, raw_model_responses.get(model, []))\n",
    "            }\n",
    "\n",
    "        # Save results to CSV \n",
    "        save_results_to_csv(\n",
    "            models=models,\n",
    "            prompt_templates_dict=prompt_templates_dict,\n",
    "            model_responses=model_responses,\n",
    "            output_file=output_csv\n",
    "        )\n",
    "\n",
    "        print(f\"Annotation results saved to {output_csv}\")\n",
    "        print(f\"Number of files processed: {len(prompt_templates_dict)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage remains the same\n",
    "output_csv = 'LLMAnnotation_gpt4o_0_shot.csv'\n",
    "models = [\n",
    "    'openai:gpt-4o-2024-11-20'\n",
    "    # 'groq:llama-3.3-70b-versatile'\n",
    "    ]\n",
    "run_multi_file_annotations(prompt_templates_dict, output_csv, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model F1 scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use \\n**Data Types:**  Account Information:\\n    Account Balance,\\n    User id\\n**Purposes:** Account management, Functionality\\n\\n**Stories:** 1. We collect Account Balance, User id for account management. We use Account Balance, User id for functionality. \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use \\n**Data Types:** Contact Data: Email address, User ID,  Name\\n**Purposes:** Account management, Functionality, Customization, Security\\n**Stories:** \\n1. We collect Email address, Username, Password for account management and Authentication.\\n\\n \\n\\n**Actions:** Collect, Use\\n**Data Types:** Financial: Bank Account, Bank Account Balance\\n**Purposes:** Functionality,  Accounts\\n**Stories:**\\n1. We collect Bank Account, Bank Account Balance to manage user finances and track account balances.\\n\\n\\n## Rationale: \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8889\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n**Data Types:** Account Data: Account Number, Account Balance, Bank Account, Company, Currency, Address, Phone Number, Name \\n**Purposes:** Functionality, Account Management, Personal Analytics\\n\\n\\n**Stories:**\\n\\n* **Story 1:**  We (Collect) Account Data: Account Number, Account Balance, Bank Account, Company, Currency, Address, Phone Number, Name for Functionality. \\n    \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8889\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use \\n**Data Types:** Account Data: Account Number, Account Balance, Bank Account, Address, Company, Name, Phone Number,  \\n**Purposes:** Functionality, Account Management \\n\\n**Stories:** \\n\\n* **Account Management:** Users can add bank accounts and credit cards to the app. The app collects account number, account balance, bank name, phone number, address, and account name for managing user finances. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:**  Contact Data: Name, Email address, Phone Number, Company; Usage Data: App Interactions: Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID, Device Information: IP Address, Device ID, Browser, Operating System, Diagnostics; Social Media; Financial: Orders, Payment History, Purchase History, Card Data, Bank Account,  ; Account Information: User id, Username, Password, Account Balance, Messages, Friends\\n\\n**Purposes:** Analytics, Customization, Advertisement, Functionality, Accounts, Security,  Contact \\n\\n**Stories:**\\n\\n1. We collect and use Name, Email address, Phone Number, Company,  Orders, Payment History, Purchase History, Card Data, Bank Account for Contact and Functionality.\\n    \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** \\n  * Contact Data:\\n    * Name:\\n    * Email address:\\n    * Phone Number:\\n    * Address:\\n    * User ID:\\n  * Social Media:\\n  * Usage Data:\\n    * App Interactions:\\n      * Pages Visited:\\n      * Timestamps:\\n      * Interaction with Ads:\\n      * User Engagement:\\n      * Session ID:\\n    * Device Information:\\n      * IP Address:\\n      * Device ID:\\n      * Advertisement ID:\\n      * Browser:\\n      * Operating System:\\n      * Diagnostics:\\n      * Sensor Data:\\n      * Audio:\\n      * Browsing history:\\n  * Account Information:\\n    * User id:\\n    * Username:\\n    * Password:\\n\\n**Purposes:** Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts, Requirements\\n\\n**Stories:**\\n1. We collect and use Name, Email address, Phone Number, and Address for Contact. We collect and use User ID for Accounts.  We collect and use Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID, IP Address, Device ID, Advertisement ID, Browser, Operating System, Diagnostics, Sensor Data, Audio, and Browsing history for Analytics, Customization, Advertisement, Security, Tracking, and Functionality.\\n2. We use Username and Password for Accounts. We use User ID for Accounts and Security.\\n\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"##  \\n\\n**Actions: Collect, Use**\\n\\n**Data types:\\n\\n**Purposes: Contact, Analytics, Customization, Advertisement, Security\\n\\n**Stories:\\n**\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Login with the same as the user\\n\\n  \\\"errcode\\\": \\\"M_THREEPID_IN_\\n\\n```json\\n{\\n  \\\"address\\\": \\\"3361122344\\\"\\n}\\n```\\n\\n```json\\n{\\n  \\\"message\\\": \\\"This is the same request and response\\n\\n```json\\n{\\n  \\\"errcode\\\": \\\"M_THREEPID_IN_\\n\\n```\\n\\n```json\\n{\\n  \\\"address\\\": \\\"336122344\\\"\\n}\\n\\n```\\n\\n```json\\n{\\n  \\\"errcode\\\": \\\"M_THREEPID_IN_\\n\\n```\\n\\n```json\\n{\\n  \\\"account\\\": \\\"336122344\\\"\\n}\\n\\n## Add phone number\\n\\n```json\\n\\n\\n```\\n{\\n  \\\"error\\\": \\\"Error contacting \\n```\\n```json\\n{\\n  \\\"error\\\": \\\"M_THREEPID_IN_\\n\\n```\\n\\n```json\\n{\\n  \\\"errcode\\\": \\\"M_THREEPID_IN_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_THREEPID_IN_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_THRE\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_TH\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n```json\\n{\\n  \\\"error\\\": \\\"\\n\\n```json\\n\\n\\n## Removing an email address\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n\\nThis is the same request.\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```\\n\\n```json\\n\\n\\n\\n\\n**\\n\\n```json\\n\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n```json\\n\\n\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"M_\\n\\n```json\\n{\\n  \\\"error\\\": \\\"\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n\\n**Data Types:** Contact Data: Email address, User ID: Nickname, Account Information: Password, Account Information: User ID,  \\n\\n**Purposes:** Account management, Functionality, Security, Customization,\\n\\n**Stories:**\\n\\n1. **We collect Email address, User ID (Nickname), and Password for account management and security purposes.** \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:**  \\n* Contact Data:\\n    * Email address:\\n    * Username:\\n    * Nickname:\\n* Account Information:\\n    * User id:\\n    * Username:\\n    * Password:\\n    * Account Balance:\\n    * Messages:\\n* Usage Data:\\n    * App Interactions:\\n        * Pages Visited:\\n        \\n**Purposes:**  \\n* Account management:\\n* Functionality:\\n* Authentication:\\n* Customization:\\n* Communication:\\n* Security\\n* Analytics\\n\\n**Stories:**\\n\\n1. **We collect Email address, Username, Nickname, and Password for Account management and Authentication.**  We use Nickname for generating web addresses and identifying your account. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:**  Contact Data: Email address, User ID: Username, \\nAccount Information: User id, Username, Password, Account Balance\\n\\n**Purposes:** Account management, Functionality, Security, Customization\\n\\n**Stories:**\\n\\n1. **We collect Email address, User name, password for Account management and Authentication.** \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** Contact Data: Email address,  User ID,  Name, \\n**Purposes:**  Account management, Contact, Functionality, Security\\n\\n**Stories:** \\n\\n1. We collect Email address, User name, password for Account management. We use Email address, User name, password for Authentication. \\n  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'account management', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'account management', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'account management', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share \\n\\n**Data Types:**\\n* Contact Data: Email address, Phone Number \\n* Account Information: User id, Username, Password, Account Balance, Messages, Friends\\n* Usage Data: App Interactions, Device Information\\n\\n**Purposes:**\\n* Security\\n* Functionality\\n* Accounts\\n* Customization\\n\\n**Stories:**\\n1. **We collect email address, User id, Username, Password for account management and security.** \\n    *Rationale:* The text explicitly states that email address, user id, username, and password are used for account management and security purposes. \\n\\n\\n2. **We use Phone Number for your reference only. **\\n    *Rationale:* The text states that the phone number is used for reference only, implying it is collected but not actively used for other purposes.\\n\\n3. **We use App Interactions and Device Information to provide a customized user experience.** \\n    *Rationale:* While not explicitly stated, inferring that user interactions and device information are used to personalize the user interface and functionality.\\n\\n\\n\\n## Annotations:\\n\\n**Actions:** Collect, Use, Share \\n\\n**Data Types:**\\n* Contact Data: Email address, Contact Data: Phone Number \\n* Account Information: User id, Username, Password, Account Balance, Messages, Friends\\n* Usage Data: App Interactions, Device Information\\n\\n**Purposes:**\\n* Security\\n* Functionality\\n* Accounts\\n* Customization\\n\\n**Stories:**\\n1. **We collect email address, User id, Username, Password for account management and security.** \\n    *Rationale:* The text explicitly states that email address, user id, username, and password are used for account management and security purposes. \\n\\n\\n2. **We use Phone Number for your reference only. **\\n    *Rationale:* The text states that the phone number is used for reference only, implying it is collected but not actively used for other purposes.\\n\\n3. **We use App Interactions and Device Information to provide a customized user experience.** \\n    *Rationale:* While not explicitly stated, inferring that user interactions and device information are used to personalize the user interface and functionality.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** \\n* Contact Data: Email address, Phone Number, Name\\n* Account Information:  User id, Username, Password, Account Balance, Messages, Friends\\n* Usage Data: App Interactions (Pages Visited, Timestamps), Device Information (IP Address, Device ID, Browser, Operating System)\\n* Social Media:\\n\\n**Purposes:**\\n* Contact, Analytics, Customization, Security, Functionality, Accounts, Requirements\\n\\n**Stories:**\\n\\n1. **We collect** Email address, Phone Number, and Name **for** User identification and contact purposes **within** the platform. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n\\n**Data Types:** \\n  *  Usage Data:\\n      * App Interactions:\\n          * Pages Visited\\n          * Timestamps\\n          * Interaction with Ads\\n          * User Engagement\\n          * Session ID\\n      * Device Information:\\n          * IP Address\\n          * Device ID\\n          * Advertisement ID\\n          * Browser\\n          * Operating System\\n          * Diagnostics\\n          * Sensor Data\\n          * Audio\\n  * Account Information:\\n      * Username\\n      * Password \\n  *  Contact Data:\\n      * Email address \\n\\n**Purposes:** Functionality, Security, Analytics,\\n\\n\\n**Stories:**\\n\\n1. We process usage data for Functionality.\\n   *  We process usage data for Security.\\n     * We process App Interactions: Pages Visited, Timestamps, User Engagement for Functionality. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n**Data Types:**  Usage Data:\\n    App Interactions: Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID\\n    Device Information: IP Address, Device ID, Advertisement ID, Browser, Operating System, Diagnostics, Sensor Data, Audio, Browsing history\\n**Purposes:** Functionality, Security\\n**Stories:**\\n\\n1. We collect usage data (App Interactions: Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID, Device Information: IP Address, Device ID, Advertisement ID, Browser, Operating System, Diagnostics, Sensor Data, Audio, Browsing history) for Functionality. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Share, Process\\n\\n**Data Types:**  Contact Data: Email address, Account Information: Username, Displayname, Matrix User, Password,  Usage Data:  \\n\\n**Purposes:** Account management, Functionality, Customization,  Contact\\n\\n**Stories:**\\n\\n1. We collect email address and username for account management. We collect displayname and matrix user for functionality. We process password for account management. We share account information for functionality.   \\n2. We collect email address for contact, functionality. We process email address for contact, functionality. \\n\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Share, Process\\n**Data Types:**  Account Information: User id, Username, Email address, Password,  Contact Data: Name, Usage Data:  App Interactions: Pages Visited, Timestamps, Interaction with Ads, User Engagement, Device Information:  IP Address,  Device ID,  Browser, Operating System,\\n**Purposes:**  Account Management, Functionality, Security, Customization, Analytics,   \\n**Stories:**\\n1.  We collect Displayname, Bio, Matrix User, Avatar, and Banner for functionality.\\n\\n2. We process  Email and Password for account management. \\n\\n3. We process Name and User ID for functionality\\n\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'identification', 'customization'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'identification', 'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'identification', 'customization'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n**Data Types:**  Contact Data: Email address, Username, Password; Account Information: User id, Username, Password, Account Balance, Messages, Friends\\n**Purposes:** Account Management, Functionality, Authentication, Security, Customization\\n\\n**Stories:**\\n\\n1. **We collect Email address, Username, Password for Account management and Authentication.** \\n    R:  The text explicitly states these data points are required for account creation and login. These actions are performed for the purposes of managing user accounts and verifying their identity.\\n\\n2. **We use Email address for Password resets and Notifications.** \\n    R: The text states that providing an email address is used for sending password reset links and notifications (if enabled).\\n\\n3. **We use Username for display within the platform.**\\n    R: The text states that the username is unique within an instance and is used for identification. \\n\\n4. **We use Password for Authentication.** \\n    R: The text explicitly states that a password is required for logging in to an account.\\n\\n5. **We use Displayname for customization of user profile.**\\n    R: The text states that a display name can be freely changed and is an alternative to the username.\\n\\n6. **We use Bio for user profile customization.**\\n    R: The text states that a bio allows for a long description of the user and can be formatted with Markdown.\\n\\n7. **We use Avatar for user profile customization.**\\n    R: The text states that an avatar is a profile picture that is shown next to all user posts.\\n\\n8. **We use Banner for user profile customization.**\\n    R: The text states that a banner is a header image for the user's profile page.\\n\\n9. **We use Interface language for user interface customization.**\\n    R: The text states that users can select the language they prefer for the user interface.\\n\\n\\n\\nLet me know if you'd like me to annotate any other sections of the text!\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:**\\n\\n* **Contact Data:** Email address, Name:\\n* **Account Information:** Username, Password\\n\\n**Purposes:** Account management, Authentication, Functionality, Customization\\n\\n**Stories:**\\n\\n1. **We collect Email address, Username, and Password for Account management and Authentication.** \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:**\\n* **Use:**  The text describes how to set up and use the Direct Messaging service in LibreEHR.\\n \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** \\n* **Use**\\n\\n**Data Types:**\\n* **Account Information: User id, Username, Password\\n\\n**Purpose:**\\n* **Accounts**\\n\\n**Stories:**\\n1. We use user ids and usernames to manage user accounts. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n**Actions:**\\n**Data Types:**\\n**Purposes:**\\n**Stories:**\\n\\n**Actions:**\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Share, Collect, Use\\n\\n\\n**Data Types:** Contact Data: User ID, Account Information: User ID\\n**Purposes:** Security, Functionality, Analytics\\n\\n\\n\\n**Stories:** \\n\\n1. We share User ID for Functionality. R: Sharing user ID is necessary for user authentication and session management, which is required for application functionality. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"##  Annotations \\n\\n**Actions:** Collect, Use, \\n**Data Types:**  Contact Data: Email address, User id:\\n**Purposes:** Account management, Functionality, Authentication\\n**Stories:** \\n1. We collect Email address, User id,  for account management. We use Email address, User id for authentication. \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n**Data Types:**\\n  Contact Data:\\n    Email address:\\n    Username:\\n    Password:\\n **Purposes:** Account management, Functionality, Authentication\\n\\n**Stories:**\\n\\n1. We collect Email address, Username, Password for Account management. We use Email address, Username, Password for Authentication.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** Contact Data: User ID, Usage Data: App Interactions: Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID, Device Information: IP Address, Device ID, Advertisement ID, Browser, Operating System, Diagnostics,  \\n\\n**Purposes:** Functionality, Security, Analytics,\\n\\n**Stories:**\\n1. We process user engagement data for functionality and analytics purposes.  \\n2. We process IP address data for security and analytics purposes. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Process\\n**Data Types:** Usage Data\\n**Purposes:** Functionality, Security\\n**Stories:**\\n\\n1. We process usage data for Functionality. \\n2. We process usage data for Security.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n\\n**Data Types:** Contact Data (Email address), Usage Data (Session ID), Account Information (Username)\\n\\n**Purposes:** Functionality, Security\\n\\n**Stories:**\\n\\n1. We collect Email address for Functionality.  The system stores email addresses to facilitate user communication and notifications within the platform. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.4000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect\\n**Data Types:** Contact Data: Email address\\n**Purposes:** Functionality\\n\\n**Stories:** We collect Email addresses for functionality. \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations: \\n\\n**Actions:** Collect, Use, \\n**Data Types:** Contact Data: Email address, User ID: Username, Account Information: Password,\\n**Purposes:** Account management, Functionality, Authentication\\n**Stories:** \\n1. We collect Email address, Username, and Password for account management and authentication. \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:**  \\n* Contact Data: Email address, Username\\n* Account Information: User id, Username, Password \\n* Usage Data: Interaction with Ads,  Timestamps, Session ID, Device Information: IP Address, Device ID\\n*  \\n\\n**Purposes:** \\n* Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts \\n\\n**Stories:**\\n\\n1. **We collect Email address, Username, Password for account management and authentication.** \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** Contact Data: Email address,  Account Information: User id, User name,  Usage Data: App Interactions: Pages Visited,  Device Information: IP Address, Device ID,   Account Information: Account Balance, Messages, Friends\\n\\n**Purposes:** Functionality, Accounts, Security, Analytics, Customization\\n\\n**Stories:**\\n\\n1. We Collect Email address, User id, User name, IP Address, Device ID for Account Management. We Use Email address, User id, User name, Account Balance, Messages, Friends, Pages Visited for Functionality. We Process IP Address, Device ID for Security.\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Share\\n\\n**Data Types:** \\n  * **Contact Data:** Email address, Name, Job Title, Company\\n  * **Account Information:** User ID, Username, Password, Account Balance\\n  * **Usage Data:** App Interactions (Pages Visited, Timestamps, Interaction with Ads, User Engagement, Session ID), Device Information (IP Address, Device ID), Browsing history\\n  * **Social Media:** \\n\\n**Purposes:** \\n   * Accounts, Security, Functionality, Analytics, Customization\\n\\n**Stories:**\\n\\n1. **We collect email address, Name, Job Title, Company for account management.**  \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**{#s (a: collect, use) (dt: Account data, Username, password, User ID,  (p: Log in)**\\n### `auth_checkers`\\n\\n_First introduced in Synapse v1.46.0_\\n\\n```python\\nauth_checkers: Dict[Tuple[str, Tuple[str, ...], Callable]\\n```\\n\\nA dict mapping from tuples of a login type identifier (such as `m.login.password`) and a\\ntuple of field names (such as `(\\\"password\\\", \\\"secret_thing\\\")` to authentication checking\\ncallbacks, which should be of the following form:\\n\\n```python\\nasync def check_auth(\\n    user: str,\\n    login_type: str,\\n    login_dict: \\\"synapse of module_api.JsonDict\\\",\\n) -> Optional[\\n    Tuple\\n    [\\n        str, \\n        Optional[Callable[[\\\"synapse User id,\\n        Awaitingable[None]]\\n    ]\\n]\\n```\\n\\nThe login type and field names should be provided by the user in the\\nrequest to the `/login` API. [The Matrix specification](https://matrix.org/docs/spec/client_server/latest#authentication-types)\\ndefines some types, however user defined ones are also allowed.\\n\\nThe callback is passed the `user` field provided by the client (which might not be in\\n`@username:server` form), the login type, and a dictionary of login secrets passed by the client.\\n\\nIf the authentication is successful, the module must return the user's Matrix ID (e.\\ng. `@alice:example.com`) and optionally a callback to be called with the response to the\\n`/login` request. If the module doesn't wish to return a callback, it must return `None` instead.\\n\\nIf the authentication is unsuccessful, the module must return `None`.\\n\\nNote that the user is not automatically registered, the `register_user(..) method of the\\n[module API](writing_a_module.html) can be used to lazily create users.\\n\\nIf multiple modules register an auth checker for the same login type but with different fields, Synapse will refuse to start.\\n\\nIf multiple modules register an auth checker for the same login type with the same fields, then the callbacks will be executed in order, until one returns a Matrix User ID (and optionally a callback). In that case, the return value of that callback will be accepted and subsequent callbacks will not be fired.\\nIf every callback returns `None`, then the authentication fails.\\n\\\\}\\n\\n**Rationale:\\n\\nThis section describes how user logins are handled by the system.\\n**\\n\\n**Purpose:**\\nThe purpose of this section is to define how the system handles logins.\\n\\n**Data Types:**\\n- **Account data:** This section deals with user Account data.\\n- **User ID:** Used to identify user accounts.\\n- **Password:** Used for authentication.\\n- **Username:** Used for identifying users.\\n**Actions:**\\n- **Collect:** The system collects user data during the login process.\\n- **Use:** The system uses the collected data for authentication.\\n\\n\\n\\n**Stories:**\\n- We collect username and password for login.\\n- We use the collected information to authenticate the user.\\n- The user is not automatically registered upon login.\\n- If multiple modules register the same login type with different fields, the system will not start.\\n- If multiple modules register the same login type with the same fields, the system executes callbacks until one returns a user ID, then ignores the rest.\\n- If every callback returns None, the authentication fails.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**{#s (a: collect, use) (dt: Account data, User id, Room ID, Account data type, json content  (p: Account Management, Auditing)\\n### `on_account_data_updated`\\n\\n_First introduced in Synapse v1.57.0_\\n\\n```python\\nasync def on_account_data_updated(\\n    user_id: str,\\n    room_id: Optional[str],\\n    account_data_type: str,\\n    content: \\\"synapse.module_api.JsonDict\\\",\\n) -> None:\\n```\\n\\nCalled after user's account data has been updated. The module is given the\\nMatrix ID of the user whose account data is changing, the room ID the data is associated\\nwith, the type associated with the change, as well as the new content. If the account\\ndata is not associated with a specific room, then the room ID is `None`.\\n\\nThis callback is triggered when new account data is added or when the data associated with\\na given type (and optionally room) changes. This includes deletion, since in Matrix,\\ndeleting account data consists of replacing the data associated with a given type\\n(and optionally room) with an empty dictionary (`{}`).\\n\\nNote that this doesn't trigger when changing the tags associated with a room, as these are\\nprocessed separately by Synapse.\\n\\nIf multiple modules implement this callback, Synapse runs them all in order.\\n\\n## Example\\n\\nThe example below is a module that implements the `on_account_data_updated` callback, and\\nsends an event to an audit room when a user changes their account data.\\n\\n```python\\nimport json\\nimport attr\\nfrom typing import Any, Dict, Optional\\n\\nfrom synapse.module_api import JsonDict, ModuleApi\\nfrom synapse.module_api.errors import ConfigError\\n\\n\\n@attr.s(auto_\\n        account_data_type: str,\\n        content: JsonDict,\\n    ) -> None:\\n        content_raw = json.dumps(content)\\n        msg_content = f\\\"{user_id} has changed their account data for type {account_data_type} to: {content_raw}\\n        if room_id is not None:\\n            msg_content += f\\\" (in room {room_id}\\\"\\n\\n        await self.api.create_and_send_event_into_room(\\n            {\\n                \\\"room_\\n\\n    \\n            \\\"room_id\\\": self.config.audit_room,\\n                \\\"sender\\\": self.config.sender,\\n                \\\"type\\\": \\\"m.room.message\\\",\\n                \\\"content\\\": {\\n                    \\\"msgtype\\\": \\\"m.text\\\",\\n                    \\\"body\\\": msg_content\\n                }\\n            }\\n        )\\n```\\n  \\n  \\n  \\n#s (a: collect, use) (dt: User ID, Room ID, Account data type, json\\n  (p: Account Management, Auditing)\\n  Stories:\\n1. We collect user ID, room ID, account data type, and json content for account management and auditing.\\n  We use user ID, room ID, account data type, and json content for account management and auditing. We process user ID, room ID, account data type, and json content for\\n  account management and auditing.  We share user ID, room ID, account data type, and json content for account management and auditing.\\n  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n{#s (a: collect, use) (dt:  Account Information, Username, Password) (p: Log in)\\n### `auth_checkers`\\n\\n_First introduced in Synapse v1.46.0_\\n\\n```python\\nauth_checkers: Dict[Tuple[str, Tuple[str, ...]], Callable]\\n```\\n\\nA dict mapping from tuples of a login type identifier (such as `m.login.password`) and a\\ntuple of field names (such as `(\\\"password\\\", \\\"secret_thing\\\")`) to authentication checking\\ncallbacks, which should be of the following form:\\n\\n```python\\nasync def check_auth(\\n    user: str,\\n    login_type: str,\\n    login_dict: \\\"synapse.module_api.JsonDict\\\",\\n) -> Optional[\\n    Tuple[\\n        str, \\n        Optional[Callable[[\\\"synapse.module_api.LoginResponse\\\"], Awaitable[None]]]\\n]\\n```\\n\\nThe login type and field names should be provided by the user in the\\nrequest to the `/login` API. [The Matrix specification](https://matrix.org/docs/spec/client_server/latest#authentication-types)\\ndefines some types, however user defined ones are also allowed.\\n\\nThe callback is passed the `user` field provided by the client (which might not be in\\n`@username:server` form), the login type, and a dictionary of login secrets passed by\\nthe client.\\n\\nIf the authentication is successful, the module must return the user's Matrix ID (e.g. \\n`@alice:example.com`) and optionally a callback to be called with the response to the\\n`/login` request. If the module doesn't wish to return a callback, it must return `None`\\ninstead.\\n\\nIf the authentication is unsuccessful, the module must return `None`.\\n\\nNote that the user is not automatically registered, the `register_user(..)` method of\\nthe [module API](writing_a-module.html) can be used to lazily create users.\\n\\nIf multiple modules register an auth checker for the same login type but with different fields, Synapse\\nwill refuse to start.\\n\\nIf multiple modules register an auth checker for the same login type with the same fields,\\nthen the callbacks will be executed in order, until one returns a Matrix User ID (and optionally a callback). In that case, the return value of that callback will be accepted and subsequent callbacks will not be fired. If every callback returns `None`, then the authentication fails.\\n\\\\} \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations\\n\\n**{#s (a: collect, use) (dt: Account data, Username, password ) (p: Log in)**\\n### `check_3pid_auth`\\n\\n_First introduced in Synapse v1.46.0_\\n\\n```python\\nasync def check_3pid_auth(\\n    medium: str, \\n    address: str,\\n    password: str,\\n) -> Optional[\\n    Tuple[\\n        str, \\n        Optional[Callable[[\\\"synapse.module_api.LoginResponse\\\"], Awaitable[None]]]\\n]\\n```\\n\\nCalled when a user attempts to register or log in with a third party identifier,\\nsuch as email. It is passed the medium (eg. `email`), an address (eg. `jdoe@example.com`)\\nand the user's password.\\n\\nIf the authentication is successful, the module must return the user's Matrix ID (e.g. \\n`@alice:example.com`) and optionally a callback to be called with the response to the `/login` request.\\nIf the module doesn't wish to return a callback, it must return `None` instead.\\n\\nIf the authentication is unsuccessful, the module must return `None`.\\n\\nIf multiple modules implement this callback, they will be considered in order. If a\\ncallback returns `None`, Synapse falls through to the next one. The value of the first\\ncallback that does not return `None` will be used. If this happens, Synapse will not call\\nany of the subsequent implementations of this callback.\\n\\\\} \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:**  Process, Collect, Use\\n**Data Types:** Account information, User ID,  Username, Password\\n**Purposes:**  Security, Account management, Functionality, Log in\\n**Stories:** \\n1. We process account information for security. \\n2. We process account information for functionality.\\n3. We process account information for account management.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n**Data Types:** Account information (Userid, Username, Password)\\n**Purposes:** Security, Login\\n\\n**Stories:**\\n\\n1. We collect account information for security. We use account information for login. \\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n\\n**Data Types:**  Contact Data: Email address,  Account Information: User id,  Usage Data:  Session ID,  Usage Data: Device Information: IP Address, Usage Data:  App Interactions: Pages Visited,  Usage Data: App Interactions: Timestamps,  Social Media: Location: Approximate location,  Social Media: Location: Precise location\\n\\n**Purposes:** Functionality, Accounts, Analytics, Customization, Advertisement, Security, Tracking\\n\\n**Stories:**\\n\\n1. We collect email address, user id, session id for functionality. We use email address, user id for accounts.\\n2. We collect IP address, pages visited, timestamps for analytics. We use IP address, pages visited, timestamps for tracking.\\n3. We collect approximate location, precise location for customization.\\n\\n\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n**Data Types:** Contact Data: Email address,  Account Information: User id,  Usage Data: Device Information: IP Address,  Usage Data: App Interactions: Pages Visited,  Account Information: Messages\\n**Purposes:** Functionality, Customization, Security, Analytics, Tracking\\n**Stories:** \\n\\n1. **We collect email address, user id for functionality.** We use email address, user id for customization, security.\\n2. **We collect IP Address for analytics, tracking.** \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8571\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use, Use \\n**Data Types:** Contact Data: Email address, Contact Data: Address,  Account Information: User id, Usage Data:  Device Information: IP Address, Usage Data: Device Information: Device ID \\n**Purposes:** Functionality, Security, Customization \\n**Stories:** \\n\\n1. We collect  Contact Data: Email address, Contact Data: Address, Account Information: User id for Functionality. We use Contact Data: Email address, Contact Data: Address, Account Information: User id for Security, Customization.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8571\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n\\n**Actions:** Collect, Use\\n**Data Types:**  Contact Data: Email address,  App Interactions: Pages Visited, Usage Data: Device ID, Device Information: IP Address,  Device Information: Browser, Usage Data: Session ID\\n**Purposes:** Functionality, Customization, Security, Analytics, Tracking\\n**Stories:** \\n1. We collect  Contact Data: Email address for Functionality. We use Contact Data: Email address for Customization. \\n2. We collect  App Interactions: Pages Visited for Analytics. We collect  Usage Data: Device ID,  Device Information: IP Address,  Device Information: Browser, Usage Data: Session ID for Tracking.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security', 'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security', 'customization'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security', 'customization'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations for INotificationSubscriber Text\\n\\n**Actions:** Collect, Use \\n\\n**Data Types:** Session ID, Email address,  Username, App Interactions,  Transport, Realm, Category, Priority, Adverb\\n\\n**Purposes:** Functionality, Security, Customization\\n\\n**Stories:**\\n\\n1. **We collect session IDs for authentication.** \\n   * **Rationale:** The text mentions that `sid` (session ID) can be used for authentication and is included in the `matches()` method to determine if a user is interested in a notification.\\n\\n2. **We collect email addresses to send notifications.**\\n   * **Rationale:** The `address` field in the `matches()` method is described as an email address used for sending notifications.\\n\\n3. **We use app interactions to determine notification relevance.**\\n   * **Rationale:** The `event` object passed to the `matches()` method contains information about the event, which likely includes app interactions.  The text states that the implementation can use \\\"any means to determine if a user is interested in hearing about a given event.\\\"\\n\\n4. **We use transport, realm, category, priority, and adverb to customize notification delivery.**\\n   * **Rationale:** The `matches()` method includes parameters like `distributor` (transport), `realm`, `category`, `priority`, and `adverb`, which are used to filter and prioritize notifications based on user preferences. \\n\\n\\n\\nLet me know if you have any further questions.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations for Text 2:\\n\\n**Actions:** Collect, Use\\n**Data Types:** Contact Data: Email address, User ID, Account Information: Username, Session ID, Usage Data: App Interactions: Pages Visited\\n**Purposes:** Functionality, Security, Functionality, Authentication\\n**Stories:**\\n1. We collect session IDs and usernames for authentication. \\n2. We use email addresses for sending notifications.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**\\n\\nHere are the annotations. \\n\\n**Actions: Share, Collect, Use\\n\\n**Data Types: Contact Data, Health Data, Usage Data\\n\\n**Purposes: Security, Analytics, Functionality\\n\\n**Stories: \\n\\n1. We collect contact data for functionality and security\\n\\n2. We use contact data for security, analytics, and functionality.\\n\\n3. We share contact data for security and functionality.\\n\\nPlease note that this text is just a sample of a single user account on Zulip\\n\\n**\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"## Annotations:\\n**Actions:** Share, Collect, Use\\n\\n**Data Types:** Contact Data, Health Data, Usage Data\\n\\n**Purposes:** Account, Security, Analytics, Customization\\n\\n**Story examples:\\n\\n1. We share health data for security\\n\\n2. We share contact data for compliance with regulations\\n3. We collect health data for compliance with regulations\\n4. We use data for security\\n5. We use contact data for security\\n\\n\\n***\\n\\nI'm\\n\\n**\\n\\nThe text provided did not provide sufficient information to annotate further.\\n\\nI need more information to annotate further\\n\\n**\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nThis text lacks sufficient information to annotate further.\\n</R>\\n\\n\\n\\n**\\n\\nPlease provide me with more information to annotate further.\\n**\\n\\n## Annotate further\\n\\n\\nLet me know if you have more details.\\n\\n\\n\\nI need more information to annotate further.\\n\\n\\n**\\n\\nUse case studies to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n**\\n\\nPlease provide me with more information to annotate further.\\n**\\n\\nPlease provide me with more information to annotate further.\\n\\n## Annotate further\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nI need more information to annotate further.\\n\\n\\n**\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n</p>\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n**\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\nPlease provide me with more information to\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annotate further.\\n\\nPlease provide me with more information to annot\\n\\n\\nPlease provide me with\"\n",
      "\n",
      "Annotation F1 Scores:\n",
      "File: Accounts_&_Transactions.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.7333\n",
      "----------------------------------------\n",
      "File: Accounts_&_Transactions.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: CreatingAnewAccount.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.8889\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9630\n",
      "----------------------------------------\n",
      "File: CreatingAnewAccount.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.8889\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9630\n",
      "----------------------------------------\n",
      "File: features.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: features.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.6667\n",
      "----------------------------------------\n",
      "File: add_threePids.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.4333\n",
      "----------------------------------------\n",
      "File: add_threePids.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.4667\n",
      "----------------------------------------\n",
      "File: account-basics.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8333\n",
      "----------------------------------------\n",
      "File: account-basics.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9333\n",
      "----------------------------------------\n",
      "File: signups.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: signups.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.7111\n",
      "----------------------------------------\n",
      "File: userdetails.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: userdetails.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: configurations.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9333\n",
      "----------------------------------------\n",
      "File: configurations.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6111\n",
      "----------------------------------------\n",
      "File: Getting Started.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8667\n",
      "----------------------------------------\n",
      "File: Getting Started.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8667\n",
      "----------------------------------------\n",
      "File: profile-preferences.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: profile-preferences.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: Direct_Messaging_README.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "File: Direct_Messaging_README.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "File: Navigation.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "File: Navigation.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.3333\n",
      "----------------------------------------\n",
      "File: README.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6333\n",
      "----------------------------------------\n",
      "File: README.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6333\n",
      "----------------------------------------\n",
      "File: Architecture.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: Architecture.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.4889\n",
      "----------------------------------------\n",
      "File: data-structure.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.3889\n",
      "----------------------------------------\n",
      "File: data-structure.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.4000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.3000\n",
      "----------------------------------------\n",
      "File: managing-users.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6556\n",
      "----------------------------------------\n",
      "File: managing-users.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6556\n",
      "----------------------------------------\n",
      "File: analyrics-events.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: analyrics-events.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: account_data_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: account_data_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.5556\n",
      "----------------------------------------\n",
      "File: account_validity_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.3333\n",
      "----------------------------------------\n",
      "File: account_validity_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "File: password_auth_provider_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8333\n",
      "----------------------------------------\n",
      "File: password_auth_provider_callbacks.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.3889\n",
      "----------------------------------------\n",
      "File: DatabaseSchema.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: DatabaseSchema.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: INotificationDistributor.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.8571\n",
      "Overall F1 Score: 0.7524\n",
      "----------------------------------------\n",
      "File: INotificationDistributor.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8571\n",
      "Overall F1 Score: 0.8413\n",
      "----------------------------------------\n",
      "File: INotificationSubscriber.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: INotificationSubscriber.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: file.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: file.txt\n",
      "Model: groq:gemma2-9b-it\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "Results saved to annotation_f1_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Dict, List, Set\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class AnnotationEvaluator:\n",
    "    def __init__(self, ontology_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with the privacy ontology.\n",
    "        \"\"\"\n",
    "        with open(ontology_path, 'r') as f:\n",
    "            self.ontology = json.load(f)\n",
    "    \n",
    "    def _normalize_label(self, label: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Normalize label by removing extra whitespace, converting to lowercase,\n",
    "        and splitting comma-separated values.\n",
    "        \"\"\"\n",
    "        # Split by comma, strip whitespace, convert to lowercase\n",
    "        return [\n",
    "            l.strip().lower() \n",
    "            for l in label.split(',') \n",
    "            if l.strip()\n",
    "        ]\n",
    "    \n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Preprocess text by removing content within or after <R> tags.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to preprocess\n",
    "        \n",
    "        Returns:\n",
    "            str: Preprocessed text\n",
    "        \"\"\"\n",
    "        # Find all <R> tags\n",
    "        r_tags = list(re.finditer(r'<R>(.*?)</R>', text, re.DOTALL))\n",
    "        \n",
    "        if not r_tags:\n",
    "            # If no </R> tags, remove everything after a single <R> tag\n",
    "            single_r_match = re.search(r'<R>', text)\n",
    "            if single_r_match:\n",
    "                return text[:single_r_match.start()]\n",
    "            return text\n",
    "        \n",
    "        # Take the content before the first <R> tag\n",
    "        preprocessed = text[:r_tags[0].start()]\n",
    "        \n",
    "        # Return preprocessed text\n",
    "        return preprocessed.strip()\n",
    "    \n",
    "    def _match_labels(self, text: str, category_labels: List[str]) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Find matching labels in the text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to search\n",
    "            category_labels (List[str]): Labels to match\n",
    "        \n",
    "        Returns:\n",
    "            Set[str]: Matched labels\n",
    "        \"\"\"\n",
    "        # Preprocess text to remove R-tag content\n",
    "        preprocessed_text = self._preprocess_text(text)\n",
    "        \n",
    "        # Normalize text\n",
    "        normalized_text = preprocessed_text.lower()\n",
    "        \n",
    "        # Match labels\n",
    "        matched_labels = set()\n",
    "        \n",
    "        for label in category_labels:\n",
    "            # Various matching strategies\n",
    "            # 1. Whole word match\n",
    "            word_pattern = r'\\b' + re.escape(label) + r'\\b'\n",
    "            # 2. Partial match\n",
    "            partial_pattern = re.escape(label)\n",
    "            \n",
    "            if (re.search(word_pattern, normalized_text) or \n",
    "                re.search(partial_pattern, normalized_text)):\n",
    "                matched_labels.add(label)\n",
    "        \n",
    "        return matched_labels\n",
    "    \n",
    "    def calculate_comprehensive_f1_scores(self, ground_truth: Dict, text: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate F1 scores for all categories.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth (Dict): Ground truth annotations\n",
    "            text (str): Text to evaluate\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, float]: F1 scores\n",
    "        \"\"\"\n",
    "        f1_scores = {}\n",
    "        categories = ['actions', 'data_types', 'purposes']\n",
    "        \n",
    "        for category in categories:\n",
    "            # Extract labels from ground truth\n",
    "            gt_labels = self._normalize_label(', '.join(ground_truth.get(category, [])))\n",
    "            \n",
    "            # Find matching labels in text\n",
    "            pred_labels = self._match_labels(text, gt_labels)\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            y_true = [1 if label in gt_labels else 0 for label in gt_labels]\n",
    "            y_pred = [1 if label in pred_labels else 0 for label in gt_labels]\n",
    "            \n",
    "            try:\n",
    "                # Macro average F1 score\n",
    "                f1 = f1_score(y_true, y_pred, average='binary')\n",
    "            except Exception as e:\n",
    "                print(f\"F1 Score calculation error for {category}: {e}\")\n",
    "                f1 = 0\n",
    "            \n",
    "            f1_scores[category] = f1\n",
    "        \n",
    "        # Calculate overall F1 score\n",
    "        f1_scores['Overall'] = sum(f1_scores.values()) / len(f1_scores)\n",
    "        \n",
    "        # Diagnostic print\n",
    "        print(f\"\\nCategory Diagnostics:\")\n",
    "        for category in categories:\n",
    "            print(f\"{category.capitalize()}:\")\n",
    "            print(f\"  Ground Truth Labels: {gt_labels}\")\n",
    "            print(f\"  Matched Labels: {pred_labels}\")\n",
    "            print(f\"  F1 Score: {f1_scores[category]:.4f}\")\n",
    "        \n",
    "        # Print preprocessed text for verification\n",
    "        print(\"\\nPreprocessed Text:\")\n",
    "        print(self._preprocess_text(text))\n",
    "        \n",
    "        return f1_scores\n",
    "\n",
    "def process_annotation_csv(csv_path: str, ontology_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process the annotation CSV and calculate F1 scores.\n",
    "    \"\"\"\n",
    "    # Initialize the evaluator\n",
    "    evaluator = AnnotationEvaluator(ontology_path)\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    # Read the CSV file\n",
    "    with open(csv_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Parse target annotations\n",
    "                ground_truth = json.loads(row['Target Annotations'])\n",
    "                \n",
    "                # Process both model responses\n",
    "                for response_col in ['Model Response 1', 'Model Response 2']:\n",
    "                    # Extract full text\n",
    "                    full_text = row[response_col]\n",
    "                    \n",
    "                    # Calculate F1 scores\n",
    "                    f1_scores = evaluator.calculate_comprehensive_f1_scores(\n",
    "                        ground_truth['metadata'], \n",
    "                        full_text\n",
    "                    )\n",
    "                    \n",
    "                    # Prepare result dictionary\n",
    "                    result = {\n",
    "                        'File': ground_truth.get('file_name', 'Unknown'),\n",
    "                        'Model': row['Model'],\n",
    "                        'Response': response_col,\n",
    "                        'Metrics': f1_scores\n",
    "                    }\n",
    "                    \n",
    "                    results.append(result)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Paths to your files\n",
    "    csv_path = 'LLMAnnotation_groqGemma.csv'\n",
    "    ontology_path = 'privacy_ontology_simple.json'\n",
    "    \n",
    "    # Process the CSV and calculate F1 scores\n",
    "    results = process_annotation_csv(csv_path, ontology_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nAnnotation F1 Scores:\")\n",
    "    for result in results:\n",
    "        print(f\"File: {result['File']}\")\n",
    "        print(f\"Model: {result['Model']}\")\n",
    "        print(f\"Response: {result['Response']}\")\n",
    "        for category, score in result['Metrics'].items():\n",
    "            print(f\"{category} F1 Score: {score:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # Save results to a CSV\n",
    "    if results:\n",
    "        output_keys = ['File', 'Model', 'Response', 'Actions F1', 'Data Types F1', 'Purposes F1', 'Overall F1']\n",
    "        with open('annotation_f1_scores.csv', 'w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=output_keys)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for result in results:\n",
    "                # Prepare row for CSV\n",
    "                csv_row = {\n",
    "                    'File': result['File'],\n",
    "                    'Model': result['Model'],\n",
    "                    'Response': result['Response'],\n",
    "                    'Actions F1': result['Metrics'].get('actions', 0),\n",
    "                    'Data Types F1': result['Metrics'].get('data_types', 0),\n",
    "                    'Purposes F1': result['Metrics'].get('purposes', 0),\n",
    "                    'Overall F1': result['Metrics'].get('Overall', 0)\n",
    "                }\n",
    "                writer.writerow(csv_row)\n",
    "        \n",
    "        print(\"Results saved to annotation_f1_scores.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge prompting llm outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompt_templates\n",
    "\n",
    "# Generate prompts for a CSV file\n",
    "def generate_prompts_from_csv(csv_file_path: str, output_file_path: str):\n",
    "    \"\"\"Reads a CSV file and generates judge prompts for each row, saving them to an output file.\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        prompts = []\n",
    "\n",
    "        for row in reader:\n",
    "            original_prompt = row.get('original_prompt', '')\n",
    "            response_1 = row.get('response_1', '')\n",
    "            response_2 = row.get('response_2', '')\n",
    "\n",
    "            prompt = prompt_templates.create_judge_prompt(original_prompt, response_1, response_2)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "    # Save prompts to output file\n",
    "    with open(output_file_path, mode='w', encoding='utf-8') as outputfile:\n",
    "        outputfile.write(\"\\n\\n---\\n\\n\".join(prompts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
