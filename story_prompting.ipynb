{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import text_processing\n",
    "import secrets \n",
    "\n",
    "from typing import List, Dict\n",
    "import openai  # Assuming OpenAI API, but adaptable to other models\n",
    "\n",
    "# Load text file and taxonomy JSON\n",
    "\n",
    "taxonomy_file_path = 'privacy_ontology.json'  # Replace with actual path\n",
    "example_file_path = 'annotations/Actual_Budget/Accounts_&_Transactions.txt'\n",
    "target_file_path = 'input/Direct_Messaging_README.txt'\n",
    "\n",
    "# Load previously processed example files\n",
    "example_data = text_processing.process_input(example_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant trained to annotate text files with metadata about behaviors, actions, data types, and purposes. For each section in a file, annotate the following:\n",
      "\n",
      "1. Actions: Actions that are performed or expected in this section.\n",
      "2. Data Types: Types of data referenced in this section. Data types may include specific subcategories.\n",
      "3. Purposes: Purposes or intentions related to these actions and data types.\n",
      "\n",
      "After providing your annotations, explain your rationale for these annotations. Place a <R> tag between your annotations and your rationale.\n",
      "\n",
      "Use only the categories listed below when annotating the sections:\n",
      "\n",
      "Actions:\n",
      "sub, Collect, Process, Share\n",
      "\n",
      "Data Types:\n",
      "sub:\n",
      "  anonymize:\n",
      "  aggregate:\n",
      "Patterns:\n",
      "  Minimal-Information-Asymmetry, Awareness Feed, User data confinement pattern\n",
      "Synonyms:\n",
      "  Personally Identifiable Information, PII, Personal Information, Your Data, Your Information\n",
      "Contact Data:\n",
      "  Phone Number:\n",
      "    Synonyms:\n",
      "      mobile number\n",
      "  Email address:\n",
      "  User ID:\n",
      "  Login Information:\n",
      "  Job Title:\n",
      "  Contact List:\n",
      "  Company Name:\n",
      "  Address:\n",
      "    Synonyms:\n",
      "      postal addess, mailing address, shipping address\n",
      "  Name:\n",
      "    First Name:\n",
      "    Last Name:\n",
      "  Date of Birth:\n",
      "    Synonyms:\n",
      "      birthday\n",
      "  Image (Photos, Pictures, Video):\n",
      "    Synonyms:\n",
      "      photo, picture, video\n",
      "  Government ID:\n",
      "    Synonyms:\n",
      "      National identification number\n",
      "    Driver's License:\n",
      "    Passport:\n",
      "    Social Security Number:\n",
      "    Tax ID Number:\n",
      "    License Plate Number:\n",
      "  Biographical Data:\n",
      "    CV:\n",
      "      Synonyms:\n",
      "        Curriculum Vitae\n",
      "    Education:\n",
      "    Employment:\n",
      "Health Data:\n",
      "  Synonyms:\n",
      "    medical information\n",
      "  Physical activity:\n",
      "Social Media:\n",
      "Location:\n",
      "  Patterns:\n",
      "    Location Granularity\n",
      "  Approximate location:\n",
      "  Precise location:\n",
      "  GPS:\n",
      "  Localisation:\n",
      "  Address:\n",
      "Financial:\n",
      "  Synonyms:\n",
      "    economic, spending, commercial information\n",
      "  Orders:\n",
      "  Payment Card:\n",
      "  Payment History:\n",
      "  Purchase History:\n",
      "    Synonyms:\n",
      "      order history\n",
      "  Carts:\n",
      "  Order:\n",
      "  Card Data:\n",
      "  Bank Account:\n",
      "  Credit Score:\n",
      "  Income Information:\n",
      "  assets:\n",
      "    vehicle:\n",
      "    Insurance:\n",
      "Usage Data:\n",
      "  App Interactions:\n",
      "    Patterns:\n",
      "      Use-of-dummies\n",
      "    Pages Visited:\n",
      "      Synonyms:\n",
      "        app activity\n",
      "    Timestamps:\n",
      "    Interaction with Ads:\n",
      "    Content Viewing Order:\n",
      "    User Engagement:\n",
      "    Content Moderation:\n",
      "    Clicks:\n",
      "    Transportation Data:\n",
      "  Device Information:\n",
      "    Synonyms:\n",
      "      Log Data, App data\n",
      "    IP Address:\n",
      "    Identifier:\n",
      "      Synonyms:\n",
      "        User IDs\n",
      "      Device ID:\n",
      "        Synonyms:\n",
      "          device identifier\n",
      "      Advertisement ID:\n",
      "        Synonyms:\n",
      "          Advertisement identifier, ad identifiers\n",
      "      Browser:\n",
      "      Operating System:\n",
      "        Synonyms:\n",
      "          OS\n",
      "      Device Settings:\n",
      "      Make:\n",
      "      Model:\n",
      "      Network Information (Mobile Network):\n",
      "      Wi-Fi Access:\n",
      "      Diagnostics:\n",
      "      Sensor Data:\n",
      "      Audio:\n",
      "      Browsing history:\n",
      "Tracking:\n",
      "  Cookies:\n",
      "    Patterns:\n",
      "      Protection-against-tracking\n",
      "  Web Beacons/Pixels:\n",
      "  Tags:\n",
      "Account Information:\n",
      "  Patterns:\n",
      "    Whoâ€™s Listening, Unusual-activities\n",
      "  Synonyms:\n",
      "    account credentials\n",
      "  User id:\n",
      "  Username:\n",
      "  Password:\n",
      "    Patterns:\n",
      "      Informed Secure Passwords\n",
      "  Files:\n",
      "  Account Balance:\n",
      "  Messages:\n",
      "  Friends:\n",
      "\n",
      "Purposes:\n",
      "Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts, Requirements, Save, Identification\n",
      "\n",
      "Here is an example of annotated sections:\n",
      "\n",
      "--- File: Accounts_&_Transactions.txt ---\n",
      "Full Cleaned Text:\n",
      "Using Actual\n",
      "Accounts & Transactions\n",
      "\n",
      "Overview\n",
      "    You can add as many accounts as you like. Adding all of your accounts (including things like mortgages) is a nice way to get an overview of all your finances.\n",
      "\n",
      "Off-budget accounts\n",
      "â€‹\n",
      "\n",
      "Actual makes a distinction between accounts being\n",
      "for\n",
      "budget or\n",
      "off\n",
      "budget. Off budget accounts don't effect the budget and are meant to track stuff like investments and mortgages. Transactions in off budget accounts can't be categorized; they simply track balances over time.\n",
      "\n",
      "For budget\n",
      "accounts affect the budget, and transactions can be categorized. These are accounts where you want to track cash flow and use the budget, like checking accounts and credit cards.\n",
      "\n",
      "Depending on your usage, savings accounts can either be on or off the budget. If you're not sure, we recommend keeping it on budget at the start.\n",
      "\n",
      "Adding a new account\n",
      "â€‹\n",
      "\n",
      "You can add an account to your budget at any time, however when you first install Actual you can use the\n",
      "Add Account\n",
      "button in the middle of the screen.\n",
      "\n",
      "You can also add an account using the\n",
      "+ Add account\n",
      "button in the sidebar.\n",
      "\n",
      "Two successive screens will appear with boxes asking you to fill in a few options\n",
      "\n",
      "Create a Local Account or Link to GoCardless (See\n",
      "Connecting Your Bank\n",
      ")\n",
      "Give your account a name\n",
      "Is the account on or off budget\n",
      "The current account balance\n",
      "\n",
      "Off budget means that the balance is not reflected when you assign money to categories in your budget register\n",
      "\n",
      "Here you can see how that looks when the options are completed.\n",
      "\n",
      "If you select the Off Budget checkbox then change the account type the Off Budget checkbox will reset and will need to be re-selected each time the account type is changed\n",
      "\n",
      "You can now see the account in the sidebar of Actual\n",
      "\n",
      "Closing or deleting an account\n",
      "â€‹\n",
      "\n",
      "Navigate to the account by clicking on it in the sidebar\n",
      "Click on the 3 dots (top right of the transactions list) to show the actions menu\n",
      "Select\n",
      "Close Account\n",
      "You need to select another account to transfer the existing balance to. Choose the account that you have moved funds to.\n",
      "Press\n",
      "Close Account\n",
      "\n",
      "You can still access this account under\n",
      "Closed Accounts\n",
      "in the sidebar, and even reopen it from the same actions menu.\n",
      "\n",
      "If you want to delete an account\n",
      "even if it has existing balances, in the popup after selecting\n",
      "Close Account\n",
      ", click the\n",
      "force close\n",
      "at the bottom.\n",
      "\n",
      "Renaming an existing account\n",
      "â€‹\n",
      "\n",
      "Click the account name in the sidebar of Actual\n",
      "\n",
      "Hovering your cursor close to the account name at the top will reveal two icons.\n",
      "The page icon allows you to write a note about this account, and the pencil icon allows you to rename the account.\n",
      "\n",
      "After editing a note for the account or its name, hit 'Enter' to save your changes.\n",
      "\n",
      "Off-budget accounts\n",
      "Adding a new account\n",
      "Closing or deleting an account\n",
      "Renaming an existing account \\s\n",
      "\n",
      "--- New File Text ---\n",
      "<PI>\n",
      "Direct Messaging with LibreEHR and EMR Direct phiMail(R)\n",
      "Version 1.3, 19 Jul 2014\n",
      "\n",
      "A. Purpose: To provide a secure method from within LibreEHR for sending/receiving \n",
      "protected health information to/from another Direct address using the Direct Project \n",
      "messaging standard, as a step toward the goal of satisfying the three MU2 criteria \n",
      "requiring the use of Direct messaging.  (For general information about Direct messaging, \n",
      "see http://www.emrdirect.com/about-directed-exchange-and-secure-direct-messaging.html)\n",
      "\n",
      "B. IMPORTANT:  Please be aware of the following limitations when using the LibreEHR \n",
      "Direct Messaging features with PHI in a production environment:\n",
      "\n",
      "1. the current code only supports a single shared \"group\" Direct Address for each LibreEHR \n",
      "installation. Note that this model is fully compliant with the Direct Project \n",
      "requirements for Direct messaging, but we may add additional models in the future \n",
      "should we determine that doing so would provide a higher degree of interoperability for \n",
      "LibreEHR users.\n",
      "\n",
      "2. the current code only sends the CCR or CCD XML data that is already available in LibreEHR; \n",
      "these files as currently generated by existing LibreEHR code do not meet the requirements \n",
      "of the MU2 criteria, and the current CCD files do not pass strict CDA validation tests.\n",
      "\n",
      "C. Problems Solved:\n",
      "\n",
      "1. Patient-initiated transmission of clinical data from the Report section of the Patient \n",
      "Portal interface.\n",
      "\n",
      "2. Provider-initiated transmission of clinical data from the Report section of the Patient \n",
      "pane in the main LibreEHR interface.\n",
      "\n",
      "3. Log all data transmissions including date/time, patient, and whether transmission \n",
      "was initiated by the patient through the Patient Portal or by an LibreEHR user through the \n",
      "main interface.\n",
      "\n",
      "4. Receive Direct messages from other sources.\n",
      "\n",
      "D. How it Works:\n",
      "Once configured, LibreEHR will interface with a phiMail Direct messaging server to complete the\n",
      "required message transactions. The phiMail platform is described on the EMR Direct website, \n",
      "http://www.emrdirect.com and http://www.emrdirect.com/phimail-faq.html.\n",
      "\n",
      "E. What you need before enabling Direct Messaging in LibreEHR:\n",
      "\n",
      "1. Test Mode: Developers may request a complimentary test address at \n",
      "https://www.emrdirect.com/subscribe-developer  \n",
      "Access to a sandbox server is available for testing and development purposes.\n",
      "\n",
      "2. Production Mode: Healthcare provider users should begin by signing up for a production \n",
      "Direct messaging account with EMR Direct by registering at https://www.emrdirect.com/subscribe\n",
      "\n",
      "Subscribers will receive the username, password, and server address information with which to \n",
      "configure LibreEHR.  \n",
      "\n",
      "F. How to enable the Direct Messaging Features in LibreEHR:\n",
      "Setup of phiMail Direct messaging Service is done in the Administration::Globals::Connectors \n",
      "tab\n",
      "\n",
      "1. Check the \"Enable phiMail Direct Messaging Service\" checkbox.\n",
      "\n",
      "2. Enter the Server Address, Username, and Password provided to you. The server address\n",
      "will be of the form \"ssl://servername.example.com:32541\" - replace the hostname and port\n",
      "with the values provided to you by EMR Direct. The Username is your Direct Address. Do not \n",
      "enter the server URL into your browser address bar, as this will not work.\n",
      "\n",
      "3. Specify the LibreEHR user who will receive notification of new incoming Direct messages. \n",
      "Enter their LibreEHR username in the notification user field.\n",
      "\n",
      "4. Specify the interval for automatic message checking; we suggest 5 or 10 minutes as a\n",
      "starting point, but installations processing a large number of Direct messages may want a \n",
      "shorter interval. To disable automatic message checking through LibreEHR's background service\n",
      "manager, set the interval to 0 (zero). Disabling automatic checking would be appropriate \n",
      "if message checking is managed through another mechanism, such as a system cron job.\n",
      "\n",
      "5. Optionally check \"phiMail Allow CCD Send\" and/or \"phiMail Allow CCR Send\" to enable\n",
      "the Transmit feature for these data types. If you do not select at least one of these,\n",
      "LibreEHR will operate in a receive-only mode.\n",
      "\n",
      "6. Click the \"Save\" button.\n",
      "\n",
      "7. Confirm that a valid Notification Email Address is set in the Administration::\n",
      "Globals::Notifications tab to receive error notifications from the Direct Messaging service.\n",
      "\n",
      "8. Install the EMR Direct trust anchor certificate.  \n",
      "\n",
      "Note: This is *not* your Direct certificate; it is the trust anchor for the SSL \n",
      "certificate issued to our servers, and is used only to validate the SSL certificate \n",
      "presented by the phiMail server on the other side of LibreEHR's connection.  Your Direct private\n",
      "key and certificate are managed by the phiMail Server and are not installed in LibreEHR.\n",
      "Your Direct certificate is made availabe for your review by EMR Direct, but you will not\n",
      "need to install it anywhere.\n",
      "\n",
      "For added security, the trust anchor for the phiMail Server should be installed in the LibreEHR \n",
      "installation tree at:\n",
      "\n",
      "[installation_root]/sites/[site_id]/documents/phimail_server_pem/phimail_server.pem\n",
      "\n",
      "This phimail_server_pem directory and its contents should be readable by the the \n",
      "webserver process, but only writable by trusted local users. The certificate file \n",
      "itself must be PEM encoded. You can identify a PEM encoded certificate file because \n",
      "it begins with the text \"-----BEGIN CERTIFICATE-----\". Although LibreEHR will connect \n",
      "to phiMail servers without installing this certificate, this is a required configuration \n",
      "step for all production  accounts to ensure that you are connecting to the correct \n",
      "server. You can obtain the correct certificate at the following URLs:\n",
      "\n",
      "  a. Test accounts: http://certs.emrdirect.com/EMRDirectTestCA.crt\n",
      "     Important: Don't forget to rename the file to phimail_server.pem and install it\n",
      "     in the correct directory.\n",
      "\n",
      "  b. Production accounts: https://www.phicert.com/certs/phiCertDirectRootCA.crt\n",
      "     Important: The production root must be converted to PEM format as follows:\n",
      "     $ openssl x509 -in phiCertDirectRootCA.crt -inform DER -out phimail_server.pem\n",
      "     Don't forget to install phimail_server.pem in the correct directory. As an added\n",
      "     security measure, please call us to confirm the thumbprint on this certificate.\n",
      "\n",
      "G. Debugging background connections to the server.\n",
      "\n",
      "You may review the connection activity to the server by Selecting Administration::Other::Logs,\n",
      "selecting \"direct-message\" in the \"Name of events:\" drop-down menu, and clicking \"[Refresh]\".\n",
      "If the background service is succesfully connecting, you will see \"message check completed\"\n",
      "events in the log as well as any message related entries (see below for instructions to\n",
      "view more detailed message related status information). If you see no entries, make sure that\n",
      "the background service is enabled (See F.4 above). If you see \"could not connect to server\"\n",
      "entries, each entry will also contain an error code:\n",
      "\n",
      "  C1: phiMail is disabled in the global configuration. Fix: enable.\n",
      "  C2: the phiMail server URL entered in the global configuration is invalid. Fix: Confirm\n",
      "      the URL has been entered correctly. It should be of the form \n",
      "      \"ssl://server.example.com:32541\".\n",
      "  C3: unable to create stream context. Fix: Usually this is because the server certificate \n",
      "      file installed in F.8 above is not the correct certificate or is in the wrong format.\n",
      "  C4: failed to open connection. Fix: Confirm you Internet service and local DNS servers are\n",
      "      online and your firewall is not blocking connections to the phiMail Server.\n",
      "\n",
      "H. Checking the status and history of the Direct Messaging Service in LibreEHR:\n",
      "Administrators may view the status of the service by Selecting Reports::Services::Background \n",
      "Services from the main LibreEHR left navigation bar. The \"View Log\" link on this page or \n",
      "Reports::Services::Direct Message Log will open the messaging history log showing each message \n",
      "sent or received and the current status of that message (Received, Sent, Delivery Confirmed, \n",
      "or Failed).\n",
      "\n",
      "I. Note of message status messages: Receiving message status updates requires that Direct message\n",
      "checking be enabled. When receiving messages, the phiMail back-end is fully compliant with the \n",
      "Direct messaging protocols to notify the sender and provide final delivery confirmation, but \n",
      "please note that  many other Direct providers do not yet support these features. If a message \n",
      "is sent to a recipient using one of these other systems, LibreEHR probably won't ever receive a \n",
      "final delivery confirmation for that message.\n",
      "\n",
      "J. How to use the Direct Messaging Features in LibreEHR:\n",
      "\n",
      "1. Sending:\n",
      "When the phiMail Direct Messaging service is enabled, an additional \"Transmit\" button will\n",
      "appear in the Continuity of Care Record (CCR) and/or Continuity of Care Document (CCD) block \n",
      "of the Reports section in both the Patient Portal and the Patient pane of the main provider \n",
      "interface. \n",
      "\n",
      "To transmit a CCR or CCD, first click the \"Transmit\" button. This will open a small dialog \n",
      "immediately below the button with a form field to enter the intended recipient's Direct Address. \n",
      "Clicking \"Transmit\" again will hide the dialog.\n",
      "\n",
      "A Direct Address should have the same form as a regular email address, e.g. \n",
      "jonesclinic@direct.example.com. Enter the address in the field and click the \"Send\" button \n",
      "immediately to the right of the field. Only a single recipient may be specified in the field.\n",
      "The Send button will be temporarily disabled while LibreEHR is communicating with the phiMail \n",
      "server. This will only work for properly-configured Direct addresses. Attempts to send to a \n",
      "regular email address or Direct address outside of our test mode \"trust sandbox\" will fail\n",
      "during testing. Production accounts have wide interoperability with other Direct service\n",
      "providers. Should you encounter a trust community with which LibreEHR does not interoperate,\n",
      "please let us know at support@emrdirect.com.\n",
      "\n",
      "LibreEHR will then display a status message immediately below the Address field, the \n",
      "success or failure of the message transmission, or an error message. If the message is\n",
      "successfully submitted to the server, the Address field will be cleared to prevent accidental\n",
      "re-transmission. If multiple recipients are required, the next recipient can now be entered.\n",
      "\n",
      "If you receive an error message, it will be followed by an error code. For a discussion\n",
      "of error codes beginning with the letter \"C\" please see section G above. Error codes\n",
      "beginning with \"EC\" are listed here:\n",
      "\n",
      "  EC 1: phiMail disabled in global configuration. Fix: enable.\n",
      "  EC 4: authentication failure. Fix: The Username and Password entered in the\n",
      "        global configuration must be corrected.\n",
      "  EC 5: request to add text failed. Fix: Confirm total message length < 5MB.\n",
      "  EC 6: problem sending the text. Fix: Confirm your local network connectivity is stable.\n",
      "  EC 7: request to add clinical document failed. Fix: see EC 5.\n",
      "  EC 8: problem sending the clinical document. Fix: see EC 6.\n",
      "\n",
      "2. Receiving:\n",
      "When the phiMail Direct Messaging service is enabled, and message checking is enabled either \n",
      "through the background services manager of another mechanism, LibreEHR will automatically process \n",
      "message status updates and new messages. Status updates will be reflected immediately in the \n",
      "Direct Messaging log. Additionally, if a \"Failed\" notification is received for a previously sent \n",
      "message, a regular email message will be generated to the Notification Email Address specified \n",
      "in the Notifications tab of the Global Settings panel (accessed by selecting Administration::\n",
      "Globals from the main left navigation menu).\n",
      "\n",
      "New Direct messages will be processed as follows. A new \"Patient Note\" will be generated and \n",
      "sent to the phiMail notification user specified in the Connectors tab of the Global settings. \n",
      "The patient note will contain information about the message, including any text at the beginning \n",
      "of the message from the sender. Any attachments (and any non-text content) will be automatically \n",
      "converted to separate LibreEHR Documents, which will be referenced in the new Patient Note.  \n",
      "The Documents and the Patient Note are initially created without an assigned patient. \n",
      "\n",
      "At this time, the envisioned workflow is that the notification user will review the message text\n",
      "and any included Documents to determine which patient the content belongs to and will then set the \n",
      "patient using the existing Patient Note interface for choosing a patient. Once the patient is sent, \n",
      "the Patient Note can be forwarded to another provider or staff member as appropriate using the \n",
      "existing forwarding mechanism for Patient Notes. The unassigned Documents can be viewed by Selecting \n",
      "Miscellaneous::New Documents from the main left navigation menu, which opens a Documents list. Once \n",
      "the specified document is opened, the user can optionally categorize the document and, when \n",
      "appropriate, assign the document to a specific patient using the \"Move to Patient #\" feature in the \n",
      "Documents interface.\n",
      "\n",
      "\n",
      "Trademark Notice: phiMail is a registered trademark of EMR Direct.\n",
      "\n",
      "Copyright (c) 2013-2014 EMR Direct.\n",
      "\n",
      "\n",
      "\n",
      "Annotate the sections of the above text with actions, data types, and purposes as demonstrated, using only the categories from the list provided. For each section, provide your annotations followed by your rationale, and place a <R> tag between your annotations and your rationale.\n",
      "\n",
      "\n",
      "Token Count: 4161 tokens\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, List, Union\n",
    "import tiktoken  # Library for token counting with OpenAI models\n",
    "import prompt_templates\n",
    "\n",
    "# Load the privacy ontology\n",
    "ontology_path = \"privacy_ontology.json\"\n",
    "privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "# Load one processed example file for demonstration\n",
    "example_file = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "\n",
    "# Define target text to be annotated (for demonstration) & Load annotated version \n",
    "target_file_annotations = text_processing.process_input(target_file_path)\n",
    "new_text_to_annotate = open(target_file_path).read()\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_example = prompt_templates.create_annotation_prompt(example_file, new_text_to_annotate, privacy_ontology)\n",
    "\n",
    "# Print the prompt to review it\n",
    "print(prompt_example)\n",
    "print(f\"\\nToken Count: {prompt_templates.count_tokens(prompt_example)} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating with LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: openai:gpt-4o-mini - Completed a run\n",
      "Model: openai:gpt-4o-mini - Completed a run\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import model_routing\n",
    "import text_processing\n",
    "import prompt_templates\n",
    "from getpass import getpass\n",
    "\n",
    "# Set API Key\n",
    "if os.environ['OPENAI_API_KEY'] is None : os.environ['OPENAI_API_KEY'] = getpass('Enter your OPENAI API key: ')\n",
    "\n",
    "def save_results_to_csv(models, prompts, target_annotations, model_responses, output_file):\n",
    "    \"\"\"\n",
    "    Save the model outputs, prompts, and file annotations to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model names.\n",
    "        prompts (list): List of prompt strings.\n",
    "        target_annotations (dict): Processed annotations for the target file.\n",
    "        model_responses (dict): Dictionary of model responses for each prompt.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Open the output CSV file\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Determine the number of model responses\n",
    "        num_runs = max(len(responses) for model in models for responses in model_responses[model])\n",
    "        \n",
    "        # Prepare the CSV header\n",
    "        fieldnames = ['Prompt', 'Model', 'Target Annotations'] + [f'Model Response {i + 1}' for i in range(num_runs)]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write data for each prompt\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            for model in models:\n",
    "                row = {\n",
    "                    'Prompt': prompt,\n",
    "                    'Model': model,\n",
    "                    'Target Annotations': json.dumps(target_annotations, ensure_ascii=False),\n",
    "                }\n",
    "\n",
    "                # Write the responses for the current model and prompt\n",
    "                for j in range(num_runs):\n",
    "                    # Access the model's responses\n",
    "                    response = model_responses[model][i][j] if j < len(model_responses[model][i]) else 'No Response'\n",
    "                    row[f'Model Response {j + 1}'] = json.dumps(response, ensure_ascii=False) if response != 'No Response' else 'No Response'\n",
    "                \n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "def example_usage(target_file_path, example_file_path, ontology_path, output_csv):\n",
    "    \"\"\"\n",
    "    Run the annotation process and save results to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        target_file_path (str): Path to the target file for annotation.\n",
    "        example_file_path (str): Path to an example processed file.\n",
    "        ontology_path (str): Path to the privacy ontology file.\n",
    "        output_csv (str): Path to save the CSV results.\n",
    "    \"\"\"\n",
    "    # Load the privacy ontology\n",
    "    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "    # Process target file and example file\n",
    "    target_file_annotations = text_processing.process_input(target_file_path)[0]\n",
    "    example_file_annotations = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "    # Read the raw text of the target file\n",
    "    with open(target_file_path, 'r', encoding='utf-8') as file:\n",
    "        new_text_to_annotate = file.read()\n",
    "\n",
    "    # Generate a prompt\n",
    "    prompt_example = prompt_templates.create_annotation_prompt(\n",
    "        example_file_annotations, \n",
    "        new_text_to_annotate, \n",
    "        privacy_ontology\n",
    "    )\n",
    "\n",
    "    # List of models to test\n",
    "    test_models = [\n",
    "        'openai:gpt-4o-mini',\n",
    "    ]\n",
    "\n",
    "    # List of prompts to test\n",
    "    test_prompts = [prompt_example]\n",
    "        \n",
    "    try:\n",
    "        # Get model responses\n",
    "        model_responses = model_routing.run_multi_model_prompts(\n",
    "            models=test_models, \n",
    "            prompts=test_prompts, \n",
    "            num_runs=2  # Number of runs per model\n",
    "        )\n",
    "\n",
    "        # Save results to CSV with added annotation data\n",
    "        save_results_to_csv(\n",
    "            models=test_models,\n",
    "            prompts=test_prompts,\n",
    "            target_annotations=target_file_annotations,\n",
    "            model_responses=model_responses,\n",
    "            output_file=output_csv\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "taxonomy_file_path = 'privacy_ontology.json'  # Replace with actual path\n",
    "example_file_path = 'annotations/Actual_Budget/Accounts_&_Transactions.txt'\n",
    "target_file_path = 'input/Direct_Messaging_README.txt'\n",
    "\n",
    "output_csv = 'LLMAnnotation_12_5_24.csv'\n",
    "\n",
    "# Run the updated example\n",
    "example_usage(target_file_path, example_file_path, ontology_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import model_routing\\nimport secrets_file\\nimport os\\nimport csv\\nfrom getpass import getpass\\nimport text_processing  # Assuming this includes your text annotation processing functions\\nimport prompt_templates\\n\\n# Set API Key\\nos.environ[\\'OPENAI_API_KEY\\'] = getpass(\\'Enter your OPENAI API key: \\')\\n\\nimport json\\n\\ndef save_results_to_csv(models, prompts, target_annotations, model_responses, output_file):\\n    \"\"\"\\n    Save the model outputs, prompts, and file annotations to a CSV file.\\n\\n    Args:\\n        models (list): List of model names.\\n        prompts (list): List of prompt strings.\\n        target_annotations (dict): Processed annotations for the target file.\\n        model_responses (dict): Dictionary of model responses for each prompt.\\n        output_file (str): Path to the output CSV file.\\n    \"\"\"\\n    with open(output_file, \\'w\\', newline=\\'\\', encoding=\\'utf-8\\') as csvfile:\\n        fieldnames = [\\'Prompt\\', \\'Model\\', \\'Target Annotations\\'] + [f\\'Model Response {i + 1}\\' for i in range(len(models))]\\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\\n\\n        writer.writeheader()\\n        for i, prompt in enumerate(prompts):\\n            for model in models:\\n                row = {\\n                    \\'Prompt\\': prompt,\\n                    \\'Model\\': model,\\n                    \\'Target Annotations\\': json.dumps(target_annotations),\\n                }\\n                row.update({f\\'Model Response {j + 1}\\': model_responses[model][i][j] for j in range(len(model_responses[model][i]))})\\n                writer.writerow(row)\\n\\ndef example_usage(target_file_path, example_file_path, ontology_path, output_file):\\n    \"\"\"\\n    Run the annotation process and save results to a JSON file.\\n    \\n    Args:\\n        target_file_path (str): Path to the target file for annotation.\\n        example_file_path (str): Path to an example processed file.\\n        ontology_path (str): Path to the privacy ontology file.\\n        output_file (str): Path to save the results JSON file.\\n    \"\"\"\\n    # Load the privacy ontology\\n    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\\n\\n    # Process target file and example file\\n    target_file_annotations = text_processing.process_input(target_file_path)[0]\\n    example_file_annotations = text_processing.process_input(example_file_path)[0]\\n\\n    # Read the raw text of the target file\\n    with open(target_file_path, \\'r\\', encoding=\\'utf-8\\') as file:\\n        new_text_to_annotate = file.read()\\n\\n    # Generate a prompt\\n    prompt_example = prompt_templates.create_annotation_prompt(\\n        example_file_annotations, \\n        new_text_to_annotate, \\n        privacy_ontology\\n    )\\n\\n    # List of models to test\\n    test_models = [\\n        \\'openai:gpt-4o-mini\\',\\n    ]\\n\\n    # List of prompts to test\\n    test_prompts = [prompt_example]\\n\\n    try:\\n        model_responses = model_routing.run_multi_model_prompts(\\n            models=test_models, \\n            prompts=test_prompts, \\n            num_runs=2,  # Number of runs per model\\n            output_file=output_csv  # We\\'ll handle the output directly\\n        )\\n\\n        # Include the processed target file annotations\\n        results = {\\n            \\'target_annotations\\': target_file_annotations,\\n            \\'model_responses\\': model_responses\\n        }\\n\\n        # Save the results to a JSON file\\n        with open(output_file, \\'w\\', encoding=\\'utf-8\\') as f:\\n            json.dump(results, f, indent=2)\\n\\n        print(f\"Results saved to: {output_file}\")\\n\\n    except Exception as e:\\n        print(f\"An error occurred: {e}\")\\n        import traceback\\n        traceback.print_exc()\\n\\n#Define paths\\ntarget_file_path = \\'path/to/target_file.txt\\'\\nexample_file_path = \\'path/to/example_file.txt\\'\\nontology_path = \\'privacy_ontology.json\\'\\noutput_csv = \\'model_comparison.csv\\'\\n\\noutput_csv = \\'LLMAnnotation_12_5_24.csv\\'\\n\\n\\n# Run the updated example\\nexample_usage(target_file_path, example_file_path, ontology_path, output_csv)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import model_routing\n",
    "import secrets_file\n",
    "import os\n",
    "import csv\n",
    "from getpass import getpass\n",
    "import text_processing  # Assuming this includes your text annotation processing functions\n",
    "import prompt_templates\n",
    "\n",
    "# Set API Key\n",
    "os.environ['OPENAI_API_KEY'] = getpass('Enter your OPENAI API key: ')\n",
    "\n",
    "import json\n",
    "\n",
    "def save_results_to_csv(models, prompts, target_annotations, model_responses, output_file):\n",
    "    \"\"\"\n",
    "    Save the model outputs, prompts, and file annotations to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of model names.\n",
    "        prompts (list): List of prompt strings.\n",
    "        target_annotations (dict): Processed annotations for the target file.\n",
    "        model_responses (dict): Dictionary of model responses for each prompt.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Prompt', 'Model', 'Target Annotations'] + [f'Model Response {i + 1}' for i in range(len(models))]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            for model in models:\n",
    "                row = {\n",
    "                    'Prompt': prompt,\n",
    "                    'Model': model,\n",
    "                    'Target Annotations': json.dumps(target_annotations),\n",
    "                }\n",
    "                row.update({f'Model Response {j + 1}': model_responses[model][i][j] for j in range(len(model_responses[model][i]))})\n",
    "                writer.writerow(row)\n",
    "\n",
    "def example_usage(target_file_path, example_file_path, ontology_path, output_file):\n",
    "    \"\"\"\n",
    "    Run the annotation process and save results to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        target_file_path (str): Path to the target file for annotation.\n",
    "        example_file_path (str): Path to an example processed file.\n",
    "        ontology_path (str): Path to the privacy ontology file.\n",
    "        output_file (str): Path to save the results JSON file.\n",
    "    \"\"\"\n",
    "    # Load the privacy ontology\n",
    "    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "    # Process target file and example file\n",
    "    target_file_annotations = text_processing.process_input(target_file_path)[0]\n",
    "    example_file_annotations = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "    # Read the raw text of the target file\n",
    "    with open(target_file_path, 'r', encoding='utf-8') as file:\n",
    "        new_text_to_annotate = file.read()\n",
    "\n",
    "    # Generate a prompt\n",
    "    prompt_example = prompt_templates.create_annotation_prompt(\n",
    "        example_file_annotations, \n",
    "        new_text_to_annotate, \n",
    "        privacy_ontology\n",
    "    )\n",
    "\n",
    "    # List of models to test\n",
    "    test_models = [\n",
    "        'openai:gpt-4o-mini',\n",
    "    ]\n",
    "\n",
    "    # List of prompts to test\n",
    "    test_prompts = [prompt_example]\n",
    "\n",
    "    try:\n",
    "        model_responses = model_routing.run_multi_model_prompts(\n",
    "            models=test_models, \n",
    "            prompts=test_prompts, \n",
    "            num_runs=2,  # Number of runs per model\n",
    "            output_file=output_csv  # We'll handle the output directly\n",
    "        )\n",
    "\n",
    "        # Include the processed target file annotations\n",
    "        results = {\n",
    "            'target_annotations': target_file_annotations,\n",
    "            'model_responses': model_responses\n",
    "        }\n",
    "\n",
    "        # Save the results to a JSON file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "''''''#Define paths\n",
    "target_file_path = 'path/to/target_file.txt'\n",
    "example_file_path = 'path/to/example_file.txt'\n",
    "ontology_path = 'privacy_ontology.json'\n",
    "output_csv = 'model_comparison.csv'\n",
    "''''''\n",
    "output_csv = 'LLMAnnotation_12_5_24.csv'\n",
    "\n",
    "\n",
    "# Run the updated example\n",
    "example_usage(target_file_path, example_file_path, ontology_path, output_csv)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
