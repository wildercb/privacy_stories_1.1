{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import text_processing\n",
    "import secrets \n",
    "\n",
    "from typing import List, Dict\n",
    "import openai  # Assuming OpenAI API, but adaptable to other models\n",
    "\n",
    "# Load text file and taxonomy JSON\n",
    "\n",
    "taxonomy_file_path = 'privacy_ontology_simple.json'  # Replace with actual path\n",
    "example_file_path = 'annotations/Actual_Budget/Accounts_&_Transactions.txt'\n",
    "target_file_path = 'input/lh-ehr/Direct_Messaging_README.txt'\n",
    "\n",
    "# Load previously processed example files\n",
    "example_data = text_processing.process_input(example_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a privacy expert annotator tasked with annotating text files with metadata about privacy behaviors and stories. For the given text, annotate the following:\n",
      "\n",
      "1. Actions: Actions performed or expected in the text.\n",
      "2. Data Types: Types of data referenced in the text. Data types may include specific subcategories.\n",
      "3. Purposes: Intentions or purposes related to the actions and data types.\n",
      "4. Stories: Concise stories that describe how actions, data types, and purposes interact in context.\n",
      "\n",
      "After providing your annotations, explain your rationale for these annotations. Place <R> tag between your annotations and your rationale.\n",
      "\n",
      "Use only the categories listed below when annotating:\n",
      "\n",
      "Actions:\n",
      "Collect, Use, Share\n",
      "\n",
      "Data Types:\n",
      "Contact Data:\n",
      "  Phone Number:\n",
      "  Email address:\n",
      "  User ID:\n",
      "  Job Title:\n",
      "  Company:\n",
      "  Address:\n",
      "  Name:\n",
      "  Date of Birth:\n",
      "  Image:\n",
      "  Government ID:\n",
      "  Biographical Data:\n",
      "    CV:\n",
      "    Education:\n",
      "    Employment:\n",
      "Health Data:\n",
      "  Physical activity:\n",
      "Social Media:\n",
      "Location:\n",
      "  Approximate location:\n",
      "  Precise location:\n",
      "Financial:\n",
      "  Orders:\n",
      "  Payment History:\n",
      "  Purchase History:\n",
      "  Order:\n",
      "  Card Data:\n",
      "  Bank Account:\n",
      "  Credit Score:\n",
      "  Income Information:\n",
      "  assets:\n",
      "    vehicle:\n",
      "    Insurance:\n",
      "Usage Data:\n",
      "  App Interactions:\n",
      "    Pages Visited:\n",
      "    Timestamps:\n",
      "    Interaction with Ads:\n",
      "    User Engagement:\n",
      "    Session ID:\n",
      "  Device Information:\n",
      "    IP Address:\n",
      "    Device ID:\n",
      "    Advertisement ID:\n",
      "    Browser:\n",
      "    Operating System:\n",
      "    Diagnostics:\n",
      "    Sensor Data:\n",
      "    Audio:\n",
      "    Browsing history:\n",
      "Tracking:\n",
      "  Cookies:\n",
      "  Web Beacons:\n",
      "  Tags:\n",
      "Account Information:\n",
      "  User id:\n",
      "  Username:\n",
      "  Password:\n",
      "  Account Balance:\n",
      "  Messages:\n",
      "  Friends:\n",
      "\n",
      "Purposes:\n",
      "Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts, Requirements\n",
      "\n",
      "Here is the text:\n",
      "\n",
      "Full Cleaned Text:\n",
      "Using Actual\n",
      "Accounts & Transactions\n",
      "\n",
      "overview\n",
      "\n",
      " You can add as many accounts as you like. Adding all of your accounts (including things like mortgages) is a nice way to get an overview of all your finances.\n",
      "\n",
      "Off-budget accounts\n",
      "â€‹\n",
      "Actual makes a distinction between accounts being\n",
      "for budget or off budget. \n",
      "Off budget accounts don't effect the budget and are meant to track stuff like investments and mortgages. Transactions in off budget accounts can't be categorized; they simply track balances over time.\n",
      "\n",
      "For budget\n",
      "accounts affect the budget, and transactions can be categorized. These are accounts where you want to track cash flow and use the budget, like checking accounts and credit cards.\n",
      "\n",
      "Depending on your usage, savings accounts can either be on or off the budget. If you're not sure, we recommend keeping it on budget at the start.\n",
      "\n",
      "Adding a new account\n",
      "â€‹\n",
      "\n",
      "You can add an account to your budget at any time, however when you first install Actual you can use the\n",
      "Add Account\n",
      "button in the middle of the screen.\n",
      "\n",
      "You can also add an account using the\n",
      "+ Add account\n",
      "button in the sidebar.\n",
      "\n",
      "Two successive screens will appear with boxes asking you to fill in a few options\n",
      "\n",
      "Create a Local Account or Link to GoCardless (See\n",
      "Connecting Your Bank\n",
      ")\n",
      "Give your account a name\n",
      "Is the account on or off budget\n",
      "The current account balance\n",
      "\n",
      "Off budget means that the balance is not reflected when you assign money to categories in your budget register\n",
      "\n",
      "Here you can see how that looks when the options are completed.\n",
      "\n",
      "If you select the Off Budget checkbox then change the account type the Off Budget checkbox will reset and will need to be re-selected each time the account type is changed\n",
      "\n",
      "You can now see the account in the sidebar of Actual\n",
      "\n",
      "\n",
      "Closing or deleting an account\n",
      "â€‹\n",
      "\n",
      "Navigate to the account by clicking on it in the sidebar\n",
      "Click on the 3 dots (top right of the transactions list) to show the actions menu\n",
      "Select\n",
      "Close Account\n",
      "You need to select another account to transfer the existing balance to. Choose the account that you have moved funds to.\n",
      "Press\n",
      "Close Account\n",
      "\n",
      "You can still access this account under\n",
      "Closed Accounts\n",
      "in the sidebar, and even reopen it from the same actions menu.\n",
      "\n",
      "If you want to delete an account\n",
      "even if it has existing balances, in the popup after selecting\n",
      "Close Account\n",
      ", click the\n",
      "force close\n",
      "at the bottom.\n",
      "\n",
      "\n",
      "Renaming an existing account\n",
      "â€‹\n",
      "\n",
      "Click the account name in the sidebar of Actual\n",
      "\n",
      "Hovering your cursor close to the account name at the top will reveal two icons.\n",
      "The page icon allows you to write a note about this account, and the pencil icon allows you to rename the account.\n",
      "\n",
      "After editing a note for the account or its name, hit 'Enter' to save your changes.\n",
      "\n",
      "Off-budget accounts\n",
      "Adding a new account\n",
      "Closing or deleting an account\n",
      "Renaming an existing account \n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "(S: \n",
      "We collect account data, account balance, bank account, and assets for personal analytics.We collect account data, account balance, bank account, and assets for account management. We collect account data, account balance, bank account, and assets for Functionality. We use account data, account balance, bank account, and assets for personal analytics. We use account data, account balance, bank account, and assets for account management. We use account data, account balance, bank account, and assets for Functionality.\n",
      ")\n",
      "\n",
      "Here are the behaviors and the privacy requirements in the form of privacy stories we build from them:\n",
      "Privacy stories are built explicitly from our labelled privacy behaviors in the format of we (action) (data type) for (purpose)Actions: Collect, Use\n",
      "Data Types: Account Data, Account Balance, Bank Account, Assets\n",
      "Purposes: Personal analytics, Provide Service, \n",
      "\n",
      " \n",
      "Direct Messaging with LibreEHR and EMR Direct phiMail(R)\n",
      "Version 1.3, 19 Jul 2014\n",
      "\n",
      "A. Purpose: To provide a secure method from within LibreEHR for sending/receiving \n",
      "protected health information to/from another Direct address using the Direct Project \n",
      "messaging standard, as a step toward the goal of satisfying the three MU2 criteria \n",
      "requiring the use of Direct messaging.  (For general information about Direct messaging, \n",
      "see http://www.emrdirect.com/about-directed-exchange-and-secure-direct-messaging.html)\n",
      "\n",
      "B. IMPORTANT:  Please be aware of the following limitations when using the LibreEHR \n",
      "Direct Messaging features with PHI in a production environment:\n",
      "\n",
      "1. the current code only supports a single shared \"group\" Direct Address for each LibreEHR \n",
      "installation. Note that this model is fully compliant with the Direct Project \n",
      "requirements for Direct messaging, but we may add additional models in the future \n",
      "should we determine that doing so would provide a higher degree of interoperability for \n",
      "LibreEHR users.\n",
      "\n",
      "2. the current code only sends the CCR or CCD XML data that is already available in LibreEHR; \n",
      "these files as currently generated by existing LibreEHR code do not meet the requirements \n",
      "of the MU2 criteria, and the current CCD files do not pass strict CDA validation tests.\n",
      "\n",
      "C. Problems Solved:\n",
      "\n",
      "1. Patient-initiated transmission of clinical data from the Report section of the Patient \n",
      "Portal interface.\n",
      "\n",
      "2. Provider-initiated transmission of clinical data from the Report section of the Patient \n",
      "pane in the main LibreEHR interface.\n",
      "\n",
      "3. Log all data transmissions including date/time, patient, and whether transmission \n",
      "was initiated by the patient through the Patient Portal or by an LibreEHR user through the \n",
      "main interface.\n",
      "\n",
      "4. Receive Direct messages from other sources.\n",
      "\n",
      "D. How it Works:\n",
      "Once configured, LibreEHR will interface with a phiMail Direct messaging server to complete the\n",
      "required message transactions. The phiMail platform is described on the EMR Direct website, \n",
      "http://www.emrdirect.com and http://www.emrdirect.com/phimail-faq.html.\n",
      "\n",
      "E. What you need before enabling Direct Messaging in LibreEHR:\n",
      "\n",
      "1. Test Mode: Developers may request a complimentary test address at \n",
      "https://www.emrdirect.com/subscribe-developer  \n",
      "Access to a sandbox server is available for testing and development purposes.\n",
      "\n",
      "2. Production Mode: Healthcare provider users should begin by signing up for a production \n",
      "Direct messaging account with EMR Direct by registering at https://www.emrdirect.com/subscribe\n",
      "\n",
      "Subscribers will receive the username, password, and server address information with which to \n",
      "configure LibreEHR.  \n",
      "\n",
      "F. How to enable the Direct Messaging Features in LibreEHR:\n",
      "Setup of phiMail Direct messaging Service is done in the Administration::Globals::Connectors \n",
      "tab\n",
      "\n",
      "1. Check the \"Enable phiMail Direct Messaging Service\" checkbox.\n",
      "\n",
      "2. Enter the Server Address, Username, and Password provided to you. The server address\n",
      "will be of the form \"ssl://servername.example.com:32541\" - replace the hostname and port\n",
      "with the values provided to you by EMR Direct. The Username is your Direct Address. Do not \n",
      "enter the server URL into your browser address bar, as this will not work.\n",
      "\n",
      "3. Specify the LibreEHR user who will receive notification of new incoming Direct messages. \n",
      "Enter their LibreEHR username in the notification user field.\n",
      "\n",
      "4. Specify the interval for automatic message checking; we suggest 5 or 10 minutes as a\n",
      "starting point, but installations processing a large number of Direct messages may want a \n",
      "shorter interval. To disable automatic message checking through LibreEHR's background service\n",
      "manager, set the interval to 0 (zero). Disabling automatic checking would be appropriate \n",
      "if message checking is managed through another mechanism, such as a system cron job.\n",
      "\n",
      "5. Optionally check \"phiMail Allow CCD Send\" and/or \"phiMail Allow CCR Send\" to enable\n",
      "the Transmit feature for these data types. If you do not select at least one of these,\n",
      "LibreEHR will operate in a receive-only mode.\n",
      "\n",
      "6. Click the \"Save\" button.\n",
      "\n",
      "7. Confirm that a valid Notification Email Address is set in the Administration::\n",
      "Globals::Notifications tab to receive error notifications from the Direct Messaging service.\n",
      "\n",
      "8. Install the EMR Direct trust anchor certificate.  \n",
      "\n",
      "Note: This is *not* your Direct certificate; it is the trust anchor for the SSL \n",
      "certificate issued to our servers, and is used only to validate the SSL certificate \n",
      "presented by the phiMail server on the other side of LibreEHR's connection.  Your Direct private\n",
      "key and certificate are managed by the phiMail Server and are not installed in LibreEHR.\n",
      "Your Direct certificate is made availabe for your review by EMR Direct, but you will not\n",
      "need to install it anywhere.\n",
      "\n",
      "For added security, the trust anchor for the phiMail Server should be installed in the LibreEHR \n",
      "installation tree at:\n",
      "\n",
      "[installation_root]/sites/[site_id]/documents/phimail_server_pem/phimail_server.pem\n",
      "\n",
      "This phimail_server_pem directory and its contents should be readable by the the \n",
      "webserver process, but only writable by trusted local users. The certificate file \n",
      "itself must be PEM encoded. You can identify a PEM encoded certificate file because \n",
      "it begins with the text \"-----BEGIN CERTIFICATE-----\". Although LibreEHR will connect \n",
      "to phiMail servers without installing this certificate, this is a required configuration \n",
      "step for all production  accounts to ensure that you are connecting to the correct \n",
      "server. You can obtain the correct certificate at the following URLs:\n",
      "\n",
      "  a. Test accounts: http://certs.emrdirect.com/EMRDirectTestCA.crt\n",
      "     Important: Don't forget to rename the file to phimail_server.pem and install it\n",
      "     in the correct directory.\n",
      "\n",
      "  b. Production accounts: https://www.phicert.com/certs/phiCertDirectRootCA.crt\n",
      "     Important: The production root must be converted to PEM format as follows:\n",
      "     $ openssl x509 -in phiCertDirectRootCA.crt -inform DER -out phimail_server.pem\n",
      "     Don't forget to install phimail_server.pem in the correct directory. As an added\n",
      "     security measure, please call us to confirm the thumbprint on this certificate.\n",
      "\n",
      "G. Debugging background connections to the server.\n",
      "\n",
      "You may review the connection activity to the server by Selecting Administration::Other::Logs,\n",
      "selecting \"direct-message\" in the \"Name of events:\" drop-down menu, and clicking \"[Refresh]\".\n",
      "If the background service is succesfully connecting, you will see \"message check completed\"\n",
      "events in the log as well as any message related entries (see below for instructions to\n",
      "view more detailed message related status information). If you see no entries, make sure that\n",
      "the background service is enabled (See F.4 above). If you see \"could not connect to server\"\n",
      "entries, each entry will also contain an error code:\n",
      "\n",
      "  C1: phiMail is disabled in the global configuration. Fix: enable.\n",
      "  C2: the phiMail server URL entered in the global configuration is invalid. Fix: Confirm\n",
      "      the URL has been entered correctly. It should be of the form \n",
      "      \"ssl://server.example.com:32541\".\n",
      "  C3: unable to create stream context. Fix: Usually this is because the server certificate \n",
      "      file installed in F.8 above is not the correct certificate or is in the wrong format.\n",
      "  C4: failed to open connection. Fix: Confirm you Internet service and local DNS servers are\n",
      "      online and your firewall is not blocking connections to the phiMail Server.\n",
      "\n",
      "H. Checking the status and history of the Direct Messaging Service in LibreEHR:\n",
      "Administrators may view the status of the service by Selecting Reports::Services::Background \n",
      "Services from the main LibreEHR left navigation bar. The \"View Log\" link on this page or \n",
      "Reports::Services::Direct Message Log will open the messaging history log showing each message \n",
      "sent or received and the current status of that message (Received, Sent, Delivery Confirmed, \n",
      "or Failed).\n",
      "\n",
      "I. Note of message status messages: Receiving message status updates requires that Direct message\n",
      "checking be enabled. When receiving messages, the phiMail back-end is fully compliant with the \n",
      "Direct messaging protocols to notify the sender and provide final delivery confirmation, but \n",
      "please note that  many other Direct providers do not yet support these features. If a message \n",
      "is sent to a recipient using one of these other systems, LibreEHR probably won't ever receive a \n",
      "final delivery confirmation for that message.\n",
      "\n",
      "J. How to use the Direct Messaging Features in LibreEHR:\n",
      "\n",
      "1. Sending:\n",
      "When the phiMail Direct Messaging service is enabled, an additional \"Transmit\" button will\n",
      "appear in the Continuity of Care Record (CCR) and/or Continuity of Care Document (CCD) block \n",
      "of the Reports section in both the Patient Portal and the Patient pane of the main provider \n",
      "interface. \n",
      "\n",
      "To transmit a CCR or CCD, first click the \"Transmit\" button. This will open a small dialog \n",
      "immediately below the button with a form field to enter the intended recipient's Direct Address. \n",
      "Clicking \"Transmit\" again will hide the dialog.\n",
      "\n",
      "A Direct Address should have the same form as a regular email address, e.g. \n",
      "jonesclinic@direct.example.com. Enter the address in the field and click the \"Send\" button \n",
      "immediately to the right of the field. Only a single recipient may be specified in the field.\n",
      "The Send button will be temporarily disabled while LibreEHR is communicating with the phiMail \n",
      "server. This will only work for properly-configured Direct addresses. Attempts to send to a \n",
      "regular email address or Direct address outside of our test mode \"trust sandbox\" will fail\n",
      "during testing. Production accounts have wide interoperability with other Direct service\n",
      "providers. Should you encounter a trust community with which LibreEHR does not interoperate,\n",
      "please let us know at support@emrdirect.com.\n",
      "\n",
      "LibreEHR will then display a status message immediately below the Address field, the \n",
      "success or failure of the message transmission, or an error message. If the message is\n",
      "successfully submitted to the server, the Address field will be cleared to prevent accidental\n",
      "re-transmission. If multiple recipients are required, the next recipient can now be entered.\n",
      "\n",
      "If you receive an error message, it will be followed by an error code. For a discussion\n",
      "of error codes beginning with the letter \"C\" please see section G above. Error codes\n",
      "beginning with \"EC\" are listed here:\n",
      "\n",
      "  EC 1: phiMail disabled in global configuration. Fix: enable.\n",
      "  EC 4: authentication failure. Fix: The Username and Password entered in the\n",
      "        global configuration must be corrected.\n",
      "  EC 5: request to add text failed. Fix: Confirm total message length < 5MB.\n",
      "  EC 6: problem sending the text. Fix: Confirm your local network connectivity is stable.\n",
      "  EC 7: request to add clinical document failed. Fix: see EC 5.\n",
      "  EC 8: problem sending the clinical document. Fix: see EC 6.\n",
      "\n",
      "2. Receiving:\n",
      "When the phiMail Direct Messaging service is enabled, and message checking is enabled either \n",
      "through the background services manager of another mechanism, LibreEHR will automatically process \n",
      "message status updates and new messages. Status updates will be reflected immediately in the \n",
      "Direct Messaging log. Additionally, if a \"Failed\" notification is received for a previously sent \n",
      "message, a regular email message will be generated to the Notification Email Address specified \n",
      "in the Notifications tab of the Global Settings panel (accessed by selecting Administration::\n",
      "Globals from the main left navigation menu).\n",
      "\n",
      "New Direct messages will be processed as follows. A new \"Patient Note\" will be generated and \n",
      "sent to the phiMail notification user specified in the Connectors tab of the Global settings. \n",
      "The patient note will contain information about the message, including any text at the beginning \n",
      "of the message from the sender. Any attachments (and any non-text content) will be automatically \n",
      "converted to separate LibreEHR Documents, which will be referenced in the new Patient Note.  \n",
      "The Documents and the Patient Note are initially created without an assigned patient. \n",
      "\n",
      "At this time, the envisioned workflow is that the notification user will review the message text\n",
      "and any included Documents to determine which patient the content belongs to and will then set the \n",
      "patient using the existing Patient Note interface for choosing a patient. Once the patient is sent, \n",
      "the Patient Note can be forwarded to another provider or staff member as appropriate using the \n",
      "existing forwarding mechanism for Patient Notes. The unassigned Documents can be viewed by Selecting \n",
      "Miscellaneous::New Documents from the main left navigation menu, which opens a Documents list. Once \n",
      "the specified document is opened, the user can optionally categorize the document and, when \n",
      "appropriate, assign the document to a specific patient using the \"Move to Patient #\" feature in the \n",
      "Documents interface.\n",
      "\n",
      "\n",
      "Trademark Notice: phiMail is a registered trademark of EMR Direct.\n",
      "\n",
      "Copyright (c) 2013-2014 EMR Direct.\n",
      "\n",
      "\n",
      "Annotate the text with actions, data types, purposes, and stories as demonstrated, using only the categories from the list provided. For each annotation, provide your rationale and place <R> tag between your annotations and rationales.\n",
      "\n",
      "\n",
      "Token Count: 3961 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from typing import Dict, List, Union\n",
    "import tiktoken  # Library for token counting with OpenAI models\n",
    "import prompt_templates\n",
    "\n",
    "# Load the privacy ontology\n",
    "ontology_path = \"privacy_ontology_simple.json\"\n",
    "privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "# Load one processed example file for demonstration\n",
    "example_file = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "\n",
    "# Define target text to be annotated (for demonstration) & Load annotated version \n",
    "target_file_annotations = text_processing.process_input(target_file_path)\n",
    "new_text_to_annotate = open(target_file_path).read()\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_example = prompt_templates.create_annotation_prompt(example_file, new_text_to_annotate, privacy_ontology)\n",
    "\n",
    "# Print the prompt to review it\n",
    "print(prompt_example)\n",
    "print(f\"\\nToken Count: {prompt_templates.count_tokens(prompt_example)} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating with LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing input\\Actual_Budget\\Backup_&_Restore.txt: 'charmap' codec can't decode byte 0x9d in position 232: character maps to <undefined>\n",
      "Created prompt templates for 24 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import prompt_templates\n",
    "import text_processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "input_dir = 'input'\n",
    "\n",
    "def find_matching_file(input_file_path, annotations_dir):\n",
    "    \"\"\"\n",
    "    Find the matching annotation file for a given input file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Root directory of annotations\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the matching annotation file, or None if not found\n",
    "    \"\"\"\n",
    "    # Get the relative path from the input directory\n",
    "    relative_path = os.path.relpath(input_file_path, input_dir)\n",
    "    annotation_file_path = os.path.join(annotations_dir, relative_path)\n",
    "    \n",
    "    return annotation_file_path if os.path.exists(annotation_file_path) else None\n",
    "\n",
    "\n",
    "def find_most_similar_file(input_file_path, annotations_dir, exclude_file):\n",
    "    \"\"\"\n",
    "    Find the most similar annotation file to the input file, excluding a specified file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Directory containing the annotation files\n",
    "        exclude_file (str): File to exclude from similarity search\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the most similar annotation file\n",
    "    \"\"\"\n",
    "    # Read the input file's content\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        input_text = f.read()\n",
    "    \n",
    "    # List to store (similarity_score, annotation_file_path)\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Loop through the annotations directory to calculate similarity\n",
    "    for root, _, files in os.walk(annotations_dir):\n",
    "        for filename in files:\n",
    "            if filename == exclude_file or filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            annotation_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Read the annotation file's content\n",
    "            with open(annotation_file_path, 'r', encoding='utf-8') as f:\n",
    "                annotation_text = f.read()\n",
    "            \n",
    "            # Compute similarity using TF-IDF and cosine similarity\n",
    "            tfidf = TfidfVectorizer().fit_transform([input_text, annotation_text])\n",
    "            similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "            similarity_scores.append((similarity, annotation_file_path))\n",
    "    \n",
    "    # Sort by similarity score in descending order and return the most similar file\n",
    "    similarity_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    return similarity_scores[0][1] if similarity_scores else None\n",
    "\n",
    "\n",
    "def create_prompt_templates_dict(input_dir='input', annotations_dir='annotations', ontology_path='privacy_ontology_simple.json'):\n",
    "    \"\"\"\n",
    "    Create a dictionary of prompt templates matching input files with their corresponding annotation examples.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Root directory containing input files to be annotated\n",
    "        annotations_dir (str): Root directory containing annotated example files\n",
    "        ontology_path (str): Path to the privacy ontology JSON file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of prompt templates for each input file\n",
    "    \"\"\"\n",
    "    # Load privacy ontology\n",
    "    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "    \n",
    "    # Dictionary to store prompt templates\n",
    "    prompt_templates_dict = {}\n",
    "    \n",
    "    # Walk through all directories and files in the input directory\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            # Skip hidden files\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            # Full path to the input file\n",
    "            input_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Find corresponding annotation file (for exclusion from similarity search)\n",
    "            annotation_file_path = find_matching_file(input_file_path, annotations_dir)\n",
    "            \n",
    "            if not annotation_file_path:\n",
    "                print(f\"No matching annotation found for {input_file_path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Read the input text to annotate\n",
    "                with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                    new_text_to_annotate = f.read()\n",
    "                \n",
    "                # Find the most similar annotation file\n",
    "                most_similar_annotation = find_most_similar_file(input_file_path, annotations_dir, os.path.basename(annotation_file_path))\n",
    "                \n",
    "                if not most_similar_annotation:\n",
    "                    print(f\"No similar annotation found for {input_file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the example file from annotations\n",
    "                example_file = text_processing.process_input(most_similar_annotation)[0]\n",
    "                \n",
    "                # Create prompt template\n",
    "                prompt_template = prompt_templates.create_annotation_prompt(\n",
    "                    example_file, \n",
    "                    new_text_to_annotate, \n",
    "                    privacy_ontology\n",
    "                )\n",
    "                \n",
    "                # Create a unique key based on relative path\n",
    "                relative_key = os.path.relpath(input_file_path, input_dir)\n",
    "                \n",
    "                # Store in dictionary\n",
    "                prompt_templates_dict[relative_key] = {\n",
    "                    'input_file_path': input_file_path,\n",
    "                    'annotation_file_path': most_similar_annotation,\n",
    "                    'prompt_template': prompt_template,\n",
    "                    'target_annotations': text_processing.process_file(annotation_file_path),\n",
    "                    'token_count': prompt_templates.count_tokens(prompt_template)\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_file_path}: {e}\")\n",
    "    \n",
    "    return prompt_templates_dict\n",
    "\n",
    "\n",
    "# Create the prompt templates dictionary\n",
    "prompt_templates_dict = create_prompt_templates_dict()\n",
    "\n",
    "# Save to JSON for inspection\n",
    "with open('prompt_templates_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({k: {**v, 'prompt_template': v['prompt_template']} \n",
    "              for k, v in prompt_templates_dict.items()}, \n",
    "              f, indent=2)\n",
    "\n",
    "print(f\"Created prompt templates for {len(prompt_templates_dict)} files\")\n",
    "\n",
    "# Optional: You can save the full dictionary using pickle if needed\n",
    "import pickle\n",
    "with open('prompt_templates.pkl', 'wb') as f:\n",
    "    pickle.dump(prompt_templates_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Model: groq:llama-3.3-70b-versatile - Completed a run\n",
      "Error with groq:llama-3.3-70b-versatile: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01jekpnf88edvabrzxjrp29n1r` on tokens per minute (TPM): Limit 6000, Requested 6715, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error with groq:llama-3.3-70b-versatile: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01jekpnf88edvabrzxjrp29n1r` on tokens per minute (TPM): Limit 6000, Requested 6715, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Annotation results saved to LLMAnnotation_groqLlama.csv\n",
      "Number of files processed: 24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from getpass import getpass\n",
    "import model_routing\n",
    "from typing import Dict, List\n",
    "\n",
    "# Ensure OPENAI_API_KEY is set\n",
    "# os.environ['OPENAI_API_KEY'] = getpass('Enter your OPENAI API key: ')\n",
    "\n",
    "os.environ['GROQ_API_KEY'] =\"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\"\n",
    "\n",
    "def save_results_to_csv(models: List[str], \n",
    "                         prompt_templates_dict: Dict, \n",
    "                         model_responses: Dict, \n",
    "                         output_file: str):\n",
    "    \"\"\"\n",
    "    Save the model outputs, prompts, and file annotations to a CSV file.\n",
    "    \"\"\"\n",
    "    # Open the output CSV file\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Prepare the CSV header\n",
    "        fieldnames = ['File', 'Prompt', 'Model', 'Target File Path', 'Target Annotations', 'Model Response 1', 'Model Response 2']\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Iterate through the prompt templates and models to pair responses\n",
    "        for file_key in file_keys:\n",
    "            template_info = prompt_templates_dict[file_key]\n",
    "            \n",
    "            for model in models:\n",
    "                # Get responses for this model\n",
    "                model_specific_responses = model_responses.get(model, {})\n",
    "                \n",
    "                # Get responses for this specific file/prompt\n",
    "                prompt_responses = model_specific_responses.get(file_key, [])\n",
    "                \n",
    "                # Ensure we have at least two responses (or 'No Response')\n",
    "                response1 = prompt_responses[0] if prompt_responses and len(prompt_responses) > 0 else 'No Response'\n",
    "                response2 = prompt_responses[1] if prompt_responses and len(prompt_responses) > 1 else 'No Response'\n",
    "\n",
    "                # Create a row for each model and file\n",
    "                row = {\n",
    "                    'File': file_key,\n",
    "                    'Prompt': template_info['prompt_template'],\n",
    "                    'Model': model,\n",
    "                    'Target File Path': template_info['input_file_path'],\n",
    "                    'Target Annotations': json.dumps(template_info['target_annotations']),\n",
    "                    'Model Response 1': json.dumps(response1, ensure_ascii=False),\n",
    "                    'Model Response 2': json.dumps(response2, ensure_ascii=False)\n",
    "                }\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "def run_multi_file_annotations(prompt_templates_dict, output_csv, models=None):\n",
    "    \"\"\"\n",
    "    Run annotation process for multiple files and save results to a CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Prepare prompts that maintains the file key order\n",
    "        test_prompts = [\n",
    "            prompt_templates_dict[file_key]['prompt_template'] \n",
    "            for file_key in file_keys\n",
    "        ]\n",
    "\n",
    "        # Get model responses \n",
    "        raw_model_responses = model_routing.run_multi_model_prompts(\n",
    "            models=models, \n",
    "            prompts=test_prompts, \n",
    "            num_runs=2  # Number of runs per model\n",
    "        )\n",
    "\n",
    "        # Restructure responses to match file keys\n",
    "        model_responses = {}\n",
    "        for model in models:\n",
    "            model_responses[model] = {\n",
    "                file_key: model_runs \n",
    "                for file_key, model_runs in zip(file_keys, raw_model_responses.get(model, []))\n",
    "            }\n",
    "\n",
    "        # Save results to CSV \n",
    "        save_results_to_csv(\n",
    "            models=models,\n",
    "            prompt_templates_dict=prompt_templates_dict,\n",
    "            model_responses=model_responses,\n",
    "            output_file=output_csv\n",
    "        )\n",
    "\n",
    "        print(f\"Annotation results saved to {output_csv}\")\n",
    "        print(f\"Number of files processed: {len(prompt_templates_dict)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage remains the same\n",
    "output_csv = 'LLMAnnotation_groqLlama.csv'\n",
    "models = [\n",
    "    # 'openai:gpt-4o-2024-11-20'\n",
    "    'groq:llama-3.3-70b-versatile'\n",
    "    ]\n",
    "run_multi_file_annotations(prompt_templates_dict, output_csv, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model F1 scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management', 'personal analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management', 'personal analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management', 'personal analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.7500\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'tracking'}\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'tracking'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'tracking'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Annotation F1 Scores:\n",
      "File: Accounts_&_Transactions.txt\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 1.0000\n",
      "----------------------------------------\n",
      "File: CreatingAnewAccount.txt\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.7500\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2500\n",
      "----------------------------------------\n",
      "File: features.txt\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: add_threePids.txt\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.5667\n",
      "----------------------------------------\n",
      "File: account-basics.txt\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.5000\n",
      "----------------------------------------\n",
      "File: signups.txt\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: userdetails.txt\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.1333\n",
      "----------------------------------------\n",
      "File: configurations.txt\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.3889\n",
      "----------------------------------------\n",
      "File: Getting Started.txt\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.5000\n",
      "----------------------------------------\n",
      "File: profile-preferences.txt\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2667\n",
      "----------------------------------------\n",
      "File: Direct_Messaging_README.txt\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: Navigation.txt\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.5556\n",
      "----------------------------------------\n",
      "File: README.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6111\n",
      "----------------------------------------\n",
      "File: Architecture.txt\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: data-structure.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.3889\n",
      "----------------------------------------\n",
      "File: managing-users.txt\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.5000\n",
      "----------------------------------------\n",
      "File: analyrics-events.txt\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.5000\n",
      "----------------------------------------\n",
      "File: account_data_callbacks.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: account_validity_callbacks.txt\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.3333\n",
      "----------------------------------------\n",
      "File: password_auth_provider_callbacks.txt\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: DatabaseSchema.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.4444\n",
      "----------------------------------------\n",
      "File: INotificationDistributor.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: INotificationSubscriber.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.2222\n",
      "----------------------------------------\n",
      "File: file.txt\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.4444\n",
      "----------------------------------------\n",
      "Results saved to annotation_f1_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Dict, List, Set\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class AnnotationEvaluator:\n",
    "    def __init__(self, ontology_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with the privacy ontology.\n",
    "        \"\"\"\n",
    "        with open(ontology_path, 'r') as f:\n",
    "            self.ontology = json.load(f)\n",
    "    \n",
    "    def _normalize_label(self, label: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize label by removing extra whitespace, converting to lowercase,\n",
    "        and splitting comma-separated values.\n",
    "        \"\"\"\n",
    "        # Split by comma, strip whitespace, convert to lowercase\n",
    "        return [\n",
    "            l.strip().lower() \n",
    "            for l in label.split(',') \n",
    "            if l.strip()\n",
    "        ]\n",
    "    \n",
    "    def _match_labels(self, text: str, category_labels: List[str]) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Find matching labels in the text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to search\n",
    "            category_labels (List[str]): Labels to match\n",
    "        \n",
    "        Returns:\n",
    "            Set[str]: Matched labels\n",
    "        \"\"\"\n",
    "        # Normalize text\n",
    "        normalized_text = text.lower()\n",
    "        \n",
    "        # Match labels\n",
    "        matched_labels = set()\n",
    "        \n",
    "        for label in category_labels:\n",
    "            # Various matching strategies\n",
    "            # 1. Whole word match\n",
    "            word_pattern = r'\\b' + re.escape(label) + r'\\b'\n",
    "            # 2. Partial match\n",
    "            partial_pattern = re.escape(label)\n",
    "            \n",
    "            if (re.search(word_pattern, normalized_text) or \n",
    "                re.search(partial_pattern, normalized_text)):\n",
    "                matched_labels.add(label)\n",
    "        \n",
    "        return matched_labels\n",
    "    \n",
    "    def calculate_comprehensive_f1_scores(self, ground_truth: Dict, text: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate F1 scores for all categories.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth (Dict): Ground truth annotations\n",
    "            text (str): Text to evaluate\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, float]: F1 scores\n",
    "        \"\"\"\n",
    "        f1_scores = {}\n",
    "        categories = ['actions', 'data_types', 'purposes']\n",
    "        \n",
    "        for category in categories:\n",
    "            # Extract labels from ground truth\n",
    "            gt_labels = self._normalize_label(', '.join(ground_truth.get(category, [])))\n",
    "            \n",
    "            # Find matching labels in text\n",
    "            pred_labels = self._match_labels(text, gt_labels)\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            y_true = [1 if label in gt_labels else 0 for label in gt_labels]\n",
    "            y_pred = [1 if label in pred_labels else 0 for label in gt_labels]\n",
    "            \n",
    "            try:\n",
    "                # Macro average F1 score\n",
    "                f1 = f1_score(y_true, y_pred, average='binary')\n",
    "            except Exception as e:\n",
    "                print(f\"F1 Score calculation error for {category}: {e}\")\n",
    "                f1 = 0\n",
    "            \n",
    "            f1_scores[category] = f1\n",
    "        \n",
    "        # Calculate overall F1 score\n",
    "        f1_scores['Overall'] = sum(f1_scores.values()) / len(f1_scores)\n",
    "        \n",
    "        # Diagnostic print\n",
    "        print(f\"\\nCategory Diagnostics:\")\n",
    "        for category in categories:\n",
    "            print(f\"{category.capitalize()}:\")\n",
    "            print(f\"  Ground Truth Labels: {gt_labels}\")\n",
    "            print(f\"  Matched Labels: {pred_labels}\")\n",
    "            print(f\"  F1 Score: {f1_scores[category]:.4f}\")\n",
    "        \n",
    "        return f1_scores\n",
    "\n",
    "def process_annotation_csv(csv_path: str, ontology_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process the annotation CSV and calculate F1 scores.\n",
    "    \"\"\"\n",
    "    # Initialize the evaluator\n",
    "    evaluator = AnnotationEvaluator(ontology_path)\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    # Read the CSV file\n",
    "    with open(csv_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Parse target annotations\n",
    "                ground_truth = json.loads(row['Target Annotations'])\n",
    "                \n",
    "                # Extract full text\n",
    "                full_text = ground_truth.get('full_cleaned_text', '')\n",
    "                \n",
    "                # Calculate F1 scores\n",
    "                f1_scores = evaluator.calculate_comprehensive_f1_scores(\n",
    "                    ground_truth['metadata'], \n",
    "                    full_text\n",
    "                )\n",
    "                \n",
    "                # Prepare result dictionary\n",
    "                result = {\n",
    "                    'File': ground_truth.get('file_name', 'Unknown'),\n",
    "                    'Metrics': f1_scores\n",
    "                }\n",
    "                \n",
    "                results.append(result)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Paths to your files\n",
    "    csv_path = 'LLMAnnotation_groqLLama.csv'\n",
    "    ontology_path = 'privacy_ontology_simple.json'\n",
    "    \n",
    "    # Process the CSV and calculate F1 scores\n",
    "    results = process_annotation_csv(csv_path, ontology_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nAnnotation F1 Scores:\")\n",
    "    for result in results:\n",
    "        print(f\"File: {result['File']}\")\n",
    "        for category, score in result['Metrics'].items():\n",
    "            print(f\"{category} F1 Score: {score:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # Save results to a CSV\n",
    "    if results:\n",
    "        output_keys = ['File', 'Actions F1', 'Data Types F1', 'Purposes F1', 'Overall F1']\n",
    "        with open('annotation_f1_scores.csv', 'w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=output_keys)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for result in results:\n",
    "                # Prepare row for CSV\n",
    "                csv_row = {\n",
    "                    'File': result['File'],\n",
    "                    'Actions F1': result['Metrics'].get('actions', 0),\n",
    "                    'Data Types F1': result['Metrics'].get('data_types', 0),\n",
    "                    'Purposes F1': result['Metrics'].get('purposes', 0),\n",
    "                    'Overall F1': result['Metrics'].get('Overall', 0)\n",
    "                }\n",
    "                writer.writerow(csv_row)\n",
    "        \n",
    "        print(\"Results saved to annotation_f1_scores.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n- Share\\n\\n#### Data Types:\\n- Account Information: Username, Password, Account Balance\\n- Financial: Bank Account, Credit Score\\n\\n#### Purposes:\\n- Accounts\\n- Functionality\\n- Security\\n\\n#### Stories:\\n1. We collect Username, Password, and Account Balance for account management and functionality.\\n2. We use Username and Password for security purposes to authenticate users.\\n3. We use Bank Account and Credit Score data for account management and functionality.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['personal analytics', 'functionality', 'account management']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**\\n- Collect\\n- Use\\n- Delete\\n\\n**Data Types:**\\n- Account Balance\\n- Account Name\\n\\n**Purposes:**\\n- Accounts\\n- Functionality\\n\\n**Stories:**\\n1. We collect Account Name and Account Balance for Accounts management.\\n2. We use Account Name and Account Balance for Functionality.\\n3. We delete Account Balance and Account Name to manage accounts.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.3333\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions**:  \\n- Collect  \\n- Use  \\n\\n**Data Types**:  \\n- Account Information:  \\n  - Account Balance  \\n- Financial:  \\n  - Bank Account  \\n  - assets  \\n\\n**Purposes**:  \\n- Analytics  \\n- Functionality  \\n- Accounts  \\n\\n**Stories**:  \\n1. We collect account balance, bank account, and assets for functionality.  \\n2. We collect account balance, bank account, and assets for account management.  \\n3. We use account balance, bank account, and assets for functionality.  \\n4. We use account balance, bank account, and assets for account management.  \\n5. We collect account balance, bank account, and assets for analytics.  \\n6. We use account balance, bank account, and assets for analytics.\\n\\n---\\n\\n### Rationale:\\n\\n**Actions**:  \\n- **Collect**: The text describes collecting information such as account details (e.g., account balance, bank accounts). This is evident when users are required to add details like account name, balance, and type during account creation.  \\n- **Use**: The collected data is used for various functionalities, such as displaying account balances, categorizing transactions, or calculating budgets.\\n\\n**Data Types**:  \\n- **Account Information: Account Balance**: The text explicitly mentions \\\"current account balance\\\" as part of the required data during account setup.  \\n- **Financial: Bank Account**: Users are instructed to provide bank account details, such as the account type and balance, when creating or managing accounts.  \\n- **Financial: assets**: The text references tracking assets like investments or mortgages in off-budget accounts, implying the use of financial data related to personal assets.\\n\\n**Purposes**:  \\n- **Analytics**: Users are encouraged to add accounts to get an overview of their finances, which suggests the purpose of analyzing financial data.  \\n- **Functionality**: The core functionality of the application revolves around managing accounts, tracking balances, and categorizing transactions.  \\n- **Accounts**: The primary purpose of the tool is account management, as evidenced by actions like creating, renaming, or closing accounts.\\n\\n**Stories**:  \\nI created the stories by combining the identified actions, data types, and purposes. For instance:  \\n- Collecting and using account data (e.g., balance, bank account, assets) is necessary for purposes such as functionality, account management, and analytics.  \\n- These stories reflect the interaction between user-provided data and the application's functionalities, which align with the stated purpose of managing finances efficiently.  \\n\\nThe annotations and stories align with how the application operates based on the provided text, ensuring clarity and relevance.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Account Information:  \\n  - Account Balance  \\n  - Messages  \\n- Financial:  \\n  - Bank Account  \\n  - Orders  \\n  - assets:  \\n\\n**Purposes:**  \\n- Functionality  \\n- Accounts  \\n- Analytics  \\n\\n**Stories:**  \\n1. We collect account balance, bank account, and assets for functionality.  \\n2. We use account balance, bank account, and assets for functionality.  \\n3. We collect account balance, bank account, and assets for account management.  \\n4. We use account balance, bank account, and assets for account management.  \\n5. We collect account balance, bank account, and assets for analytics.  \\n6. We use account balance, bank account, and assets for analytics.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**  \\nCollect, Use  \\n\\n**Data Types:**  \\nContact Data:  \\n- Email Address  \\n- Name  \\n- Address  \\n- Date of Birth  \\n- Image  \\n\\nAccount Information:  \\n- Friends  \\n\\nUsage Data:  \\n- App Interactions: Pages Visited, User Engagement  \\n- Device Information: Device ID  \\n\\nTracking:  \\n- Cookies  \\n\\n**Purposes:**  \\nContact, Customization, Analytics, Advertisement, Security, Functionality  \\n\\n**Stories:**  \\n1. We collect and use email addresses, names, and dates of birth for contact purposes.  \\n2. We collect and use images and friends' data for customization purposes.  \\n3. We collect and use app interaction data such as pages visited and user engagement for analytics purposes.  \\n4. We collect and use cookies and device information for advertisement and security purposes.  \\n5. We use address information for functionality purposes such as reminders and personalized features.\\n\\n---\\n\\n**Rationale:**  \\n**Actions:** The text mentions actions related to managing personal data, such as adding contacts, uploading documents and photos, managing addresses, and using the app for reminders and personalization. These indicate the actions of collecting and using data.  \\n\\n**Data Types:** A variety of personal data types are referenced directly or implied in the text:  \\n- Email addresses are used for reminders and contact purposes (e.g., sending emails).  \\n- Names and addresses are mentioned for contact management.  \\n- Images are uploaded, indicating the collection and use of photo data.  \\n- Friends are part of the app's functionality, indicating the collection of social relationship data.  \\n- Dates of birth are used for birthday reminders.  \\n- Device ID and cookies are implied in functionality such as tracking and analytics.  \\n- App interactions, pages visited, and user engagement are inferred as part of analytics features.  \\n\\n**Purposes:**  \\n- Contact: Email addresses and names are collected for reminders and communication.  \\n- Customization: Images and friends' data are used to personalize the app experience.  \\n- Analytics: App interaction data is collected to understand how users engage with the app.  \\n- Advertisement: Cookies and device information could be used for advertisement-related purposes.  \\n- Security: Device information might help in ensuring the app's security and user authentication.  \\n- Functionality: Address information supports features like reminders and personalized management tools.\\n\\n**Stories:**  \\nThe stories are derived directly from the interaction of actions, data types, and purposes. For instance, reminders imply collecting and using dates of birth for contact purposes, while uploading images ties into customization. Tracking via cookies and device information aligns with advertisement and security purposes.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Contact Data:  \\n  - Email address  \\n  - Name  \\n- Account Information:  \\n  - Friends  \\n- Health Data:  \\n  - Physical activity  \\n- Usage Data:  \\n  - App Interactions: Timestamps, Pages Visited  \\n  - Device Information: Device ID, IP Address  \\n\\n**Purposes:**  \\n- Contact  \\n- Customization  \\n- Analytics  \\n- Functionality  \\n\\n**Stories:**  \\n1. We collect and use email addresses and names for contact.  \\n2. We collect and use timestamps and pages visited for analytics.  \\n3. We collect and use friends and physical activity for customization.  \\n4. We collect and use device ID and IP address for functionality.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions: \\n1. Collect\\n2. Use\\n\\n#### Data Types:\\n1. Account Information:\\n   - Username\\n   - Password\\n   - Email address\\n   - Phone number\\n\\n#### Purposes:\\n1. Functionality\\n2. Account Management\\n\\n#### Stories:\\n1. We collect account information, username, password, email address, and phone number for functionality.\\n2. We collect account information, username, password, email address, and phone number for account management.\\n3. We use account information, username, password, email address, and phone number for functionality.\\n4. We use account information, username, password, email address, and phone number for account management.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'accounts', 'contact'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'accounts', 'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'accounts', 'functionality', 'contact', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'accounts', 'contact'}\n",
      "  F1 Score: 0.9091\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n\\n#### Data Types:\\n- Contact Data:\\n  - Email address\\n  - Phone Number\\n- Account Information:\\n  - Username\\n  - Password\\n\\n#### Purposes:\\n- Accounts\\n- Functionality\\n- Security\\n\\n#### Stories:\\n1. We collect email addresses and phone numbers for account functionality.\\n2. We use email addresses and phone numbers for account functionality.\\n3. We collect usernames and passwords for account functionality.\\n4. We use usernames and passwords for account functionality.\\n5. We use email addresses and phone numbers for security purposes.\\n6. We collect email addresses and phone numbers for security purposes.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Email address  \\n- Username  \\n- Password  \\n- Personal Data  \\n\\n**Purposes:**  \\n- Account management  \\n- Authentication  \\n- Functionality  \\n\\n**Stories:**  \\n1. We collect Email address, Username, and Password for account management.  \\n2. We use Email address, Username, and Password for authentication.  \\n3. We collect Personal Data (export) for functionality (to allow users to relocate accounts).  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n- Share\\n\\n#### Data Types:\\n- Contact Data:\\n  - Email address\\n  - Username\\n  - Name\\n  - Nickname\\n- Account Information:\\n  - Password\\n- Usage Data:\\n  - Interaction with Ads\\n  - Preferences (NSFW content, language preferences)\\n- Social Media:\\n  - Profile Picture (Avatar)\\n  - Bio\\n- Tracking:\\n  - Cookies\\n\\n#### Purposes:\\n- Account management\\n- Authentication\\n- Functionality\\n- Customization\\n- Security\\n\\n#### Stories:\\n1. We collect Email Address, Username, Password, and Nickname for account management and authentication.\\n2. We collect and use Email Address for sending notifications and account login details for functionality purposes.\\n3. We use Profile Pictures (Avatars), Display Names, and Bio for customization of user profiles.\\n4. We collect and use preferences such as NSFW content settings and language preferences for customization purposes.\\n5. We collect and use Cookies to enhance functionality and security.\\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n\\n#### Data Types:\\n- Email address\\n- Username\\n- Password\\n\\n#### Purposes:\\n- Account Management\\n- Authentication\\n- Security\\n\\n#### Stories:\\n1. We collect Email address, Username, and Password for account management and authentication purposes.\\n2. We use Email address for authentication and communication during the account sign-up process.\\n3. We collect and use Email address for administrative purposes, such as account approval or rejection notifications for admins and moderators.\\n4. We use Email address for security purposes, like confirmation of ownership to prevent unauthorized access.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection', 'functionality']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:** Collect, Use  \\n**Data Types:** Email address, Username, Password  \\n**Purposes:** Account management, Authentication  \\n\\n**Stories:**  \\n1. We collect email addresses, usernames, and passwords for account management.  \\n2. We use email addresses, usernames, and passwords for authentication.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'account management', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'account management', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'identification', 'account management', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Delete  \\n\\n**Data Types:**  \\n- Email Address  \\n- Username  \\n- Password  \\n- Account Information: User ID, Messages  \\n- Financial: Payment History  \\n- Contact Data: Name, Phone Number  \\n- Usage Data: App Interactions (Pages Visited), Device Information (Browser, Operating System)  \\n\\n**Purposes:**  \\n- Accounts  \\n- Security  \\n- Functionality  \\n\\n**Stories:**  \\n1. We collect Email Address, Username, Password, and Account Information (User ID, Messages) for Accounts purposes.  \\n2. We use Email Address, Username, and Password for Security purposes, such as enabling two-factor authentication and resetting passwords.  \\n3. We collect Name, Phone Number, and Financial Data (Payment History) for Accounts purposes to assist with user management and accountability.  \\n4. We use Usage Data (App Interactions, Device Information) for Functionality purposes to improve user experience and platform performance.  \\n5. We delete Account Information (User ID, Messages) for user protection when accounts are removed or banned.\\n\\n---\\n\\n### Rationale:\\n\\n**Actions:**  \\n- \\\"Collect\\\" is inferred because the system gathers information like email addresses, usernames, and passwords during account registration.  \\n- \\\"Use\\\" is evident when the text discusses the use of data for account management, password resets, and two-factor authentication setup.  \\n- \\\"Delete\\\" is specified in the text when discussing the removal of user accounts and associated data, such as videos and messages.  \\n\\n**Data Types:**  \\n- \\\"Email Address\\\" is explicitly mentioned as a requirement for account registration and password resets.  \\n- \\\"Username\\\" is used to identify and manage users.  \\n- \\\"Password\\\" is a key component of user authentication and is referenced for resetting and security purposes.  \\n- \\\"Account Information\\\" includes details like User ID and Messages, which are relevant to managing user accounts and communication.  \\n- \\\"Financial Data\\\" (Payment History) is implied in the Invoice Ninja section, where user and client management are discussed.  \\n- \\\"Contact Data\\\" includes Name and Phone Number, which are used for identification and reference purposes.  \\n- \\\"Usage Data\\\" includes App Interactions (Pages Visited) and Device Information (Browser, Operating System), which are collected to enhance functionality and user experience.  \\n\\n**Purposes:**  \\n- \\\"Accounts\\\" is applicable because much of the data collection and use is centered around account creation, management, and user identification.  \\n- \\\"Security\\\" is relevant due to the emphasis on password resets, two-factor authentication, and account protection measures.  \\n- \\\"Functionality\\\" is inferred from the use of data to manage quotas, improve user experience, and ensure the platform operates efficiently.  \\n\\n**Stories:**  \\n- Story 1 combines actions of collecting and using account-related data for managing user accounts.  \\n- Story 2 highlights the use of Email Address, Username, and Password for security measures, including authentication and password resets.  \\n- Story 3 involves the collection of Contact Data (Name, Phone Number) and Financial Data for managing accounts and ensuring accountability in organizational contexts.  \\n- Story 4 underscores the use of Usage Data to enhance platform functionality, such as improving the user interface and managing resources.  \\n- Story 5 addresses the deletion of account information for user protection when accounts are banned or removed.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.8571\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'security', 'identification']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions**:  \\n- Collect  \\n- Use  \\n- Share  \\n- Process  \\n- Delete  \\n\\n**Data Types**:  \\n- Contact Data:  \\n  - Email address  \\n  - Name  \\n- Account Information:  \\n  - Password  \\n  - User id  \\n  - Username  \\n  - Messages  \\n  - Friends  \\n- Usage Data:  \\n  - App Interactions:  \\n    - Pages Visited  \\n    - Interaction with Ads  \\n  - Device Information:  \\n    - IP Address  \\n    - Browser  \\n    - Operating System  \\n- Social Media  \\n- Health Data  \\n  - Physical activity  \\n\\n**Purposes**:  \\n- Accounts  \\n- Security  \\n- Functionality  \\n- Customization  \\n- Contact  \\n\\n**Stories**:  \\n1. We collect email address, name, and account information for accounts and contact purposes.  \\n2. We process email addresses, passwords, and user preferences for accounts and security purposes.  \\n3. We delete account information and messages for user protection and functionality purposes.  \\n4. We use device information and app interactions for functionality and customization purposes.  \\n5. We collect and process social media activity for contact and customization purposes.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**\\n1. Collect\\n2. Use\\n3. Share\\n\\n**Data Types:**\\n1. Usage Data:\\n   - App Interactions:\\n     - Session ID\\n     - Pages Visited\\n   - Device Information:\\n     - IP Address\\n2. Contact Data:\\n   - Email Address\\n   - Name\\n3. Account Information:\\n   - User ID\\n   - Username\\n\\n**Purposes:**\\n1. Security\\n2. Functionality\\n3. Analytics\\n\\n**Stories:**\\n1. We collect usage data (Session ID, Pages Visited) for functionality.\\n2. We use device information (IP Address) for security.\\n3. We share contact data (Email Address, Name) for analytics.\\n4. We collect account information (User ID, Username) for functionality.\\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics', 'functionality']\n",
      "  Matched Labels: {'functionality', 'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n\\n#### Data Types:\\n- Usage Data:\\n  - App Interactions:\\n    - Session ID\\n    - Pages Visited\\n  - Device Information:\\n    - IP Address\\n  - Diagnostics:\\n  - Browsing history:\\n- Contact Data:\\n  - Email address:\\n- Account Information:\\n  - Username:\\n\\n#### Purposes:\\n- Functionality\\n- Security\\n- Analytics\\n- Requirements\\n\\n#### Stories:\\n1. We collect and use Session ID, IP Address, and other app interaction data for Functionality and Security.\\n2. We collect and use browsing history and diagnostics data for Functionality and Analytics.\\n3. We collect and use email addresses and usernames for Requirements and Analytics.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Share  \\n\\n**Data Types:**  \\n- Contact Data:  \\n  - Email address  \\n  - Username  \\n  - Name  \\n- Account Information:  \\n  - Password  \\n  - Messages  \\n- Usage Data:  \\n  - Pages Visited  \\n  - Device Information: IP Address  \\n\\n**Purposes:**  \\n- Accounts  \\n- Functionality  \\n- Security  \\n- Contact  \\n\\n**Stories:**  \\n1. We collect email addresses for account registration and password reset purposes.  \\n2. We collect username and password for account creation and security.  \\n3. We collect and use email addresses for sending notifications and password recovery.  \\n4. We collect and use account information such as username and messages for functionality, like enabling communication and interaction.  \\n5. We collect and use device information, including IP address, for security and functionality purposes.  \\n6. We use usernames for display and interaction purposes within the platform.  \\n7. We share account-related data across instances to enable federated interactions.  \\n\\n---\\n\\n### Rationale \n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'functionality', 'authenticate']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n- Share\\n\\n#### Data Types:\\n- Contact Data:\\n  - Email Address\\n  - Username\\n  - Password\\n  - Display name\\n  - Bio\\n  - Avatar\\n  - Banner\\n- Account Information:\\n  - Account Balance\\n  - Messages\\n- Usage Data:\\n  - Device Information:\\n    - IP Address\\n  - App Interactions:\\n    - Timestamps\\n\\n#### Purposes:\\n- Accounts\\n- Contact\\n- Functionality\\n- Requirements\\n- Analytics\\n\\n#### Stories:\\n1. We collect email address, username, and password for account creation and management.\\n2. We use email address for password resets and notifications.\\n3. We collect and use display names, bio, avatar, and banner for profile customization and public display.\\n4. We process email address and account information for contact purposes.\\n5. We collect and use app interactions (timestamps) for analytics purposes.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'functionality', 'customization'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**\\n1. Collect  \\n2. Use  \\n3. Share  \\n\\n**Data Types:**\\n1. Username  \\n2. Password  \\n3. Email Address  \\n4. Avatar (Image)  \\n5. Profile Preferences (Customizations)  \\n\\n**Purposes:**\\n1. Account Management  \\n2. Authentication  \\n3. Functionality  \\n4. Customization  \\n5. Security  \\n\\n**Stories:**\\n1. We collect Username, Password, and Email Address for Account Management.  \\n2. We use Password and Email Address for Authentication.  \\n3. We use Avatar (Image) for Customization and Functionality.  \\n4. We use Profile Preferences for Customization and improved User Functionality.  \\n5. We use Password for Security by enforcing strong password policies and checking against leaked passwords.  \\n6. We share Avatar (Image) with Gravatar for functionality and profile enhancement.  \\n\\n---\\n\\n### Rationale:\\n\\n**Actions:**\\n1. **Collect:** Data such as Username, Password, and Email Address is explicitly mentioned as being entered during account creation or profile updates.  \\n2. **Use:** The text outlines various uses of data, such as authentication, customization, and functionality (e.g., enabling notifications or applying themes).  \\n3. **Share:** Sharing of the Avatar (Image) with Gravatar is explicitly mentioned.  \\n\\n**Data Types:**\\n1. **Username:** Explicitly collected during account creation and used as a unique identifier.  \\n2. **Password:** Collected during registration and used for authentication and security purposes.  \\n3. **Email Address:** Collected for account recovery, notifications, and Gravatar integration.  \\n4. **Avatar (Image):** Users can upload an image to personalize their profile, which is shared with Gravatar if not using a custom avatar.  \\n5. **Profile Preferences:** Includes settings like language, themes, playback preferences, and notifications, which customize the user experience.  \\n\\n**Purposes:**\\n1. **Account Management:** Data like Email Address, Username, and Password are used for creating and maintaining user accounts.  \\n2. **Authentication:** Password and Email Address are used to authenticate users and ensure account security.  \\n3. **Functionality:** Preferences and settings optimize user experience, such as enabling notifications and playback features.  \\n4. **Customization:** Avatar (Image) and themes allow users to personalize their profiles.  \\n5. **Security:** Password policies ensure accounts are secured, and leaked password checks are performed to protect users.  \\n\\n**Stories:**\\nThe stories are derived from the interaction of actions, data types, and purposes. For example:  \\n- \\\"We collect Username, Password, and Email Address for Account Management\\\" ties together the action (Collect), data types (Username, Password, Email Address), and purpose (Account Management).  \\n- \\\"We share Avatar (Image) with Gravatar for functionality and profile enhancement\\\" reflects the sharing action and its purpose of improving profile customization.  \\n\\nThese annotations align with the categories provided and comprehensively cover the privacy-related behaviors described in the text.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'identification', 'customization']\n",
      "  Matched Labels: {'customization'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Username  \\n- Email address  \\n- Password  \\n- Avatar (Image)  \\n\\n**Purposes:**  \\n- Account Management  \\n- Authentication  \\n- Customization  \\n\\n**Stories:**  \\n1. We collect Username, Email address, and Password for Account Management.  \\n2. We use Username, Email address, and Password for Authentication.  \\n3. We collect and use Avatar (Image) for Customization.  \\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Share  \\n\\n**Data Types:**  \\n- Health Data:  \\n  - Physical activity: (e.g., clinical data in CCR or CCD format)  \\n- Contact Data:  \\n  - Email address: (e.g., recipient's Direct address)  \\n- Usage Data:  \\n  - Timestamps: (e.g., log of data transmissions with date and time)  \\n\\n**Purposes:**  \\n- Security  \\n- Contact  \\n- Functionality  \\n\\n**Stories:**  \\n1. We collect health data for functionality.  \\n2. We use contact data for contact purposes.  \\n3. We use usage data for security purposes.  \\n4. We share health data for contact purposes.  \\n\\n---\\n\\n**Rationale:**  \\n\\n1. **Actions:**  \\n   - The text discusses collecting clinical data (CCR/CCD) and transmitting it securely, which involves collection and sharing.  \\n   - It also involves using contact data (Direct address) and usage data (timestamps/logs) for functionality, security, and contact purposes.  \\n\\n2. **Data Types:**  \\n   - Health Data (Physical activity): References to \\\"clinical data\\\" in CCR/CCD formats are examples of health-related data.  \\n   - Contact Data (Email address): The Direct address is a contact data type used for the transmission of messages.  \\n   - Usage Data (Timestamps): The logging of data transmissions with date and time involves usage data.  \\n\\n3. **Purposes:**  \\n   - Security: The text repeatedly mentions ensuring secure messaging and verifying server connections.  \\n   - Contact: The primary purpose of the Direct messaging system is to enable communication between healthcare providers or patients.  \\n   - Functionality: Features like enabling transmission, logging, and categorizing documents are aimed at improving the application's functionality.  \\n\\n4. **Stories:**  \\n   - The collection of health data (CCR/CCD) is necessary for the application's functionality, ensuring that medical professionals can access and transmit clinical information.  \\n   - Contact data (email address/Direct address) is used to facilitate communication between users for contact purposes.  \\n   - Usage data, such as timestamps, is used to ensure security by logging and tracking data transmissions.  \\n   - Sharing health data is necessary for communication with other healthcare providers or systems, fulfilling the contact purpose.  \\n\\nThe annotations and rationale align with the details provided in the text and maintain adherence to the specified categories.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['compliance', 'functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Health Data:  \\n  - Physical activity  \\n\\n**Purposes:**  \\n- Security  \\n- Functionality  \\n\\n**Stories:**  \\n1. We collect health data for security.  \\n2. We use health data for functionality.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**\\n- Share\\n- Collect\\n- Process\\n\\n**Data Types:**\\n- Health Data:\\n  - Protected health information (PHI)\\n  - Clinical data (CCR, CCD)\\n- Contact Data:\\n  - Email address\\n  - Username\\n  - Password\\n- Usage Data:\\n  - App interactions (e.g., patient portal usage, transmission logs)\\n  - Device Information (e.g., server configuration)\\n- Tracking:\\n  - Cookies\\n- Account Information:\\n  - Account Balance\\n  - Messages\\n\\n**Purposes:**\\n- Compliance\\n- Functionality\\n- Security\\n- Contact\\n\\n**Stories:**\\n1. We share health data, email address, and messages for compliance.\\n2. We collect health data, email address, and usage data for functionality.\\n3. We process health data, email address, and app interactions for compliance.\\n4. We process device information for security.\\n5. We share account balance and messages for contact purposes.\\n\\n---\\n\\n**Rationale:**\\n\\n1. **Actions:**\\n   - \\\"Share\\\" is identified when PHI, clinical data, and other information are transmitted to external systems or recipients.\\n   - \\\"Collect\\\" is noted in instances where data (e.g., PHI from reports, configuration details) is gathered or stored.\\n   - \\\"Process\\\" applies to situations where data is interpreted, validated, or used in the context of compliance, functionality, or security.\\n\\n2. **Data Types:**\\n   - Health Data: PHI and clinical data (CCR, CCD) are explicitly mentioned as being transmitted and processed.\\n   - Contact Data: Email addresses (used for notifications), usernames, and passwords (used for account access and configuration) are collected and shared.\\n   - Usage Data: Logs of data transmissions, app interactions like message checks, and device information related to server configurations are processed.\\n   - Tracking: Cookies appear to be relevant for managing sessions and ensuring functionality.\\n   - Account Information: Messages (Direct Messaging feature) and account balances (related to usage scenarios) are included.\\n\\n3. **Purposes:**\\n   - Compliance: Many references to compliance with Direct messaging standards and MU2 criteria are present.\\n   - Functionality: Data like PHI and clinical reports are shared or processed for the system's functionality (e.g., CCR/CCD transmission).\\n   - Security: Installation of trust anchor certificates and securing server connections (SSL) reflect security purposes.\\n   - Contact: Notifications and messages to users signify contact purposes.\\n\\n4. **Stories:**\\n   - The stories tie together actions, data types, and purposes in a logical sequence. For example, sharing health data and messages is tied to compliance (Direct messaging protocols), while collecting and processing email addresses or app interactions serves functionality and security needs.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**  \\n1. Collect  \\n2. Use  \\n3. Share  \\n\\n**Data Types:**  \\n1. Health Data:  \\n   - Protected Health Information (PHI)  \\n2. Contact Data:  \\n   - Email Address  \\n   - Username  \\n3. Usage Data:  \\n   - App Interactions: Pages Visited  \\n   - Timestamps  \\n   - Diagnostics  \\n\\n**Purposes:**  \\n1. Contact  \\n2. Security  \\n3. Functionality  \\n4. Compliance  \\n\\n**Stories:**  \\n1. We collect health data and contact data for compliance.  \\n2. We use health data and contact data for contact purposes.  \\n3. We share health data for compliance and functionality.  \\n4. We process usage data for security and functionality.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Contact Data:  \\n  - Email address  \\n  - Name  \\n  - Address  \\n- Biographical Data:  \\n  - Employment  \\n  - CV  \\n- Account Information:  \\n  - Username  \\n  - Password  \\n\\n**Purposes:**  \\n- Functionality  \\n- Contact  \\n- Accounts  \\n\\n**Stories:**  \\n1. We collect Email address, Username, and Password for account creation and authentication purposes.  \\n2. We use Email address for sending reminders and notifications as part of functionality.  \\n3. We collect and use Name, Address, and Email address for managing personal relationships and organizing data.  \\n4. We collect CV and Employment details to allow users to document life events and relationships.  \\n\\n---\\n\\n### Rationale:  \\n\\n1. **Actions:**  \\n   - \\\"Collect\\\" is evident as the text describes the process of users entering their personal details (email, username, password) during account creation or adding contact information.  \\n   - \\\"Use\\\" is annotated as the system uses the collected data for functionalities such as sending reminders, managing interactions, and enabling account-related features.  \\n\\n2. **Data Types:**  \\n   - **Email address:** Explicitly mentioned as required for reminders, password resets, and notifications.  \\n   - **Name, Address:** Mentioned as part of user-provided contact information for documenting relationships.  \\n   - **Username, Password:** Required for account creation and login authentication.  \\n   - **CV, Employment:** Referenced in the context of documenting life events and relationships.  \\n\\n3. **Purposes:**  \\n   - **Functionality:** The data is used to enable core features like reminders, organization of personal details, and managing life interactions.  \\n   - **Contact:** Email is used for communication like sending reminders or notifications.  \\n   - **Accounts:** Username and password are used for account setup and secure authentication.  \\n\\n4. **Stories:**  \\n   - The stories logically combine the actions, data types, and purposes identified. For example, the collection of a username and password clearly serves the purpose of account management and functionality. Similarly, email addresses are utilized for notifications, which aligns with the purpose of functionality.  \\n\\nThis structured annotation captures the essence of the text while aligning with the provided categories.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['contact', 'customization', 'access']\n",
      "  Matched Labels: {'contact'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations\\n\\n**Actions:**\\n- Collect  \\n- Use  \\n\\n**Data Types:**\\n- Contact Data:  \\n  - Name  \\n  - Address  \\n  - Email address  \\n- Biographical Data:  \\n  - CV  \\n  - Employment  \\n  - Education  \\n- Usage Data:  \\n  - App Interactions: Pages Visited  \\n- Account Information:  \\n  - Username  \\n  - Password  \\n\\n**Purposes:**\\n- Contact  \\n- Functionality  \\n- Requirements  \\n\\n**Stories:**\\n1. We collect Name, Address, Email Address, Username, and Password to facilitate account creation and functionality.  \\n2. We use Email Address for sending reminders and notifications to users for contact purposes.  \\n3. We collect CV, Employment, and Education for organizing and managing personal and professional relationships.  \\n4. We use Pages Visited to improve functionality and enhance user interaction with the service.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations\\n\\nActions:  \\n- Use  \\n- Process  \\n\\nData Types:  \\n- Usage Data:  \\n  - Pages Visited  \\n  - Timestamps  \\n  - Interaction with Ads  \\n  - User Engagement  \\n\\nPurposes:  \\n- Security  \\n- Functionality  \\n\\nStories:  \\n1. We use usage data (Pages Visited, Timestamps, Interaction with Ads, User Engagement) for security.  \\n2. We process usage data (Pages Visited, Timestamps, Interaction with Ads, User Engagement) for functionality.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'compliance', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n1. Use  \\n2. Process  \\n3. Collect  \\n\\n**Data Types:**  \\n1. Usage Data: App Interactions  \\n2. Usage Data: Device Information  \\n3. Account Information: User ID  \\n\\n**Purposes:**  \\n1. Functionality  \\n2. Security  \\n\\n**Stories:**  \\n1. We use usage data to ensure functionality.  \\n2. We process usage data for security purposes.  \\n3. We collect user IDs for account management.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n\\n**Data Types:**  \\n- Email address  \\n- Usage Data  \\n  - Session ID  \\n  - Device time  \\n\\n**Purposes:**  \\n- Functionality  \\n- Authentication  \\n\\n**Stories:**  \\n1. We collect Email address and Usage Data for functionality.  \\n2. We use Email address and Usage Data for authentication.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'health analysis', 'customization', 'functionality', 'health analysis', 'customization']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\nCollect, Use\\n\\n**Data Types:**  \\n- Email address  \\n- User ID  \\n- Usage Data: Session ID, Timestamps  \\n\\n**Purposes:**  \\nFunctionality, Authentication, Analytics  \\n\\n**Stories:**  \\n1. We collect and use Email address and User ID for authentication.  \\n2. We collect and use Usage Data, like Session ID and Timestamps, for functionality.  \\n3. We collect and use Usage Data, like Session ID and Timestamps, for analytics.\\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n1. Collect  \\n2. Use  \\n3. Share  \\n\\n**Data Types:**  \\n1. Email address  \\n2. Username  \\n3. Password  \\n4. Role  \\n5. User ID  \\n6. Video Quota  \\n7. Daily Video Quota  \\n\\n**Purposes:**  \\n1. Account management  \\n2. Authentication  \\n3. Functionality  \\n4. Security  \\n\\n**Stories:**  \\n1. We collect email address, username, and password for account management.  \\n2. We use email address and username for authentication.  \\n3. We collect and use role, user ID, and quotas (video quota, daily video quota) for functionality and security.  \\n4. We share video abuse reports (reporter, abuse report date, video title) for moderation and security purposes.  \\n\\n---\\n\\n### Rationale:  \\n\\n**Actions:**  \\n1. **Collect:** The text explicitly mentions collecting data such as email address, username, password, and other user information during registration and while managing user accounts.  \\n2. **Use:** The collected data is used for various purposes, including account authentication, managing roles, and enabling functionality like video uploads, commenting, and reporting abuse.  \\n3. **Share:** Video abuse reports are shared with moderators for review and action, which includes information such as abuse report details and associated users.  \\n\\n**Data Types:**  \\n1. **Email address, Username, Password:** These are fundamental data points collected during registration and used for authentication and account management.  \\n2. **Role:** Defines levels of permissions for administrators, moderators, and users.  \\n3. **User ID:** Required for user identification and management.  \\n4. **Video Quota, Daily Video Quota:** These are specific data points that limit the amount of video content users can upload, ensuring fair resource allocation and functionality.  \\n\\n**Purposes:**  \\n1. **Account management:** Data like email address, username, and password are collected to create and manage user accounts.  \\n2. **Authentication:** Password and email address are used to authenticate users and reset passwords.  \\n3. **Functionality:** Role, user ID, and quotas are used to enable specific functionalities like uploading videos, creating playlists, and moderating content.  \\n4. **Security:** Abuse reports and quotas help maintain the security and proper functioning of the platform by addressing misuse and managing resources.  \\n\\n**Stories:**  \\n1. \\\"We collect email address, username, and password for account management\\\" is derived from the registration process, where these data types are entered to create user accounts.  \\n2. \\\"We use email address and username for authentication\\\" reflects their use for password resets and account access.  \\n3. \\\"We collect and use role, user ID, and quotas (video quota, daily video quota) for functionality and security\\\" captures the role-based permissions and quota limits to manage platform resources and prevent misuse.  \\n4. \\\"We share video abuse reports (reporter, abuse report date, video title) for moderation and security purposes\\\" highlights the sharing of abuse report details with moderators to handle violations and ensure platform security.  \\n\\nThe annotations align with the categories provided and reflect the privacy behaviors described in the text.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['account management', 'user protection']\n",
      "  Matched Labels: {'account management'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Share  \\n\\n**Data Types:**  \\n- Account Information:  \\n  - Username  \\n  - Password  \\n  - Email address  \\n- Contact Data:  \\n  - Email address  \\n- Usage Data:  \\n  - App Interactions: Pages Visited, Interaction with Ads, Timestamps  \\n  - Device Information: IP Address, Browser  \\n- Tracking: Cookies, Web Beacons  \\n- Content Data: Posts, Comments  \\n\\n**Purposes:**  \\n- Accounts  \\n- Functionality  \\n- Security  \\n- Advertisement  \\n- Analytics  \\n\\n**Stories:**  \\n1. We collect Username, Password, Email address for account creation and management on an instance.  \\n2. We use Email address for authentication, password reset, and notifications purposes.  \\n3. We collect and use Cookies and Web Beacons for tracking and advertisement purposes.  \\n4. We use Pages Visited, Interaction with Ads, and Timestamps for analytics and customization purposes.  \\n5. We collect Posts, Comments, and User Engagement data to improve functionality and maintain engagement on the platform.  \\n6. We collect IP Address and Browser information for security purposes.  \\n\\n---\\n\\n### Rationale:  \\n**Actions:**  \\n1. **Collect:** The text describes the collection of data such as username, password, email, and other optional fields during account registration.  \\n2. **Use:** Data like email is used for authentication, notifications, and other account-related activities. Cookies and tracking mechanisms are used to enhance functionality and deliver advertisements.  \\n3. **Share:** Interaction with federated communities implies data sharing across instances, although the text doesn't explicitly detail this process.  \\n\\n**Data Types:**  \\n1. **Account Information (Username, Password, Email address):** These are explicitly required for registration and account management.  \\n2. **Contact Data (Email address):** Used for notifications and password resets.  \\n3. **Usage Data (App Interactions, Device Information):** Includes Pages Visited, Interaction with Ads, and Timestamps, which are necessary for analytics and engagement. Device data such as IP Address and Browser are mentioned for potential security purposes.  \\n4. **Tracking (Cookies, Web Beacons):** Necessary for tracking and targeted advertisements.  \\n5. **Content Data (Posts, Comments):** Used to engage users and maintain platform functionality.  \\n\\n**Purposes:**  \\n1. **Accounts:** Data is collected and used to create and manage user accounts.  \\n2. **Functionality:** Posts, comments, and user profiles are integral to the platform's functionality.  \\n3. **Security:** IP Address and Browser data are collected for security purposes to protect accounts.  \\n4. **Advertisement and Analytics:** Cookies, Web Beacons, and interaction data are used for targeted advertising and analytics.  \\n\\n**Stories:**  \\nThe stories connect the actions, data types, and purposes. For example, the collection of email addresses, usernames, and passwords is directly tied to account creation and authentication. Tracking mechanisms like cookies are explicitly tied to advertisement and analytics purposes. These stories provide a clear narrative of how personal data is used within the platform’s ecosystem.  \\n\\nThe annotations and stories are based on explicit mentions and inferred purposes in the text, adhering to the categories provided.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.8571\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**\\n- Collect\\n- Use\\n- Share\\n- Delete\\n\\n**Data Types:**\\n- Contact Data:\\n  - Email address\\n  - Username\\n  - User ID\\n  - Name\\n- Account Information:\\n  - Password\\n  - Messages\\n- Usage Data:\\n  - App Interactions:\\n    - User Engagement\\n    - Timestamps\\n  - Device Information:\\n    - IP Address\\n- Financial:\\n  - Payment History\\n  - Purchase History\\n- Analytics:\\n  - Logs\\n  - Events\\n\\n**Purposes:**\\n- Accounts\\n- Security\\n- Analytics\\n- Customization\\n- Functionality\\n- Tracking\\n\\n**Stories:**\\n1. We collect email address, username, and user ID for account creation and management.\\n2. We use email address and name for user communication and account verification.\\n3. We delete account information and associated user content for user protection and security.\\n4. We collect and use app interaction data (e.g., user engagement, timestamps) for analytics purposes.\\n5. We share logs and analytics events with external analytics engines for tracking and customization purposes.\\n6. We collect and process financial data (payment and purchase history) for functionality and financial transactions.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.5000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['analytics']\n",
      "  Matched Labels: {'analytics'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Delete  \\n\\n**Data Types:**  \\n- Contact Data:  \\n  - Email address  \\n  - Username  \\n- Account Information:  \\n  - User ID  \\n  - Password  \\n  - Roles  \\n- Usage Data:  \\n  - App Interactions:  \\n    - User Engagement  \\n- Video  \\n\\n**Purposes:**  \\n- Accounts  \\n- Security  \\n- Functionality  \\n- Analytics  \\n\\n**Stories:**  \\n1. We collect email address, username, user ID, and password for accounts and security.  \\n2. We use roles and user engagement data for functionality and accounts.  \\n3. We delete videos and account information for security.  \\n4. We use app interaction data for analytics.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\nCollect, Use\\n\\n#### Data Types:\\n- Account Information:\\n  - User id\\n  - Username\\n  - Password\\n  - Email Address\\n- Contact Data:\\n  - Phone Number\\n\\n#### Purposes:\\n- Functionality\\n- Accounts\\n- Security\\n\\n#### Stories:\\n1. We collect account information (username, password, user ID, email address) for functionality.\\n2. We use account information (username, password, user ID, email address) for functionality.\\n3. We collect account information (username, password, user ID, email address) for accounts management.\\n4. We use account information (username, password, user ID, email address) for accounts management.\\n5. We collect contact data (phone number) for functionality.\\n6. We use contact data (phone number) for functionality.\\n7. We collect account data (user ID) for security during login and account validation.\\n8. We use account data (user ID) for security during login and account validation.\\n\\n---\\n\\n### Rationale:\\n\\n#### Actions:\\n- **Collect** is annotated because the system needs to gather user input (username, password, email address, phone number, etc.) during login, registration, and account setup processes.\\n- **Use** is annotated because the collected data is actively processed for authentication, user management, and security checks during these operations.\\n\\n#### Data Types:\\n- The **Account Information** category is chosen due to references to usernames, passwords, user IDs, and email addresses for logging in and account management.\\n- The **Contact Data** category is chosen because phone numbers and email addresses are explicitly mentioned and processed in third-party identifier binding and registration workflows.\\n\\n#### Purposes:\\n- **Functionality** is selected because the main goal of these modules is to enable basic system operations such as logging in, account setup, and data updates.\\n- **Accounts** is added as a purpose because account management tasks like registration and username assignment are explicitly described.\\n- **Security** is included as the purpose for authentication-related processes, such as validating user credentials and ensuring secure logins.\\n\\n#### Stories:\\nThe stories are constructed to reflect the interaction between actions (collect, use), data types (account information, contact data), and purposes (functionality, accounts, security). For example:\\n- **Story 1** highlights collecting account information for operational functionality like login.\\n- **Story 2** extends this to using collected data for the same purpose.\\n- **Story 7** and **Story 8** emphasize security as a purpose when handling sensitive data like user IDs during authentication.\"\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n1. **Actions**: Collect, Use  \\n   **Data Types**: Username, Password, Email address  \\n   **Purposes**: Log in  \\n   **Story**: We collect and use username, password, and email address for the purpose of logging in.  \\n   \\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n1. Collect\\n2. Use\\n\\n#### Data Types:\\n1. Account Information:\\n   - Username\\n   - Password\\n   - Email\\n2. Phone Number\\n3. User ID\\n\\n#### Purposes:\\n1. Log in\\n2. Account open\\n3. Functionality\\n4. Account management\\n\\n#### Stories:\\n1. We collect account information (e.g., username, email, and password) for logging in and account management.  \\n2. We use account information (e.g., username, email, and password) for logging in and account management.  \\n3. We collect phone numbers and user IDs to support functionality and account creation processes.  \\n4. We use phone numbers and user IDs to enable functionality and manage user accounts.  \\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['security', 'account management', 'functionality']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n1. Collect\\n2. Use\\n\\n#### Data Types:\\n1. Account Information:\\n   - Username\\n   - Password\\n   - Email Address\\n   - Access token\\n   - Device ID\\n2. Phone Number\\n\\n#### Purposes:\\n1. Log in\\n2. Log out\\n3. Account open\\n4. Functionality\\n5. Account management\\n\\n#### Stories:\\n1. We collect and use account information (username, password, email address, access token, device ID) for logging in.\\n2. We collect and use account information (username, password, email address, access token, device ID) for logging out.\\n3. We collect and use account information (username, password, email address, access token, device ID, phone number) for account opening.\\n4. We collect and use account information (username, password, email address, phone number) for functionality.\\n5. We collect and use account information (username, password, email address, phone number) for account management.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: set()\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations\\n\\n**Actions:**  \\nCollect, Use  \\n\\n**Data Types:**  \\n- Account Information:  \\n  - Username  \\n  - Password  \\n  - Email Address  \\n\\n**Purposes:**  \\n- Log In  \\n- Log Out  \\n- Account Open  \\n\\n**Stories:**  \\n1. We collect and use account information (username, password, email) for log-in purposes.  \\n2. We collect and use account information (username, password) for log-out purposes.  \\n3. We collect and use account information (username) for account opening purposes.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.6667\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 0.8000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'account management']\n",
      "  Matched Labels: {'functionality', 'account management'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n\\n#### Data Types:\\n- Account Information:\\n  - Username\\n  - Password\\n  - Email address\\n\\n#### Purposes:\\n- Login\\n- Logout\\n- Account Management\\n- Security\\n- Functionality\\n\\n#### Stories:\\n1. **We collect and use account information (username, password, email address) for login purposes.**\\n2. **We collect and use account information (username, password) for logout purposes.**\\n3. **We collect and use account information for account management.**\\n4. **We collect and use account information for security purposes.**\\n5. **We collect and use account information for functionality purposes.**\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\nCollect, Use  \\n\\n**Data Types:**  \\nAccount Information:  \\n  User id:  \\n  Username:  \\n  Messages:  \\n\\n**Purposes:**  \\nFunctionality, Security  \\n\\n**Stories:**  \\n1. We collect user id, username, and messages for functionality.  \\n2. We use user id, username, and messages for security.  \\n\\n---\\n\\n**Rationale:**  \\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'authentication', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"Actions:  \\n- Collect  \\n- Use  \\n\\nData Types:  \\n- Contact Data: Email Address  \\n- Account Information: User ID, Session ID  \\n\\nPurposes:  \\n- Functionality  \\n- Customization  \\n- Security  \\n\\nStories:  \\n1. We collect the Email Address, User ID, and Session ID for functionality.  \\n2. We use the Email Address, User ID, and Session ID for customization and security.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n- Distribute\\n\\n#### Data Types:\\n- Contact Data:\\n  - Email address:\\n  - User ID:\\n- Messages:\\n- Account Information:\\n  - User ID:\\n\\n#### Purposes:\\n- Notification\\n- Functionality\\n\\n#### Stories:\\n1. We collect email address and user ID for notification purposes.  \\n2. We distribute messages for functionality purposes.  \\n3. We use user ID and messages for notification purposes.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.4000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'security', 'functionality', 'authentication']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Share  \\n\\n**Data Types:**  \\n- Contact Data:  \\n  - Email address  \\n  - Name  \\n- Account Information:  \\n  - Session ID  \\n- Usage Data:  \\n  - Timestamps  \\n  - Interaction with Ads  \\n- Messages  \\n\\n**Purposes:**  \\n- Functionality  \\n- Contact  \\n- Customization  \\n\\n**Stories:**  \\n1. We collect Name, Email address, and Session ID for functionality.  \\n2. We use Timestamps and Interaction with Ads for customization.  \\n3. We share Messages for contact.\\n\\n---\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality', 'security'}\n",
      "  F1 Score: 0.8000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"**Annotations:**\\n\\n**Actions:**  \\nCollect, Use  \\n\\n**Data Types:**  \\nContact Data: Email Address, User ID  \\nAccount Information: Username  \\nUsage Data: App Interactions, Session ID  \\n\\n**Purposes:**  \\nFunctionality, Security, Authentication  \\n\\n**Stories:**  \\n1. We collect session IDs for authentication.  \\n2. We use email addresses and usernames for functionality.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.6667\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['functionality', 'customization', 'security', 'functionality', 'customization', 'security']\n",
      "  Matched Labels: {'functionality'}\n",
      "  F1 Score: 0.5000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**\\n- Collect\\n- Use\\n\\n**Data Types:**\\n- Email Address\\n- Session ID\\n- Username\\n\\n**Purposes:**\\n- Functionality\\n- Authentication\\n\\n**Stories:**\\n1. We collect email addresses for functionality.\\n2. We collect session IDs for authentication.\\n3. We use usernames for functionality.\\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security'}\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n**Actions:**  \\n- Collect  \\n- Use  \\n- Share  \\n\\n**Data Types:**  \\n- Health Data:  \\n  - Physical activity  \\n- Contact Data:  \\n  - Email Address  \\n  - Username  \\n  - Password  \\n  - User ID  \\n- Financial:  \\n  - Payment History  \\n  - Purchase History  \\n- Usage Data:  \\n  - App Interactions:  \\n    - Pages Visited  \\n    - Timestamps  \\n  - Device Information:  \\n    - IP Address  \\n    - Device ID  \\n    - Advertisement ID  \\n    - Browser  \\n    - Operating System  \\n    - Diagnostics  \\n    - Browsing History  \\n- Account Information:  \\n  - User ID  \\n  - Username  \\n  - Password  \\n  - Friends  \\n\\n**Purposes:**  \\n- Security  \\n- Functionality  \\n- Compliance  \\n- Analytics  \\n\\n**Stories:**  \\n1. We share health data and contact data for functionality.  \\n2. We collect health data and usage data for functionality.  \\n3. We collect financial data for compliance.  \\n4. We use usage data for analytics.  \\n5. We process account information and contact data for security.  \\n\\n\n",
      "\n",
      "Category Diagnostics:\n",
      "Actions:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "Data_types:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "Purposes:\n",
      "  Ground Truth Labels: ['tracking', 'security']\n",
      "  Matched Labels: {'security', 'tracking'}\n",
      "  F1 Score: 1.0000\n",
      "\n",
      "Preprocessed Text:\n",
      "\"### Annotations:\\n\\n#### Actions:\\n- Collect\\n- Use\\n- Share\\n- Process\\n\\n#### Data Types:\\n- Contact Data:\\n  - Email Address\\n  - User ID\\n  - Password\\n- Health Data:\\n  - Physical activity\\n- Usage Data:\\n  - App Interactions:\\n    - Pages Visited\\n    - Timestamps\\n    - User Engagement\\n  - Device Information:\\n    - IP Address\\n    - Advertisement ID\\n    - Diagnostics\\n- Tracking:\\n  - Cookies\\n  - Tags\\n- Account Information:\\n  - Username\\n  - Messages\\n\\n#### Purposes:\\n- Compliance\\n- Functionality\\n- Security\\n- Tracking\\n- Analytics\\n\\n#### Stories:\\n1. We collect and use email addresses and passwords for functionality and security.\\n2. We share health data for compliance and functionality.\\n3. We collect and use user IDs, app interactions (timestamps, pages visited), and device information for analytics and functionality.\\n4. We process account information (usernames, messages) and usage data for security and functionality.\\n5. We track cookies and tags for analytics and tracking purposes.\\n\\n---\\n\\n### Rationale:\\n\\n#### Actions:\\nThe text involves **Collecting** and **Using** data, such as email addresses, passwords, and metadata, for functionalities like account management and compliance. It also involves **Sharing** data (e.g., health data via Direct Messaging) and **Processing** data for security, analytics, and functionality purposes, as seen in the workflows for Direct Messaging and push notification services.\\n\\n#### Data Types:\\nThe data types identified include:\\n- **Contact Data**: Email addresses and user IDs are mentioned explicitly in contexts like authentication and registration.\\n- **Health Data**: The text discusses clinical data (e.g., CCR or CCD files).\\n- **Usage Data**: Includes app interactions like pages visited, timestamps, and user engagement, as well as device information like IP addresses, diagnostics, and advertisement IDs.\\n- **Tracking**: Cookies and tags are used for analytics and tracking purposes.\\n- **Account Information**: Includes usernames and messages, which are processed for notifications and functionality.\\n\\n#### Purposes:\\nThe data is used for:\\n- **Compliance**: Sharing health data aligns with regulatory requirements.\\n- **Functionality**: Services like Direct Messaging and push notifications rely on data to function.\\n- **Security**: Protecting metadata and managing encrypted connections are security-focused actions.\\n- **Tracking**: Tracking cookies and tags are mentioned for monitoring purposes.\\n- **Analytics**: Usage statistics and metadata uploads are analyzed for service improvement.\\n\\n#### Stories:\\nThe privacy stories are synthesized to connect the actions, data types, and purposes:\\n1. **Email and password** collection and usage are necessary for account management and security.\\n2. **Health data** sharing supports compliance with regulations and ensures functionality in transmitting medical records.\\n3. **User IDs** and **app interactions** are collected and analyzed to improve user experience and functionality.\\n4. **Account information** is processed to enhance security and ensure proper notification services.\\n5. **Cookies and tags** tracking is employed for analytics and monitoring purposes.\\n\\nThese annotations and connections are based on explicit details in the provided text. The text describes workflows and functionalities that align with these categories, ensuring adherence to privacy and security standards while delivering the described services.\"\n",
      "\n",
      "Annotation F1 Scores:\n",
      "File: Accounts_&_Transactions.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: Accounts_&_Transactions.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6333\n",
      "----------------------------------------\n",
      "File: CreatingAnewAccount.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.3333\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.7778\n",
      "----------------------------------------\n",
      "File: CreatingAnewAccount.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.6667\n",
      "----------------------------------------\n",
      "File: features.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.6667\n",
      "----------------------------------------\n",
      "File: features.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.5556\n",
      "----------------------------------------\n",
      "File: add_threePids.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6222\n",
      "----------------------------------------\n",
      "File: add_threePids.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.9091\n",
      "Overall F1 Score: 0.7030\n",
      "----------------------------------------\n",
      "File: account-basics.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.7222\n",
      "----------------------------------------\n",
      "File: account-basics.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9333\n",
      "----------------------------------------\n",
      "File: signups.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.7222\n",
      "----------------------------------------\n",
      "File: signups.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6111\n",
      "----------------------------------------\n",
      "File: userdetails.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: userdetails.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.8571\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.7857\n",
      "----------------------------------------\n",
      "File: configurations.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9333\n",
      "----------------------------------------\n",
      "File: configurations.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8333\n",
      "----------------------------------------\n",
      "File: Getting Started.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.7667\n",
      "----------------------------------------\n",
      "File: Getting Started.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.7667\n",
      "----------------------------------------\n",
      "File: profile-preferences.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.7556\n",
      "----------------------------------------\n",
      "File: profile-preferences.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6556\n",
      "----------------------------------------\n",
      "File: Direct_Messaging_README.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8667\n",
      "----------------------------------------\n",
      "File: Direct_Messaging_README.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: Navigation.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 1.0000\n",
      "----------------------------------------\n",
      "File: Navigation.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 1.0000\n",
      "----------------------------------------\n",
      "File: README.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6333\n",
      "----------------------------------------\n",
      "File: README.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.6333\n",
      "----------------------------------------\n",
      "File: Architecture.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.4889\n",
      "----------------------------------------\n",
      "File: Architecture.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: data-structure.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.3889\n",
      "----------------------------------------\n",
      "File: data-structure.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.5000\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.5556\n",
      "----------------------------------------\n",
      "File: managing-users.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.7556\n",
      "----------------------------------------\n",
      "File: managing-users.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.8000\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.7556\n",
      "----------------------------------------\n",
      "File: analyrics-events.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.8571\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.9524\n",
      "----------------------------------------\n",
      "File: analyrics-events.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.5000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.7222\n",
      "----------------------------------------\n",
      "File: account_data_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: account_data_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "File: account_validity_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.9333\n",
      "----------------------------------------\n",
      "File: account_validity_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.6000\n",
      "----------------------------------------\n",
      "File: password_auth_provider_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 0.0000\n",
      "Overall F1 Score: 0.4889\n",
      "----------------------------------------\n",
      "File: password_auth_provider_callbacks.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 0.6667\n",
      "data_types F1 Score: 0.8000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: DatabaseSchema.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.5556\n",
      "----------------------------------------\n",
      "File: DatabaseSchema.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.7778\n",
      "----------------------------------------\n",
      "File: INotificationDistributor.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6889\n",
      "----------------------------------------\n",
      "File: INotificationDistributor.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.4000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.6889\n",
      "----------------------------------------\n",
      "File: INotificationSubscriber.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.8000\n",
      "Overall F1 Score: 0.8222\n",
      "----------------------------------------\n",
      "File: INotificationSubscriber.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 0.6667\n",
      "purposes F1 Score: 0.5000\n",
      "Overall F1 Score: 0.7222\n",
      "----------------------------------------\n",
      "File: file.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 1\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 0.6667\n",
      "Overall F1 Score: 0.8889\n",
      "----------------------------------------\n",
      "File: file.txt\n",
      "Model: openai:gpt-4o-2024-11-20\n",
      "Response: Model Response 2\n",
      "actions F1 Score: 1.0000\n",
      "data_types F1 Score: 1.0000\n",
      "purposes F1 Score: 1.0000\n",
      "Overall F1 Score: 1.0000\n",
      "----------------------------------------\n",
      "Results saved to annotation_f1_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Dict, List, Set\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class AnnotationEvaluator:\n",
    "    def __init__(self, ontology_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator with the privacy ontology.\n",
    "        \"\"\"\n",
    "        with open(ontology_path, 'r') as f:\n",
    "            self.ontology = json.load(f)\n",
    "    \n",
    "    def _normalize_label(self, label: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Normalize label by removing extra whitespace, converting to lowercase,\n",
    "        and splitting comma-separated values.\n",
    "        \"\"\"\n",
    "        # Split by comma, strip whitespace, convert to lowercase\n",
    "        return [\n",
    "            l.strip().lower() \n",
    "            for l in label.split(',') \n",
    "            if l.strip()\n",
    "        ]\n",
    "    \n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Preprocess text by removing content within or after <R> tags.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to preprocess\n",
    "        \n",
    "        Returns:\n",
    "            str: Preprocessed text\n",
    "        \"\"\"\n",
    "        # Find all <R> tags\n",
    "        r_tags = list(re.finditer(r'<R>(.*?)</R>', text, re.DOTALL))\n",
    "        \n",
    "        if not r_tags:\n",
    "            # If no </R> tags, remove everything after a single <R> tag\n",
    "            single_r_match = re.search(r'<R>', text)\n",
    "            if single_r_match:\n",
    "                return text[:single_r_match.start()]\n",
    "            return text\n",
    "        \n",
    "        # Take the content before the first <R> tag\n",
    "        preprocessed = text[:r_tags[0].start()]\n",
    "        \n",
    "        # Return preprocessed text\n",
    "        return preprocessed.strip()\n",
    "    \n",
    "    def _match_labels(self, text: str, category_labels: List[str]) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Find matching labels in the text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to search\n",
    "            category_labels (List[str]): Labels to match\n",
    "        \n",
    "        Returns:\n",
    "            Set[str]: Matched labels\n",
    "        \"\"\"\n",
    "        # Preprocess text to remove R-tag content\n",
    "        preprocessed_text = self._preprocess_text(text)\n",
    "        \n",
    "        # Normalize text\n",
    "        normalized_text = preprocessed_text.lower()\n",
    "        \n",
    "        # Match labels\n",
    "        matched_labels = set()\n",
    "        \n",
    "        for label in category_labels:\n",
    "            # Various matching strategies\n",
    "            # 1. Whole word match\n",
    "            word_pattern = r'\\b' + re.escape(label) + r'\\b'\n",
    "            # 2. Partial match\n",
    "            partial_pattern = re.escape(label)\n",
    "            \n",
    "            if (re.search(word_pattern, normalized_text) or \n",
    "                re.search(partial_pattern, normalized_text)):\n",
    "                matched_labels.add(label)\n",
    "        \n",
    "        return matched_labels\n",
    "    \n",
    "    def calculate_comprehensive_f1_scores(self, ground_truth: Dict, text: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate F1 scores for all categories.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth (Dict): Ground truth annotations\n",
    "            text (str): Text to evaluate\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, float]: F1 scores\n",
    "        \"\"\"\n",
    "        f1_scores = {}\n",
    "        categories = ['actions', 'data_types', 'purposes']\n",
    "        \n",
    "        for category in categories:\n",
    "            # Extract labels from ground truth\n",
    "            gt_labels = self._normalize_label(', '.join(ground_truth.get(category, [])))\n",
    "            \n",
    "            # Find matching labels in text\n",
    "            pred_labels = self._match_labels(text, gt_labels)\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            y_true = [1 if label in gt_labels else 0 for label in gt_labels]\n",
    "            y_pred = [1 if label in pred_labels else 0 for label in gt_labels]\n",
    "            \n",
    "            try:\n",
    "                # Macro average F1 score\n",
    "                f1 = f1_score(y_true, y_pred, average='binary')\n",
    "            except Exception as e:\n",
    "                print(f\"F1 Score calculation error for {category}: {e}\")\n",
    "                f1 = 0\n",
    "            \n",
    "            f1_scores[category] = f1\n",
    "        \n",
    "        # Calculate overall F1 score\n",
    "        f1_scores['Overall'] = sum(f1_scores.values()) / len(f1_scores)\n",
    "        \n",
    "        # Diagnostic print\n",
    "        print(f\"\\nCategory Diagnostics:\")\n",
    "        for category in categories:\n",
    "            print(f\"{category.capitalize()}:\")\n",
    "            print(f\"  Ground Truth Labels: {gt_labels}\")\n",
    "            print(f\"  Matched Labels: {pred_labels}\")\n",
    "            print(f\"  F1 Score: {f1_scores[category]:.4f}\")\n",
    "        \n",
    "        # Print preprocessed text for verification\n",
    "        print(\"\\nPreprocessed Text:\")\n",
    "        print(self._preprocess_text(text))\n",
    "        \n",
    "        return f1_scores\n",
    "\n",
    "def process_annotation_csv(csv_path: str, ontology_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process the annotation CSV and calculate F1 scores.\n",
    "    \"\"\"\n",
    "    # Initialize the evaluator\n",
    "    evaluator = AnnotationEvaluator(ontology_path)\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    # Read the CSV file\n",
    "    with open(csv_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Parse target annotations\n",
    "                ground_truth = json.loads(row['Target Annotations'])\n",
    "                \n",
    "                # Process both model responses\n",
    "                for response_col in ['Model Response 1', 'Model Response 2']:\n",
    "                    # Extract full text\n",
    "                    full_text = row[response_col]\n",
    "                    \n",
    "                    # Calculate F1 scores\n",
    "                    f1_scores = evaluator.calculate_comprehensive_f1_scores(\n",
    "                        ground_truth['metadata'], \n",
    "                        full_text\n",
    "                    )\n",
    "                    \n",
    "                    # Prepare result dictionary\n",
    "                    result = {\n",
    "                        'File': ground_truth.get('file_name', 'Unknown'),\n",
    "                        'Model': row['Model'],\n",
    "                        'Response': response_col,\n",
    "                        'Metrics': f1_scores\n",
    "                    }\n",
    "                    \n",
    "                    results.append(result)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Paths to your files\n",
    "    csv_path = 'LLMAnnotation_gpt4o-latest.csv'\n",
    "    ontology_path = 'privacy_ontology_simple.json'\n",
    "    \n",
    "    # Process the CSV and calculate F1 scores\n",
    "    results = process_annotation_csv(csv_path, ontology_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nAnnotation F1 Scores:\")\n",
    "    for result in results:\n",
    "        print(f\"File: {result['File']}\")\n",
    "        print(f\"Model: {result['Model']}\")\n",
    "        print(f\"Response: {result['Response']}\")\n",
    "        for category, score in result['Metrics'].items():\n",
    "            print(f\"{category} F1 Score: {score:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # Save results to a CSV\n",
    "    if results:\n",
    "        output_keys = ['File', 'Model', 'Response', 'Actions F1', 'Data Types F1', 'Purposes F1', 'Overall F1']\n",
    "        with open('annotation_f1_scores.csv', 'w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=output_keys)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for result in results:\n",
    "                # Prepare row for CSV\n",
    "                csv_row = {\n",
    "                    'File': result['File'],\n",
    "                    'Model': result['Model'],\n",
    "                    'Response': result['Response'],\n",
    "                    'Actions F1': result['Metrics'].get('actions', 0),\n",
    "                    'Data Types F1': result['Metrics'].get('data_types', 0),\n",
    "                    'Purposes F1': result['Metrics'].get('purposes', 0),\n",
    "                    'Overall F1': result['Metrics'].get('Overall', 0)\n",
    "                }\n",
    "                writer.writerow(csv_row)\n",
    "        \n",
    "        print(\"Results saved to annotation_f1_scores.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge prompting llm outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompt_templates\n",
    "\n",
    "# Generate prompts for a CSV file\n",
    "def generate_prompts_from_csv(csv_file_path: str, output_file_path: str):\n",
    "    \"\"\"Reads a CSV file and generates judge prompts for each row, saving them to an output file.\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        prompts = []\n",
    "\n",
    "        for row in reader:\n",
    "            original_prompt = row.get('original_prompt', '')\n",
    "            response_1 = row.get('response_1', '')\n",
    "            response_2 = row.get('response_2', '')\n",
    "\n",
    "            prompt = prompt_templates.create_judge_prompt(original_prompt, response_1, response_2)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "    # Save prompts to output file\n",
    "    with open(output_file_path, mode='w', encoding='utf-8') as outputfile:\n",
    "        outputfile.write(\"\\n\\n---\\n\\n\".join(prompts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
