{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import text_processing\n",
    "import secrets \n",
    "\n",
    "from typing import List, Dict\n",
    "import openai  # Assuming OpenAI API, but adaptable to other models\n",
    "\n",
    "# Load text file and taxonomy JSON\n",
    "\n",
    "taxonomy_file_path = 'privacy_ontology_simple.json'  # Replace with actual path\n",
    "example_file_path = 'annotations/Actual_Budget/Accounts_&_Transactions.txt'\n",
    "target_file_path = 'input/lh-ehr/Direct_Messaging_README.txt'\n",
    "\n",
    "# Load previously processed example files\n",
    "example_data = text_processing.process_input(example_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a privacy expert annotator tasked with annotating text files with metadata about privacy behaviors and stories. For the given text, annotate the following:\n",
      "\n",
      "1. Actions: Actions performed or expected in the text.\n",
      "2. Data Types: Types of data referenced in the text. Data types may include specific subcategories.\n",
      "3. Purposes: Intentions or purposes related to the actions and data types.\n",
      "4. Stories: Concise stories that describe how actions, data types, and purposes interact in context.\n",
      "\n",
      "After providing your annotations, explain your rationale for these annotations. Place <R> tag between your annotations and your rationale.\n",
      "\n",
      "Use only the categories listed below when annotating:\n",
      "\n",
      "Actions:\n",
      "Collect, Use, Share\n",
      "\n",
      "Data Types:\n",
      "Contact Data:\n",
      "  Phone Number:\n",
      "  Email address:\n",
      "  User ID:\n",
      "  Job Title:\n",
      "  Company:\n",
      "  Address:\n",
      "  Name:\n",
      "  Date of Birth:\n",
      "  Image:\n",
      "  Government ID:\n",
      "  Biographical Data:\n",
      "    CV:\n",
      "    Education:\n",
      "    Employment:\n",
      "Health Data:\n",
      "  Physical activity:\n",
      "Social Media:\n",
      "Location:\n",
      "  Approximate location:\n",
      "  Precise location:\n",
      "Financial:\n",
      "  Orders:\n",
      "  Payment History:\n",
      "  Purchase History:\n",
      "  Order:\n",
      "  Card Data:\n",
      "  Bank Account:\n",
      "  Credit Score:\n",
      "  Income Information:\n",
      "  assets:\n",
      "    vehicle:\n",
      "    Insurance:\n",
      "Usage Data:\n",
      "  App Interactions:\n",
      "    Pages Visited:\n",
      "    Timestamps:\n",
      "    Interaction with Ads:\n",
      "    User Engagement:\n",
      "    Session ID:\n",
      "  Device Information:\n",
      "    IP Address:\n",
      "    Device ID:\n",
      "    Advertisement ID:\n",
      "    Browser:\n",
      "    Operating System:\n",
      "    Diagnostics:\n",
      "    Sensor Data:\n",
      "    Audio:\n",
      "    Browsing history:\n",
      "Tracking:\n",
      "  Cookies:\n",
      "  Web Beacons:\n",
      "  Tags:\n",
      "Account Information:\n",
      "  User id:\n",
      "  Username:\n",
      "  Password:\n",
      "  Account Balance:\n",
      "  Messages:\n",
      "  Friends:\n",
      "\n",
      "Purposes:\n",
      "Contact, Analytics, Customization, Advertisement, Security, Tracking, Functionality, Accounts, Requirements\n",
      "\n",
      "Here is the text:\n",
      "\n",
      "Full Cleaned Text:\n",
      "Using Actual\n",
      "Accounts & Transactions\n",
      "\n",
      "overview\n",
      "\n",
      " You can add as many accounts as you like. Adding all of your accounts (including things like mortgages) is a nice way to get an overview of all your finances.\n",
      "\n",
      "Off-budget accounts\n",
      "â€‹\n",
      "Actual makes a distinction between accounts being\n",
      "for budget or off budget. \n",
      "Off budget accounts don't effect the budget and are meant to track stuff like investments and mortgages. Transactions in off budget accounts can't be categorized; they simply track balances over time.\n",
      "\n",
      "For budget\n",
      "accounts affect the budget, and transactions can be categorized. These are accounts where you want to track cash flow and use the budget, like checking accounts and credit cards.\n",
      "\n",
      "Depending on your usage, savings accounts can either be on or off the budget. If you're not sure, we recommend keeping it on budget at the start.\n",
      "\n",
      "Adding a new account\n",
      "â€‹\n",
      "\n",
      "You can add an account to your budget at any time, however when you first install Actual you can use the\n",
      "Add Account\n",
      "button in the middle of the screen.\n",
      "\n",
      "You can also add an account using the\n",
      "+ Add account\n",
      "button in the sidebar.\n",
      "\n",
      "Two successive screens will appear with boxes asking you to fill in a few options\n",
      "\n",
      "Create a Local Account or Link to GoCardless (See\n",
      "Connecting Your Bank\n",
      ")\n",
      "Give your account a name\n",
      "Is the account on or off budget\n",
      "The current account balance\n",
      "\n",
      "Off budget means that the balance is not reflected when you assign money to categories in your budget register\n",
      "\n",
      "Here you can see how that looks when the options are completed.\n",
      "\n",
      "If you select the Off Budget checkbox then change the account type the Off Budget checkbox will reset and will need to be re-selected each time the account type is changed\n",
      "\n",
      "You can now see the account in the sidebar of Actual\n",
      "\n",
      "\n",
      "Closing or deleting an account\n",
      "â€‹\n",
      "\n",
      "Navigate to the account by clicking on it in the sidebar\n",
      "Click on the 3 dots (top right of the transactions list) to show the actions menu\n",
      "Select\n",
      "Close Account\n",
      "You need to select another account to transfer the existing balance to. Choose the account that you have moved funds to.\n",
      "Press\n",
      "Close Account\n",
      "\n",
      "You can still access this account under\n",
      "Closed Accounts\n",
      "in the sidebar, and even reopen it from the same actions menu.\n",
      "\n",
      "If you want to delete an account\n",
      "even if it has existing balances, in the popup after selecting\n",
      "Close Account\n",
      ", click the\n",
      "force close\n",
      "at the bottom.\n",
      "\n",
      "\n",
      "Renaming an existing account\n",
      "â€‹\n",
      "\n",
      "Click the account name in the sidebar of Actual\n",
      "\n",
      "Hovering your cursor close to the account name at the top will reveal two icons.\n",
      "The page icon allows you to write a note about this account, and the pencil icon allows you to rename the account.\n",
      "\n",
      "After editing a note for the account or its name, hit 'Enter' to save your changes.\n",
      "\n",
      "Off-budget accounts\n",
      "Adding a new account\n",
      "Closing or deleting an account\n",
      "Renaming an existing account \n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "(S: \n",
      "We collect account data, account balance, bank account, and assets for personal analytics.We collect account data, account balance, bank account, and assets for account management. We collect account data, account balance, bank account, and assets for Functionality. We use account data, account balance, bank account, and assets for personal analytics. We use account data, account balance, bank account, and assets for account management. We use account data, account balance, bank account, and assets for Functionality.\n",
      ")\n",
      "\n",
      "Here are the behaviors and the privacy requirements in the form of privacy stories we build from them:\n",
      "Privacy stories are built explicitly from our labelled privacy behaviors in the format of we (action) (data type) for (purpose)Actions: Collect, Use\n",
      "Data Types: Account Data, Account Balance, Bank Account, Assets\n",
      "Purposes: Personal analytics, Provide Service, \n",
      "\n",
      " \n",
      "Direct Messaging with LibreEHR and EMR Direct phiMail(R)\n",
      "Version 1.3, 19 Jul 2014\n",
      "\n",
      "A. Purpose: To provide a secure method from within LibreEHR for sending/receiving \n",
      "protected health information to/from another Direct address using the Direct Project \n",
      "messaging standard, as a step toward the goal of satisfying the three MU2 criteria \n",
      "requiring the use of Direct messaging.  (For general information about Direct messaging, \n",
      "see http://www.emrdirect.com/about-directed-exchange-and-secure-direct-messaging.html)\n",
      "\n",
      "B. IMPORTANT:  Please be aware of the following limitations when using the LibreEHR \n",
      "Direct Messaging features with PHI in a production environment:\n",
      "\n",
      "1. the current code only supports a single shared \"group\" Direct Address for each LibreEHR \n",
      "installation. Note that this model is fully compliant with the Direct Project \n",
      "requirements for Direct messaging, but we may add additional models in the future \n",
      "should we determine that doing so would provide a higher degree of interoperability for \n",
      "LibreEHR users.\n",
      "\n",
      "2. the current code only sends the CCR or CCD XML data that is already available in LibreEHR; \n",
      "these files as currently generated by existing LibreEHR code do not meet the requirements \n",
      "of the MU2 criteria, and the current CCD files do not pass strict CDA validation tests.\n",
      "\n",
      "C. Problems Solved:\n",
      "\n",
      "1. Patient-initiated transmission of clinical data from the Report section of the Patient \n",
      "Portal interface.\n",
      "\n",
      "2. Provider-initiated transmission of clinical data from the Report section of the Patient \n",
      "pane in the main LibreEHR interface.\n",
      "\n",
      "3. Log all data transmissions including date/time, patient, and whether transmission \n",
      "was initiated by the patient through the Patient Portal or by an LibreEHR user through the \n",
      "main interface.\n",
      "\n",
      "4. Receive Direct messages from other sources.\n",
      "\n",
      "D. How it Works:\n",
      "Once configured, LibreEHR will interface with a phiMail Direct messaging server to complete the\n",
      "required message transactions. The phiMail platform is described on the EMR Direct website, \n",
      "http://www.emrdirect.com and http://www.emrdirect.com/phimail-faq.html.\n",
      "\n",
      "E. What you need before enabling Direct Messaging in LibreEHR:\n",
      "\n",
      "1. Test Mode: Developers may request a complimentary test address at \n",
      "https://www.emrdirect.com/subscribe-developer  \n",
      "Access to a sandbox server is available for testing and development purposes.\n",
      "\n",
      "2. Production Mode: Healthcare provider users should begin by signing up for a production \n",
      "Direct messaging account with EMR Direct by registering at https://www.emrdirect.com/subscribe\n",
      "\n",
      "Subscribers will receive the username, password, and server address information with which to \n",
      "configure LibreEHR.  \n",
      "\n",
      "F. How to enable the Direct Messaging Features in LibreEHR:\n",
      "Setup of phiMail Direct messaging Service is done in the Administration::Globals::Connectors \n",
      "tab\n",
      "\n",
      "1. Check the \"Enable phiMail Direct Messaging Service\" checkbox.\n",
      "\n",
      "2. Enter the Server Address, Username, and Password provided to you. The server address\n",
      "will be of the form \"ssl://servername.example.com:32541\" - replace the hostname and port\n",
      "with the values provided to you by EMR Direct. The Username is your Direct Address. Do not \n",
      "enter the server URL into your browser address bar, as this will not work.\n",
      "\n",
      "3. Specify the LibreEHR user who will receive notification of new incoming Direct messages. \n",
      "Enter their LibreEHR username in the notification user field.\n",
      "\n",
      "4. Specify the interval for automatic message checking; we suggest 5 or 10 minutes as a\n",
      "starting point, but installations processing a large number of Direct messages may want a \n",
      "shorter interval. To disable automatic message checking through LibreEHR's background service\n",
      "manager, set the interval to 0 (zero). Disabling automatic checking would be appropriate \n",
      "if message checking is managed through another mechanism, such as a system cron job.\n",
      "\n",
      "5. Optionally check \"phiMail Allow CCD Send\" and/or \"phiMail Allow CCR Send\" to enable\n",
      "the Transmit feature for these data types. If you do not select at least one of these,\n",
      "LibreEHR will operate in a receive-only mode.\n",
      "\n",
      "6. Click the \"Save\" button.\n",
      "\n",
      "7. Confirm that a valid Notification Email Address is set in the Administration::\n",
      "Globals::Notifications tab to receive error notifications from the Direct Messaging service.\n",
      "\n",
      "8. Install the EMR Direct trust anchor certificate.  \n",
      "\n",
      "Note: This is *not* your Direct certificate; it is the trust anchor for the SSL \n",
      "certificate issued to our servers, and is used only to validate the SSL certificate \n",
      "presented by the phiMail server on the other side of LibreEHR's connection.  Your Direct private\n",
      "key and certificate are managed by the phiMail Server and are not installed in LibreEHR.\n",
      "Your Direct certificate is made availabe for your review by EMR Direct, but you will not\n",
      "need to install it anywhere.\n",
      "\n",
      "For added security, the trust anchor for the phiMail Server should be installed in the LibreEHR \n",
      "installation tree at:\n",
      "\n",
      "[installation_root]/sites/[site_id]/documents/phimail_server_pem/phimail_server.pem\n",
      "\n",
      "This phimail_server_pem directory and its contents should be readable by the the \n",
      "webserver process, but only writable by trusted local users. The certificate file \n",
      "itself must be PEM encoded. You can identify a PEM encoded certificate file because \n",
      "it begins with the text \"-----BEGIN CERTIFICATE-----\". Although LibreEHR will connect \n",
      "to phiMail servers without installing this certificate, this is a required configuration \n",
      "step for all production  accounts to ensure that you are connecting to the correct \n",
      "server. You can obtain the correct certificate at the following URLs:\n",
      "\n",
      "  a. Test accounts: http://certs.emrdirect.com/EMRDirectTestCA.crt\n",
      "     Important: Don't forget to rename the file to phimail_server.pem and install it\n",
      "     in the correct directory.\n",
      "\n",
      "  b. Production accounts: https://www.phicert.com/certs/phiCertDirectRootCA.crt\n",
      "     Important: The production root must be converted to PEM format as follows:\n",
      "     $ openssl x509 -in phiCertDirectRootCA.crt -inform DER -out phimail_server.pem\n",
      "     Don't forget to install phimail_server.pem in the correct directory. As an added\n",
      "     security measure, please call us to confirm the thumbprint on this certificate.\n",
      "\n",
      "G. Debugging background connections to the server.\n",
      "\n",
      "You may review the connection activity to the server by Selecting Administration::Other::Logs,\n",
      "selecting \"direct-message\" in the \"Name of events:\" drop-down menu, and clicking \"[Refresh]\".\n",
      "If the background service is succesfully connecting, you will see \"message check completed\"\n",
      "events in the log as well as any message related entries (see below for instructions to\n",
      "view more detailed message related status information). If you see no entries, make sure that\n",
      "the background service is enabled (See F.4 above). If you see \"could not connect to server\"\n",
      "entries, each entry will also contain an error code:\n",
      "\n",
      "  C1: phiMail is disabled in the global configuration. Fix: enable.\n",
      "  C2: the phiMail server URL entered in the global configuration is invalid. Fix: Confirm\n",
      "      the URL has been entered correctly. It should be of the form \n",
      "      \"ssl://server.example.com:32541\".\n",
      "  C3: unable to create stream context. Fix: Usually this is because the server certificate \n",
      "      file installed in F.8 above is not the correct certificate or is in the wrong format.\n",
      "  C4: failed to open connection. Fix: Confirm you Internet service and local DNS servers are\n",
      "      online and your firewall is not blocking connections to the phiMail Server.\n",
      "\n",
      "H. Checking the status and history of the Direct Messaging Service in LibreEHR:\n",
      "Administrators may view the status of the service by Selecting Reports::Services::Background \n",
      "Services from the main LibreEHR left navigation bar. The \"View Log\" link on this page or \n",
      "Reports::Services::Direct Message Log will open the messaging history log showing each message \n",
      "sent or received and the current status of that message (Received, Sent, Delivery Confirmed, \n",
      "or Failed).\n",
      "\n",
      "I. Note of message status messages: Receiving message status updates requires that Direct message\n",
      "checking be enabled. When receiving messages, the phiMail back-end is fully compliant with the \n",
      "Direct messaging protocols to notify the sender and provide final delivery confirmation, but \n",
      "please note that  many other Direct providers do not yet support these features. If a message \n",
      "is sent to a recipient using one of these other systems, LibreEHR probably won't ever receive a \n",
      "final delivery confirmation for that message.\n",
      "\n",
      "J. How to use the Direct Messaging Features in LibreEHR:\n",
      "\n",
      "1. Sending:\n",
      "When the phiMail Direct Messaging service is enabled, an additional \"Transmit\" button will\n",
      "appear in the Continuity of Care Record (CCR) and/or Continuity of Care Document (CCD) block \n",
      "of the Reports section in both the Patient Portal and the Patient pane of the main provider \n",
      "interface. \n",
      "\n",
      "To transmit a CCR or CCD, first click the \"Transmit\" button. This will open a small dialog \n",
      "immediately below the button with a form field to enter the intended recipient's Direct Address. \n",
      "Clicking \"Transmit\" again will hide the dialog.\n",
      "\n",
      "A Direct Address should have the same form as a regular email address, e.g. \n",
      "jonesclinic@direct.example.com. Enter the address in the field and click the \"Send\" button \n",
      "immediately to the right of the field. Only a single recipient may be specified in the field.\n",
      "The Send button will be temporarily disabled while LibreEHR is communicating with the phiMail \n",
      "server. This will only work for properly-configured Direct addresses. Attempts to send to a \n",
      "regular email address or Direct address outside of our test mode \"trust sandbox\" will fail\n",
      "during testing. Production accounts have wide interoperability with other Direct service\n",
      "providers. Should you encounter a trust community with which LibreEHR does not interoperate,\n",
      "please let us know at support@emrdirect.com.\n",
      "\n",
      "LibreEHR will then display a status message immediately below the Address field, the \n",
      "success or failure of the message transmission, or an error message. If the message is\n",
      "successfully submitted to the server, the Address field will be cleared to prevent accidental\n",
      "re-transmission. If multiple recipients are required, the next recipient can now be entered.\n",
      "\n",
      "If you receive an error message, it will be followed by an error code. For a discussion\n",
      "of error codes beginning with the letter \"C\" please see section G above. Error codes\n",
      "beginning with \"EC\" are listed here:\n",
      "\n",
      "  EC 1: phiMail disabled in global configuration. Fix: enable.\n",
      "  EC 4: authentication failure. Fix: The Username and Password entered in the\n",
      "        global configuration must be corrected.\n",
      "  EC 5: request to add text failed. Fix: Confirm total message length < 5MB.\n",
      "  EC 6: problem sending the text. Fix: Confirm your local network connectivity is stable.\n",
      "  EC 7: request to add clinical document failed. Fix: see EC 5.\n",
      "  EC 8: problem sending the clinical document. Fix: see EC 6.\n",
      "\n",
      "2. Receiving:\n",
      "When the phiMail Direct Messaging service is enabled, and message checking is enabled either \n",
      "through the background services manager of another mechanism, LibreEHR will automatically process \n",
      "message status updates and new messages. Status updates will be reflected immediately in the \n",
      "Direct Messaging log. Additionally, if a \"Failed\" notification is received for a previously sent \n",
      "message, a regular email message will be generated to the Notification Email Address specified \n",
      "in the Notifications tab of the Global Settings panel (accessed by selecting Administration::\n",
      "Globals from the main left navigation menu).\n",
      "\n",
      "New Direct messages will be processed as follows. A new \"Patient Note\" will be generated and \n",
      "sent to the phiMail notification user specified in the Connectors tab of the Global settings. \n",
      "The patient note will contain information about the message, including any text at the beginning \n",
      "of the message from the sender. Any attachments (and any non-text content) will be automatically \n",
      "converted to separate LibreEHR Documents, which will be referenced in the new Patient Note.  \n",
      "The Documents and the Patient Note are initially created without an assigned patient. \n",
      "\n",
      "At this time, the envisioned workflow is that the notification user will review the message text\n",
      "and any included Documents to determine which patient the content belongs to and will then set the \n",
      "patient using the existing Patient Note interface for choosing a patient. Once the patient is sent, \n",
      "the Patient Note can be forwarded to another provider or staff member as appropriate using the \n",
      "existing forwarding mechanism for Patient Notes. The unassigned Documents can be viewed by Selecting \n",
      "Miscellaneous::New Documents from the main left navigation menu, which opens a Documents list. Once \n",
      "the specified document is opened, the user can optionally categorize the document and, when \n",
      "appropriate, assign the document to a specific patient using the \"Move to Patient #\" feature in the \n",
      "Documents interface.\n",
      "\n",
      "\n",
      "Trademark Notice: phiMail is a registered trademark of EMR Direct.\n",
      "\n",
      "Copyright (c) 2013-2014 EMR Direct.\n",
      "\n",
      "\n",
      "Annotate the text with actions, data types, purposes, and stories as demonstrated, using only the categories from the list provided. For each annotation, provide your rationale and place <R> tag between your annotations and rationales.\n",
      "\n",
      "\n",
      "Token Count: 3961 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from typing import Dict, List, Union\n",
    "import tiktoken  # Library for token counting with OpenAI models\n",
    "import prompt_templates\n",
    "\n",
    "# Load the privacy ontology\n",
    "ontology_path = \"privacy_ontology_simple.json\"\n",
    "privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "\n",
    "# Load one processed example file for demonstration\n",
    "example_file = text_processing.process_input(example_file_path)[0]\n",
    "\n",
    "\n",
    "# Define target text to be annotated (for demonstration) & Load annotated version \n",
    "target_file_annotations = text_processing.process_input(target_file_path)\n",
    "new_text_to_annotate = open(target_file_path).read()\n",
    "\n",
    "# Generate the prompt\n",
    "prompt_example = prompt_templates.create_annotation_prompt(example_file, new_text_to_annotate, privacy_ontology)\n",
    "\n",
    "# Print the prompt to review it\n",
    "print(prompt_example)\n",
    "print(f\"\\nToken Count: {prompt_templates.count_tokens(prompt_example)} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating with LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing input\\Actual_Budget\\Backup_&_Restore.txt: 'charmap' codec can't decode byte 0x9d in position 232: character maps to <undefined>\n",
      "Created prompt templates for 24 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import prompt_templates\n",
    "import text_processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "input_dir = 'input'\n",
    "\n",
    "def find_matching_file(input_file_path, annotations_dir):\n",
    "    \"\"\"\n",
    "    Find the matching annotation file for a given input file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Root directory of annotations\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the matching annotation file, or None if not found\n",
    "    \"\"\"\n",
    "    # Get the relative path from the input directory\n",
    "    relative_path = os.path.relpath(input_file_path, input_dir)\n",
    "    annotation_file_path = os.path.join(annotations_dir, relative_path)\n",
    "    \n",
    "    return annotation_file_path if os.path.exists(annotation_file_path) else None\n",
    "\n",
    "\n",
    "def find_most_similar_file(input_file_path, annotations_dir, exclude_file):\n",
    "    \"\"\"\n",
    "    Find the most similar annotation file to the input file, excluding a specified file.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to the input file\n",
    "        annotations_dir (str): Directory containing the annotation files\n",
    "        exclude_file (str): File to exclude from similarity search\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the most similar annotation file\n",
    "    \"\"\"\n",
    "    # Read the input file's content\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        input_text = f.read()\n",
    "    \n",
    "    # List to store (similarity_score, annotation_file_path)\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Loop through the annotations directory to calculate similarity\n",
    "    for root, _, files in os.walk(annotations_dir):\n",
    "        for filename in files:\n",
    "            if filename == exclude_file or filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            annotation_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Read the annotation file's content\n",
    "            with open(annotation_file_path, 'r', encoding='utf-8') as f:\n",
    "                annotation_text = f.read()\n",
    "            \n",
    "            # Compute similarity using TF-IDF and cosine similarity\n",
    "            tfidf = TfidfVectorizer().fit_transform([input_text, annotation_text])\n",
    "            similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "            similarity_scores.append((similarity, annotation_file_path))\n",
    "    \n",
    "    # Sort by similarity score in descending order and return the most similar file\n",
    "    similarity_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    return similarity_scores[0][1] if similarity_scores else None\n",
    "\n",
    "\n",
    "def create_prompt_templates_dict(input_dir='input', annotations_dir='annotations', ontology_path='privacy_ontology_simple.json'):\n",
    "    \"\"\"\n",
    "    Create a dictionary of prompt templates matching input files with their corresponding annotation examples.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Root directory containing input files to be annotated\n",
    "        annotations_dir (str): Root directory containing annotated example files\n",
    "        ontology_path (str): Path to the privacy ontology JSON file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of prompt templates for each input file\n",
    "    \"\"\"\n",
    "    # Load privacy ontology\n",
    "    privacy_ontology = prompt_templates.load_privacy_ontology(ontology_path)\n",
    "    \n",
    "    # Dictionary to store prompt templates\n",
    "    prompt_templates_dict = {}\n",
    "    \n",
    "    # Walk through all directories and files in the input directory\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            # Skip hidden files\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            \n",
    "            # Full path to the input file\n",
    "            input_file_path = os.path.join(root, filename)\n",
    "            \n",
    "            # Find corresponding annotation file (for exclusion from similarity search)\n",
    "            annotation_file_path = find_matching_file(input_file_path, annotations_dir)\n",
    "            \n",
    "            if not annotation_file_path:\n",
    "                print(f\"No matching annotation found for {input_file_path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Read the input text to annotate\n",
    "                with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                    new_text_to_annotate = f.read()\n",
    "                \n",
    "                # Find the most similar annotation file\n",
    "                most_similar_annotation = find_most_similar_file(input_file_path, annotations_dir, os.path.basename(annotation_file_path))\n",
    "                \n",
    "                if not most_similar_annotation:\n",
    "                    print(f\"No similar annotation found for {input_file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the example file from annotations\n",
    "                example_file = text_processing.process_input(most_similar_annotation)[0]\n",
    "                \n",
    "                # Create prompt template\n",
    "                prompt_template = prompt_templates.create_0_shot_annotation_prompt(\n",
    "                    example_file, \n",
    "                    new_text_to_annotate, \n",
    "                    privacy_ontology\n",
    "                )\n",
    "                \n",
    "                # Create a unique key based on relative path\n",
    "                relative_key = os.path.relpath(input_file_path, input_dir)\n",
    "                \n",
    "                # Store in dictionary\n",
    "                prompt_templates_dict[relative_key] = {\n",
    "                    'input_file_path': input_file_path,\n",
    "                    'annotation_file_path': most_similar_annotation,\n",
    "                    'prompt_template': prompt_template,\n",
    "                    'target_annotations': text_processing.process_file(annotation_file_path),\n",
    "                    'token_count': prompt_templates.count_tokens(prompt_template)\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_file_path}: {e}\")\n",
    "    \n",
    "    return prompt_templates_dict\n",
    "\n",
    "\n",
    "# Create the prompt templates dictionary\n",
    "prompt_templates_dict = create_prompt_templates_dict()\n",
    "\n",
    "# Save to JSON for inspection\n",
    "with open('prompt_templates_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({k: {**v, 'prompt_template': v['prompt_template']} \n",
    "              for k, v in prompt_templates_dict.items()}, \n",
    "              f, indent=2)\n",
    "\n",
    "print(f\"Created prompt templates for {len(prompt_templates_dict)} files\")\n",
    "\n",
    "# Optional: You can save the full dictionary using pickle if needed\n",
    "import pickle\n",
    "with open('prompt_templates.pkl', 'wb') as f:\n",
    "    pickle.dump(prompt_templates_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Error with groq:llama-3.2-3b-preview: no healthy upstream\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Model: groq:llama-3.2-3b-preview - Completed a run\n",
      "Annotation results saved to LLMAnnotation_grokLLama3_2_0_shot.csv\n",
      "Number of files processed: 24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from getpass import getpass\n",
    "import model_routing\n",
    "from typing import Dict, List\n",
    "\n",
    "# Ensure OPENAI_API_KEY is set\n",
    "# os.environ['OPENAI_API_KEY'] = getpass('Enter your OPENAI API key: ')\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = getpass('Enter your Groq API key: ')\n",
    "\n",
    "def save_results_to_csv(models: List[str], \n",
    "                         prompt_templates_dict: Dict, \n",
    "                         model_responses: Dict, \n",
    "                         output_file: str):\n",
    "    \"\"\"\n",
    "    Save the model outputs, prompts, and file annotations to a CSV file.\n",
    "    \"\"\"\n",
    "    # Open the output CSV file\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Prepare the CSV header\n",
    "        fieldnames = ['File', 'Prompt', 'Model', 'Target File Path', 'Target Annotations', 'Model Response 1', 'Model Response 2']\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Iterate through the prompt templates and models to pair responses\n",
    "        for file_key in file_keys:\n",
    "            template_info = prompt_templates_dict[file_key]\n",
    "            \n",
    "            for model in models:\n",
    "                # Get responses for this model\n",
    "                model_specific_responses = model_responses.get(model, {})\n",
    "                \n",
    "                # Get responses for this specific file/prompt\n",
    "                prompt_responses = model_specific_responses.get(file_key, [])\n",
    "                \n",
    "                # Ensure we have at least two responses (or 'No Response')\n",
    "                response1 = prompt_responses[0] if prompt_responses and len(prompt_responses) > 0 else 'No Response'\n",
    "                response2 = prompt_responses[1] if prompt_responses and len(prompt_responses) > 1 else 'No Response'\n",
    "\n",
    "                # Create a row for each model and file\n",
    "                row = {\n",
    "                    'File': file_key,\n",
    "                    'Prompt': template_info['prompt_template'],\n",
    "                    'Model': model,\n",
    "                    'Target File Path': template_info['input_file_path'],\n",
    "                    'Target Annotations': json.dumps(template_info['target_annotations']),\n",
    "                    'Model Response 1': json.dumps(response1, ensure_ascii=False),\n",
    "                    'Model Response 2': json.dumps(response2, ensure_ascii=False)\n",
    "                }\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "def run_multi_file_annotations(prompt_templates_dict, output_csv, models=None):\n",
    "    \"\"\"\n",
    "    Run annotation process for multiple files and save results to a CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Create a list of file keys to maintain order\n",
    "        file_keys = list(prompt_templates_dict.keys())\n",
    "\n",
    "        # Prepare prompts that maintains the file key order\n",
    "        test_prompts = [\n",
    "            prompt_templates_dict[file_key]['prompt_template'] \n",
    "            for file_key in file_keys\n",
    "        ]\n",
    "\n",
    "        # Get model responses \n",
    "        raw_model_responses = model_routing.run_multi_model_prompts(\n",
    "            models=models, \n",
    "            prompts=test_prompts, \n",
    "            num_runs=2  # Number of runs per model\n",
    "        )\n",
    "\n",
    "        # Restructure responses to match file keys\n",
    "        model_responses = {}\n",
    "        for model in models:\n",
    "            model_responses[model] = {\n",
    "                file_key: model_runs \n",
    "                for file_key, model_runs in zip(file_keys, raw_model_responses.get(model, []))\n",
    "            }\n",
    "\n",
    "        # Save results to CSV \n",
    "        save_results_to_csv(\n",
    "            models=models,\n",
    "            prompt_templates_dict=prompt_templates_dict,\n",
    "            model_responses=model_responses,\n",
    "            output_file=output_csv\n",
    "        )\n",
    "\n",
    "        print(f\"Annotation results saved to {output_csv}\")\n",
    "        print(f\"Number of files processed: {len(prompt_templates_dict)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage remains the same\n",
    "output_csv = 'LLMAnnotation_grokLLama3_2_0_shot.csv'\n",
    "models = [\n",
    "    # 'openai:gpt-4o-2024-11-20'\n",
    "    'groq:llama-3.2-3b-preview'\n",
    "    ]\n",
    "run_multi_file_annotations(prompt_templates_dict, output_csv, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
